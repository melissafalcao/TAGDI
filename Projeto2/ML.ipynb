{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Proj2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "T7XyMhjQdgyp",
        "IpFBPry1eFfv",
        "2KHVWIB6eROa",
        "L3mgMFmCchIK",
        "_K8mBYKocqqO",
        "Avwiqzgbc8oS",
        "kHQgp-F1dEDx",
        "RZBvpotEdLX1"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7XyMhjQdgyp"
      },
      "source": [
        "# **Dependências**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZIZhdsw-4J9"
      },
      "source": [
        "!pip install mlflow --quiet"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW1heNfn_FCf"
      },
      "source": [
        "!pip install mlflow --quiet"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cquT4Oa-_boi"
      },
      "source": [
        "!pip install optuna --quiet"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNSTdZStSM07"
      },
      "source": [
        "!pip install pyngrok --quiet"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXk2xKC2TmFI"
      },
      "source": [
        "!pip install ngrok --quiet"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wr8uCWBKvmxw"
      },
      "source": [
        "!pip install auto-sklearn --quiet"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0v6RDnRxX0W"
      },
      "source": [
        "!pip install scipy==1.7.1 --quiet"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piIchDdVZV1B"
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "import optuna\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "askb0I6FFuP3"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn import neighbors\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn import preprocessing"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpFBPry1eFfv"
      },
      "source": [
        "# **Dataframe**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txSop5z-pfM9"
      },
      "source": [
        "Aqui adicionamos mais um pouco de pre-processamento, pois para utilizar algoritmos de regressão precisamos de variáveis numéricas. Sendo assim realizamos a conversão dos tipos categóricos para numéricos, e as normalizações necessárias."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAMCUzmhL6NK"
      },
      "source": [
        "data = pd.read_csv(\"https://raw.githubusercontent.com/melissafalcao/TAGDI/main/Projeto2/saida.csv?token=AHWTHUD4X4NG6S7FASU7DUTBEGYKK\", encoding =\"UTF-8\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiJl1twHKXVi"
      },
      "source": [
        "data = data.drop(data.columns[0], axis=1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "id": "ixKFlUToMWg0",
        "outputId": "e3f3b404-c991-46b5-8381-33dcdb679df4"
      },
      "source": [
        "data.head(5)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Score</th>\n",
              "      <th>Genders</th>\n",
              "      <th>Type</th>\n",
              "      <th>Episodes</th>\n",
              "      <th>Producers</th>\n",
              "      <th>Studios</th>\n",
              "      <th>Source</th>\n",
              "      <th>Duration</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Members</th>\n",
              "      <th>Favorites</th>\n",
              "      <th>Watching</th>\n",
              "      <th>Completed</th>\n",
              "      <th>On-Hold</th>\n",
              "      <th>Dropped</th>\n",
              "      <th>Plan to Watch</th>\n",
              "      <th>Score-10</th>\n",
              "      <th>Score-9</th>\n",
              "      <th>Score-8</th>\n",
              "      <th>Score-7</th>\n",
              "      <th>Score-6</th>\n",
              "      <th>Score-5</th>\n",
              "      <th>Score-4</th>\n",
              "      <th>Score-3</th>\n",
              "      <th>Score-2</th>\n",
              "      <th>Score-1</th>\n",
              "      <th>Finished</th>\n",
              "      <th>Estreia</th>\n",
              "      <th>GendersList</th>\n",
              "      <th>StudiosList</th>\n",
              "      <th>members_log</th>\n",
              "      <th>Score-10/1</th>\n",
              "      <th>MembersClass</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Cowboy Bebop</td>\n",
              "      <td>0.944142</td>\n",
              "      <td>Action, Adventure, Comedy, Drama, Sci-Fi, Space</td>\n",
              "      <td>TV</td>\n",
              "      <td>0.008181</td>\n",
              "      <td>Bandai Visual</td>\n",
              "      <td>Sunrise</td>\n",
              "      <td>Original</td>\n",
              "      <td>24 min. per ep.</td>\n",
              "      <td>R - 17+ (violence &amp; profanity)</td>\n",
              "      <td>0.483459</td>\n",
              "      <td>0.336956</td>\n",
              "      <td>0.119243</td>\n",
              "      <td>0.329041</td>\n",
              "      <td>0.380552</td>\n",
              "      <td>0.152699</td>\n",
              "      <td>329800.0</td>\n",
              "      <td>0.320601</td>\n",
              "      <td>0.340261</td>\n",
              "      <td>0.286693</td>\n",
              "      <td>0.205156</td>\n",
              "      <td>0.109786</td>\n",
              "      <td>0.071328</td>\n",
              "      <td>0.039222</td>\n",
              "      <td>0.030677</td>\n",
              "      <td>0.029168</td>\n",
              "      <td>0.046787</td>\n",
              "      <td>0.788462</td>\n",
              "      <td>0.778846</td>\n",
              "      <td>['Action', 'Adventure', 'Comedy', 'Drama', 'Sc...</td>\n",
              "      <td>['Sunrise']</td>\n",
              "      <td>6.097590</td>\n",
              "      <td>2.161501</td>\n",
              "      <td>SS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Cowboy Bebop: Tengoku no Tobira</td>\n",
              "      <td>0.891008</td>\n",
              "      <td>Action, Drama, Mystery, Sci-Fi, Space</td>\n",
              "      <td>Movie</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Sunrise, Bandai Visual</td>\n",
              "      <td>Bones</td>\n",
              "      <td>Original</td>\n",
              "      <td>1 hr. 55 min.</td>\n",
              "      <td>R - 17+ (violence &amp; profanity)</td>\n",
              "      <td>0.105469</td>\n",
              "      <td>0.006383</td>\n",
              "      <td>0.004669</td>\n",
              "      <td>0.095452</td>\n",
              "      <td>0.010297</td>\n",
              "      <td>0.004407</td>\n",
              "      <td>57964.0</td>\n",
              "      <td>0.042028</td>\n",
              "      <td>0.091919</td>\n",
              "      <td>0.107826</td>\n",
              "      <td>0.074490</td>\n",
              "      <td>0.030802</td>\n",
              "      <td>0.015030</td>\n",
              "      <td>0.007098</td>\n",
              "      <td>0.004977</td>\n",
              "      <td>0.004257</td>\n",
              "      <td>0.011200</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>['Action', 'Drama', 'Mystery', 'Sci-Fi', 'Space']</td>\n",
              "      <td>['Bones']</td>\n",
              "      <td>5.436393</td>\n",
              "      <td>1.899104</td>\n",
              "      <td>SS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Trigun</td>\n",
              "      <td>0.870572</td>\n",
              "      <td>Action, Sci-Fi, Adventure, Comedy, Drama, Shounen</td>\n",
              "      <td>TV</td>\n",
              "      <td>0.008181</td>\n",
              "      <td>Victor Entertainment</td>\n",
              "      <td>Madhouse</td>\n",
              "      <td>Manga</td>\n",
              "      <td>24 min. per ep.</td>\n",
              "      <td>PG-13 - Teens 13 or older</td>\n",
              "      <td>0.215824</td>\n",
              "      <td>0.070381</td>\n",
              "      <td>0.032810</td>\n",
              "      <td>0.157378</td>\n",
              "      <td>0.135511</td>\n",
              "      <td>0.079704</td>\n",
              "      <td>146918.0</td>\n",
              "      <td>0.070268</td>\n",
              "      <td>0.141336</td>\n",
              "      <td>0.187625</td>\n",
              "      <td>0.162703</td>\n",
              "      <td>0.081595</td>\n",
              "      <td>0.046764</td>\n",
              "      <td>0.024201</td>\n",
              "      <td>0.014999</td>\n",
              "      <td>0.012416</td>\n",
              "      <td>0.015763</td>\n",
              "      <td>0.778846</td>\n",
              "      <td>0.778846</td>\n",
              "      <td>['Action', 'Sci-Fi', 'Adventure', 'Comedy', 'D...</td>\n",
              "      <td>['Madhouse']</td>\n",
              "      <td>5.747344</td>\n",
              "      <td>1.974227</td>\n",
              "      <td>SS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Witch Hunter Robin</td>\n",
              "      <td>0.738420</td>\n",
              "      <td>Action, Mystery, Police, Supernatural, Drama, ...</td>\n",
              "      <td>TV</td>\n",
              "      <td>0.008181</td>\n",
              "      <td>TV Tokyo, Bandai Visual, Dentsu, Victor Entert...</td>\n",
              "      <td>Sunrise</td>\n",
              "      <td>Original</td>\n",
              "      <td>25 min. per ep.</td>\n",
              "      <td>PG-13 - Teens 13 or older</td>\n",
              "      <td>0.036552</td>\n",
              "      <td>0.003192</td>\n",
              "      <td>0.004846</td>\n",
              "      <td>0.021152</td>\n",
              "      <td>0.027251</td>\n",
              "      <td>0.030782</td>\n",
              "      <td>33719.0</td>\n",
              "      <td>0.003051</td>\n",
              "      <td>0.008977</td>\n",
              "      <td>0.022058</td>\n",
              "      <td>0.038237</td>\n",
              "      <td>0.030292</td>\n",
              "      <td>0.023386</td>\n",
              "      <td>0.013333</td>\n",
              "      <td>0.007963</td>\n",
              "      <td>0.006425</td>\n",
              "      <td>0.003852</td>\n",
              "      <td>0.817308</td>\n",
              "      <td>0.817308</td>\n",
              "      <td>['Action', 'Mystery', 'Police', 'Supernatural'...</td>\n",
              "      <td>['Sunrise']</td>\n",
              "      <td>4.976272</td>\n",
              "      <td>1.221583</td>\n",
              "      <td>SS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bouken Ou Beet</td>\n",
              "      <td>0.698910</td>\n",
              "      <td>Adventure, Fantasy, Shounen, Supernatural</td>\n",
              "      <td>TV</td>\n",
              "      <td>0.016688</td>\n",
              "      <td>TV Tokyo, Dentsu</td>\n",
              "      <td>Toei Animation</td>\n",
              "      <td>Manga</td>\n",
              "      <td>23 min. per ep.</td>\n",
              "      <td>PG - Children</td>\n",
              "      <td>0.005094</td>\n",
              "      <td>0.000098</td>\n",
              "      <td>0.000724</td>\n",
              "      <td>0.003351</td>\n",
              "      <td>0.004076</td>\n",
              "      <td>0.006342</td>\n",
              "      <td>3394.0</td>\n",
              "      <td>0.000435</td>\n",
              "      <td>0.000986</td>\n",
              "      <td>0.002703</td>\n",
              "      <td>0.005635</td>\n",
              "      <td>0.005663</td>\n",
              "      <td>0.005071</td>\n",
              "      <td>0.003253</td>\n",
              "      <td>0.001855</td>\n",
              "      <td>0.001931</td>\n",
              "      <td>0.000770</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.836538</td>\n",
              "      <td>['Adventure', 'Fantasy', 'Shounen', 'Supernatu...</td>\n",
              "      <td>['Toei Animation']</td>\n",
              "      <td>4.121363</td>\n",
              "      <td>1.062791</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              Name     Score  ... Score-10/1 MembersClass\n",
              "0                     Cowboy Bebop  0.944142  ...   2.161501           SS\n",
              "1  Cowboy Bebop: Tengoku no Tobira  0.891008  ...   1.899104           SS\n",
              "2                           Trigun  0.870572  ...   1.974227           SS\n",
              "3               Witch Hunter Robin  0.738420  ...   1.221583           SS\n",
              "4                   Bouken Ou Beet  0.698910  ...   1.062791            S\n",
              "\n",
              "[5 rows x 34 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yY6-1IBMqAi",
        "outputId": "b3c834a0-3f3b-4af0-91d3-18cd8e669fdb"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 12421 entries, 0 to 12420\n",
            "Data columns (total 34 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   Name           12421 non-null  object \n",
            " 1   Score          12421 non-null  float64\n",
            " 2   Genders        12421 non-null  object \n",
            " 3   Type           12421 non-null  object \n",
            " 4   Episodes       12421 non-null  float64\n",
            " 5   Producers      12421 non-null  object \n",
            " 6   Studios        12421 non-null  object \n",
            " 7   Source         12421 non-null  object \n",
            " 8   Duration       12421 non-null  object \n",
            " 9   Rating         12421 non-null  object \n",
            " 10  Members        12421 non-null  float64\n",
            " 11  Favorites      12421 non-null  float64\n",
            " 12  Watching       12421 non-null  float64\n",
            " 13  Completed      12421 non-null  float64\n",
            " 14  On-Hold        12421 non-null  float64\n",
            " 15  Dropped        12421 non-null  float64\n",
            " 16  Plan to Watch  12421 non-null  float64\n",
            " 17  Score-10       12421 non-null  float64\n",
            " 18  Score-9        12421 non-null  float64\n",
            " 19  Score-8        12421 non-null  float64\n",
            " 20  Score-7        12421 non-null  float64\n",
            " 21  Score-6        12421 non-null  float64\n",
            " 22  Score-5        12421 non-null  float64\n",
            " 23  Score-4        12421 non-null  float64\n",
            " 24  Score-3        12421 non-null  float64\n",
            " 25  Score-2        12421 non-null  float64\n",
            " 26  Score-1        12421 non-null  float64\n",
            " 27  Finished       12421 non-null  float64\n",
            " 28  Estreia        12421 non-null  float64\n",
            " 29  GendersList    12421 non-null  object \n",
            " 30  StudiosList    12421 non-null  object \n",
            " 31  members_log    12421 non-null  float64\n",
            " 32  Score-10/1     12421 non-null  float64\n",
            " 33  MembersClass   12421 non-null  object \n",
            "dtypes: float64(23), object(11)\n",
            "memory usage: 3.2+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NraO6o4Ba-RS"
      },
      "source": [
        "data['Genders'] = data['Genders'].astype('category')\n",
        "data['Type'] = data['Type'].astype('category')\n",
        "data['Producers'] = data['Producers'].astype('category')\n",
        "data['Duration'] = data['Duration'].astype('category')\n",
        "data['Studios'] = data['Studios'].astype('category')\n",
        "data['Source'] = data['Source'].astype('category')\n",
        "data['Rating'] = data['Rating'].astype('category')\n",
        "data['MembersClass'] = data['MembersClass'].astype('category')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNf53FN1dV3j",
        "outputId": "65dd6beb-aebb-4e9d-b9d9-a60cd33601ff"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 12421 entries, 0 to 12420\n",
            "Data columns (total 34 columns):\n",
            " #   Column         Non-Null Count  Dtype   \n",
            "---  ------         --------------  -----   \n",
            " 0   Name           12421 non-null  object  \n",
            " 1   Score          12421 non-null  float64 \n",
            " 2   Genders        12421 non-null  category\n",
            " 3   Type           12421 non-null  category\n",
            " 4   Episodes       12421 non-null  float64 \n",
            " 5   Producers      12421 non-null  category\n",
            " 6   Studios        12421 non-null  category\n",
            " 7   Source         12421 non-null  category\n",
            " 8   Duration       12421 non-null  category\n",
            " 9   Rating         12421 non-null  category\n",
            " 10  Members        12421 non-null  float64 \n",
            " 11  Favorites      12421 non-null  float64 \n",
            " 12  Watching       12421 non-null  float64 \n",
            " 13  Completed      12421 non-null  float64 \n",
            " 14  On-Hold        12421 non-null  float64 \n",
            " 15  Dropped        12421 non-null  float64 \n",
            " 16  Plan to Watch  12421 non-null  float64 \n",
            " 17  Score-10       12421 non-null  float64 \n",
            " 18  Score-9        12421 non-null  float64 \n",
            " 19  Score-8        12421 non-null  float64 \n",
            " 20  Score-7        12421 non-null  float64 \n",
            " 21  Score-6        12421 non-null  float64 \n",
            " 22  Score-5        12421 non-null  float64 \n",
            " 23  Score-4        12421 non-null  float64 \n",
            " 24  Score-3        12421 non-null  float64 \n",
            " 25  Score-2        12421 non-null  float64 \n",
            " 26  Score-1        12421 non-null  float64 \n",
            " 27  Finished       12421 non-null  float64 \n",
            " 28  Estreia        12421 non-null  float64 \n",
            " 29  GendersList    12421 non-null  object  \n",
            " 30  StudiosList    12421 non-null  object  \n",
            " 31  members_log    12421 non-null  float64 \n",
            " 32  Score-10/1     12421 non-null  float64 \n",
            " 33  MembersClass   12421 non-null  category\n",
            "dtypes: category(8), float64(23), object(3)\n",
            "memory usage: 3.0+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yu8x1mPEgAUv"
      },
      "source": [
        "le = preprocessing.LabelEncoder()\n",
        "data['Genders'] = le.fit_transform(data['Genders'])\n",
        "data['Source'] = le.fit_transform(data['Source'])\n",
        "data['Type'] = le.fit_transform(data['Type'])\n",
        "data['Producers'] = le.fit_transform(data['Producers'])\n",
        "data['Duration'] = le.fit_transform(data['Duration'])\n",
        "data['Studios'] = le.fit_transform(data['Studios'])\n",
        "data['Rating'] = le.fit_transform(data['Rating'])\n",
        "data['MembersClass'] = le.fit_transform(data['MembersClass'])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "G5J5ldapgtBg",
        "outputId": "f396a365-48ef-4482-87e6-364aed586960"
      },
      "source": [
        "data.head(3)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Score</th>\n",
              "      <th>Genders</th>\n",
              "      <th>Type</th>\n",
              "      <th>Episodes</th>\n",
              "      <th>Producers</th>\n",
              "      <th>Studios</th>\n",
              "      <th>Source</th>\n",
              "      <th>Duration</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Members</th>\n",
              "      <th>Favorites</th>\n",
              "      <th>Watching</th>\n",
              "      <th>Completed</th>\n",
              "      <th>On-Hold</th>\n",
              "      <th>Dropped</th>\n",
              "      <th>Plan to Watch</th>\n",
              "      <th>Score-10</th>\n",
              "      <th>Score-9</th>\n",
              "      <th>Score-8</th>\n",
              "      <th>Score-7</th>\n",
              "      <th>Score-6</th>\n",
              "      <th>Score-5</th>\n",
              "      <th>Score-4</th>\n",
              "      <th>Score-3</th>\n",
              "      <th>Score-2</th>\n",
              "      <th>Score-1</th>\n",
              "      <th>Finished</th>\n",
              "      <th>Estreia</th>\n",
              "      <th>GendersList</th>\n",
              "      <th>StudiosList</th>\n",
              "      <th>members_log</th>\n",
              "      <th>Score-10/1</th>\n",
              "      <th>MembersClass</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Cowboy Bebop</td>\n",
              "      <td>0.944142</td>\n",
              "      <td>28</td>\n",
              "      <td>5</td>\n",
              "      <td>0.008181</td>\n",
              "      <td>473</td>\n",
              "      <td>772</td>\n",
              "      <td>10</td>\n",
              "      <td>155</td>\n",
              "      <td>4</td>\n",
              "      <td>0.483459</td>\n",
              "      <td>0.336956</td>\n",
              "      <td>0.119243</td>\n",
              "      <td>0.329041</td>\n",
              "      <td>0.380552</td>\n",
              "      <td>0.152699</td>\n",
              "      <td>329800.0</td>\n",
              "      <td>0.320601</td>\n",
              "      <td>0.340261</td>\n",
              "      <td>0.286693</td>\n",
              "      <td>0.205156</td>\n",
              "      <td>0.109786</td>\n",
              "      <td>0.071328</td>\n",
              "      <td>0.039222</td>\n",
              "      <td>0.030677</td>\n",
              "      <td>0.029168</td>\n",
              "      <td>0.046787</td>\n",
              "      <td>0.788462</td>\n",
              "      <td>0.778846</td>\n",
              "      <td>['Action', 'Adventure', 'Comedy', 'Drama', 'Sc...</td>\n",
              "      <td>['Sunrise']</td>\n",
              "      <td>6.097590</td>\n",
              "      <td>2.161501</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Cowboy Bebop: Tengoku no Tobira</td>\n",
              "      <td>0.891008</td>\n",
              "      <td>742</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2704</td>\n",
              "      <td>124</td>\n",
              "      <td>10</td>\n",
              "      <td>64</td>\n",
              "      <td>4</td>\n",
              "      <td>0.105469</td>\n",
              "      <td>0.006383</td>\n",
              "      <td>0.004669</td>\n",
              "      <td>0.095452</td>\n",
              "      <td>0.010297</td>\n",
              "      <td>0.004407</td>\n",
              "      <td>57964.0</td>\n",
              "      <td>0.042028</td>\n",
              "      <td>0.091919</td>\n",
              "      <td>0.107826</td>\n",
              "      <td>0.074490</td>\n",
              "      <td>0.030802</td>\n",
              "      <td>0.015030</td>\n",
              "      <td>0.007098</td>\n",
              "      <td>0.004977</td>\n",
              "      <td>0.004257</td>\n",
              "      <td>0.011200</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>['Action', 'Drama', 'Mystery', 'Sci-Fi', 'Space']</td>\n",
              "      <td>['Bones']</td>\n",
              "      <td>5.436393</td>\n",
              "      <td>1.899104</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Trigun</td>\n",
              "      <td>0.870572</td>\n",
              "      <td>1322</td>\n",
              "      <td>5</td>\n",
              "      <td>0.008181</td>\n",
              "      <td>3322</td>\n",
              "      <td>408</td>\n",
              "      <td>6</td>\n",
              "      <td>155</td>\n",
              "      <td>3</td>\n",
              "      <td>0.215824</td>\n",
              "      <td>0.070381</td>\n",
              "      <td>0.032810</td>\n",
              "      <td>0.157378</td>\n",
              "      <td>0.135511</td>\n",
              "      <td>0.079704</td>\n",
              "      <td>146918.0</td>\n",
              "      <td>0.070268</td>\n",
              "      <td>0.141336</td>\n",
              "      <td>0.187625</td>\n",
              "      <td>0.162703</td>\n",
              "      <td>0.081595</td>\n",
              "      <td>0.046764</td>\n",
              "      <td>0.024201</td>\n",
              "      <td>0.014999</td>\n",
              "      <td>0.012416</td>\n",
              "      <td>0.015763</td>\n",
              "      <td>0.778846</td>\n",
              "      <td>0.778846</td>\n",
              "      <td>['Action', 'Sci-Fi', 'Adventure', 'Comedy', 'D...</td>\n",
              "      <td>['Madhouse']</td>\n",
              "      <td>5.747344</td>\n",
              "      <td>1.974227</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              Name     Score  ...  Score-10/1  MembersClass\n",
              "0                     Cowboy Bebop  0.944142  ...    2.161501             5\n",
              "1  Cowboy Bebop: Tengoku no Tobira  0.891008  ...    1.899104             5\n",
              "2                           Trigun  0.870572  ...    1.974227             5\n",
              "\n",
              "[3 rows x 34 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwP-QRMSjPvC"
      },
      "source": [
        "data = data.drop(columns=['Name','GendersList', 'StudiosList'])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "Ztzk9odMkHfS",
        "outputId": "8fe90cae-d8de-4f2f-eb83-e259db253206"
      },
      "source": [
        "data.head(3)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Score</th>\n",
              "      <th>Genders</th>\n",
              "      <th>Type</th>\n",
              "      <th>Episodes</th>\n",
              "      <th>Producers</th>\n",
              "      <th>Studios</th>\n",
              "      <th>Source</th>\n",
              "      <th>Duration</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Members</th>\n",
              "      <th>Favorites</th>\n",
              "      <th>Watching</th>\n",
              "      <th>Completed</th>\n",
              "      <th>On-Hold</th>\n",
              "      <th>Dropped</th>\n",
              "      <th>Plan to Watch</th>\n",
              "      <th>Score-10</th>\n",
              "      <th>Score-9</th>\n",
              "      <th>Score-8</th>\n",
              "      <th>Score-7</th>\n",
              "      <th>Score-6</th>\n",
              "      <th>Score-5</th>\n",
              "      <th>Score-4</th>\n",
              "      <th>Score-3</th>\n",
              "      <th>Score-2</th>\n",
              "      <th>Score-1</th>\n",
              "      <th>Finished</th>\n",
              "      <th>Estreia</th>\n",
              "      <th>members_log</th>\n",
              "      <th>Score-10/1</th>\n",
              "      <th>MembersClass</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.944142</td>\n",
              "      <td>28</td>\n",
              "      <td>5</td>\n",
              "      <td>0.008181</td>\n",
              "      <td>473</td>\n",
              "      <td>772</td>\n",
              "      <td>10</td>\n",
              "      <td>155</td>\n",
              "      <td>4</td>\n",
              "      <td>0.483459</td>\n",
              "      <td>0.336956</td>\n",
              "      <td>0.119243</td>\n",
              "      <td>0.329041</td>\n",
              "      <td>0.380552</td>\n",
              "      <td>0.152699</td>\n",
              "      <td>329800.0</td>\n",
              "      <td>0.320601</td>\n",
              "      <td>0.340261</td>\n",
              "      <td>0.286693</td>\n",
              "      <td>0.205156</td>\n",
              "      <td>0.109786</td>\n",
              "      <td>0.071328</td>\n",
              "      <td>0.039222</td>\n",
              "      <td>0.030677</td>\n",
              "      <td>0.029168</td>\n",
              "      <td>0.046787</td>\n",
              "      <td>0.788462</td>\n",
              "      <td>0.778846</td>\n",
              "      <td>6.097590</td>\n",
              "      <td>2.161501</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.891008</td>\n",
              "      <td>742</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2704</td>\n",
              "      <td>124</td>\n",
              "      <td>10</td>\n",
              "      <td>64</td>\n",
              "      <td>4</td>\n",
              "      <td>0.105469</td>\n",
              "      <td>0.006383</td>\n",
              "      <td>0.004669</td>\n",
              "      <td>0.095452</td>\n",
              "      <td>0.010297</td>\n",
              "      <td>0.004407</td>\n",
              "      <td>57964.0</td>\n",
              "      <td>0.042028</td>\n",
              "      <td>0.091919</td>\n",
              "      <td>0.107826</td>\n",
              "      <td>0.074490</td>\n",
              "      <td>0.030802</td>\n",
              "      <td>0.015030</td>\n",
              "      <td>0.007098</td>\n",
              "      <td>0.004977</td>\n",
              "      <td>0.004257</td>\n",
              "      <td>0.011200</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>5.436393</td>\n",
              "      <td>1.899104</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.870572</td>\n",
              "      <td>1322</td>\n",
              "      <td>5</td>\n",
              "      <td>0.008181</td>\n",
              "      <td>3322</td>\n",
              "      <td>408</td>\n",
              "      <td>6</td>\n",
              "      <td>155</td>\n",
              "      <td>3</td>\n",
              "      <td>0.215824</td>\n",
              "      <td>0.070381</td>\n",
              "      <td>0.032810</td>\n",
              "      <td>0.157378</td>\n",
              "      <td>0.135511</td>\n",
              "      <td>0.079704</td>\n",
              "      <td>146918.0</td>\n",
              "      <td>0.070268</td>\n",
              "      <td>0.141336</td>\n",
              "      <td>0.187625</td>\n",
              "      <td>0.162703</td>\n",
              "      <td>0.081595</td>\n",
              "      <td>0.046764</td>\n",
              "      <td>0.024201</td>\n",
              "      <td>0.014999</td>\n",
              "      <td>0.012416</td>\n",
              "      <td>0.015763</td>\n",
              "      <td>0.778846</td>\n",
              "      <td>0.778846</td>\n",
              "      <td>5.747344</td>\n",
              "      <td>1.974227</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Score  Genders  Type  ...  members_log  Score-10/1  MembersClass\n",
              "0  0.944142       28     5  ...     6.097590    2.161501             5\n",
              "1  0.891008      742     0  ...     5.436393    1.899104             5\n",
              "2  0.870572     1322     5  ...     5.747344    1.974227             5\n",
              "\n",
              "[3 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPMVq8YOK1Lu",
        "outputId": "f712cefe-8ea6-4b71-d742-2cc5bc8dcc91"
      },
      "source": [
        "y = data['Score']\n",
        "x = data.copy()\n",
        "print(y)\n",
        "x = x.drop(columns=['Score','members_log','Score-10/1','MembersClass','Score-10','Score-9','Score-8','Score-7','Score-6','Score-5','Score-4','Score-3','Score-2','Score-1',])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0        0.944142\n",
            "1        0.891008\n",
            "2        0.870572\n",
            "3        0.738420\n",
            "4        0.698910\n",
            "           ...   \n",
            "12416    0.645777\n",
            "12417    0.772480\n",
            "12418    0.678474\n",
            "12419    0.403270\n",
            "12420    0.636240\n",
            "Name: Score, Length: 12421, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "T3uTWovpK1Lv",
        "outputId": "ab4ae1bc-883a-47b4-cde5-9cdfcdc97649"
      },
      "source": [
        "x.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Genders</th>\n",
              "      <th>Type</th>\n",
              "      <th>Episodes</th>\n",
              "      <th>Producers</th>\n",
              "      <th>Studios</th>\n",
              "      <th>Source</th>\n",
              "      <th>Duration</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Members</th>\n",
              "      <th>Favorites</th>\n",
              "      <th>Watching</th>\n",
              "      <th>Completed</th>\n",
              "      <th>On-Hold</th>\n",
              "      <th>Dropped</th>\n",
              "      <th>Plan to Watch</th>\n",
              "      <th>Finished</th>\n",
              "      <th>Estreia</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>28</td>\n",
              "      <td>5</td>\n",
              "      <td>0.008181</td>\n",
              "      <td>473</td>\n",
              "      <td>772</td>\n",
              "      <td>10</td>\n",
              "      <td>155</td>\n",
              "      <td>4</td>\n",
              "      <td>0.483459</td>\n",
              "      <td>0.336956</td>\n",
              "      <td>0.119243</td>\n",
              "      <td>0.329041</td>\n",
              "      <td>0.380552</td>\n",
              "      <td>0.152699</td>\n",
              "      <td>329800.0</td>\n",
              "      <td>0.788462</td>\n",
              "      <td>0.778846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>742</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2704</td>\n",
              "      <td>124</td>\n",
              "      <td>10</td>\n",
              "      <td>64</td>\n",
              "      <td>4</td>\n",
              "      <td>0.105469</td>\n",
              "      <td>0.006383</td>\n",
              "      <td>0.004669</td>\n",
              "      <td>0.095452</td>\n",
              "      <td>0.010297</td>\n",
              "      <td>0.004407</td>\n",
              "      <td>57964.0</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>0.807692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1322</td>\n",
              "      <td>5</td>\n",
              "      <td>0.008181</td>\n",
              "      <td>3322</td>\n",
              "      <td>408</td>\n",
              "      <td>6</td>\n",
              "      <td>155</td>\n",
              "      <td>3</td>\n",
              "      <td>0.215824</td>\n",
              "      <td>0.070381</td>\n",
              "      <td>0.032810</td>\n",
              "      <td>0.157378</td>\n",
              "      <td>0.135511</td>\n",
              "      <td>0.079704</td>\n",
              "      <td>146918.0</td>\n",
              "      <td>0.778846</td>\n",
              "      <td>0.778846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1243</td>\n",
              "      <td>5</td>\n",
              "      <td>0.008181</td>\n",
              "      <td>2877</td>\n",
              "      <td>772</td>\n",
              "      <td>10</td>\n",
              "      <td>158</td>\n",
              "      <td>3</td>\n",
              "      <td>0.036552</td>\n",
              "      <td>0.003192</td>\n",
              "      <td>0.004846</td>\n",
              "      <td>0.021152</td>\n",
              "      <td>0.027251</td>\n",
              "      <td>0.030782</td>\n",
              "      <td>33719.0</td>\n",
              "      <td>0.817308</td>\n",
              "      <td>0.817308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1946</td>\n",
              "      <td>5</td>\n",
              "      <td>0.016688</td>\n",
              "      <td>2889</td>\n",
              "      <td>849</td>\n",
              "      <td>6</td>\n",
              "      <td>152</td>\n",
              "      <td>2</td>\n",
              "      <td>0.005094</td>\n",
              "      <td>0.000098</td>\n",
              "      <td>0.000724</td>\n",
              "      <td>0.003351</td>\n",
              "      <td>0.004076</td>\n",
              "      <td>0.006342</td>\n",
              "      <td>3394.0</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.836538</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Genders  Type  Episodes  ...  Plan to Watch  Finished   Estreia\n",
              "0       28     5  0.008181  ...       329800.0  0.788462  0.778846\n",
              "1      742     0  0.000000  ...        57964.0  0.807692  0.807692\n",
              "2     1322     5  0.008181  ...       146918.0  0.778846  0.778846\n",
              "3     1243     5  0.008181  ...        33719.0  0.817308  0.817308\n",
              "4     1946     5  0.016688  ...         3394.0  0.846154  0.836538\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-kuSevjCO-j"
      },
      "source": [
        "x['Genders'] = (x['Genders'] - x['Genders'].min()) / (x['Genders'].max() - x['Genders'].min())\n",
        "x['Type'] = (x['Type'] - x['Type'].min()) / (x['Type'].max() - x['Type'].min())\n",
        "x['Producers'] = (x['Producers'] - x['Producers'].min()) / (x['Producers'].max() - x['Producers'].min())\n",
        "x['Studios'] = (x['Studios'] - x['Studios'].min()) / (x['Studios'].max() - x['Studios'].min())\n",
        "x['Source'] = (x['Source'] - x['Source'].min()) / (x['Source'].max() - x['Source'].min())\n",
        "x['Duration'] = (x['Duration'] - x['Duration'].min()) / (x['Duration'].max() - x['Duration'].min())\n",
        "x['Rating'] = (x['Rating'] - x['Rating'].min()) / (x['Rating'].max() - x['Rating'].min())\n",
        "x['Plan to Watch'] = (x['Plan to Watch'] - x['Plan to Watch'].min()) / (x['Plan to Watch'].max() - x['Plan to Watch'].min())"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5N0Woof69Tlm",
        "outputId": "c9a27869-924c-45cd-b7c9-b7286fd9acec"
      },
      "source": [
        "data.isnull().sum()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Score            0\n",
              "Genders          0\n",
              "Type             0\n",
              "Episodes         0\n",
              "Producers        0\n",
              "Studios          0\n",
              "Source           0\n",
              "Duration         0\n",
              "Rating           0\n",
              "Members          0\n",
              "Favorites        0\n",
              "Watching         0\n",
              "Completed        0\n",
              "On-Hold          0\n",
              "Dropped          0\n",
              "Plan to Watch    0\n",
              "Score-10         0\n",
              "Score-9          0\n",
              "Score-8          0\n",
              "Score-7          0\n",
              "Score-6          0\n",
              "Score-5          0\n",
              "Score-4          0\n",
              "Score-3          0\n",
              "Score-2          0\n",
              "Score-1          0\n",
              "Finished         0\n",
              "Estreia          0\n",
              "members_log      0\n",
              "Score-10/1       0\n",
              "MembersClass     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRlxGgzx_vVu",
        "outputId": "4aa0e7c9-4ed9-4d19-d209-5c860efa5777"
      },
      "source": [
        "print(x.to_numpy)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method DataFrame.to_numpy of         Genders  Type  Episodes  ...  Plan to Watch  Finished   Estreia\n",
            "0      0.006295   1.0  0.008181  ...       0.775025  0.788462  0.778846\n",
            "1      0.166817   0.0  0.000000  ...       0.136191  0.807692  0.807692\n",
            "2      0.297212   1.0  0.008181  ...       0.345240  0.778846  0.778846\n",
            "3      0.279451   1.0  0.008181  ...       0.079214  0.817308  0.817308\n",
            "4      0.437500   1.0  0.016688  ...       0.007948  0.846154  0.836538\n",
            "...         ...   ...       ...  ...            ...       ...       ...\n",
            "12416  0.477068   0.4  0.000982  ...       0.024380  1.000000  1.000000\n",
            "12417  0.831610   0.2  0.000000  ...       0.000576  1.000000  1.000000\n",
            "12418  0.941772   0.8  0.000000  ...       0.000679  1.000000  1.000000\n",
            "12419  0.857914   0.8  0.000000  ...       0.007892  1.000000  1.000000\n",
            "12420  0.604541   0.8  0.000000  ...       0.006256  1.000000  1.000000\n",
            "\n",
            "[12421 rows x 17 columns]>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yu2Ad7daFu2P"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=2020)\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=2020)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "hQzi7ROjdIE7",
        "outputId": "67a8a953-f819-4cfa-f872-226ea14436bd"
      },
      "source": [
        "data.head(1864)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Score</th>\n",
              "      <th>Genders</th>\n",
              "      <th>Type</th>\n",
              "      <th>Episodes</th>\n",
              "      <th>Producers</th>\n",
              "      <th>Studios</th>\n",
              "      <th>Source</th>\n",
              "      <th>Duration</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Members</th>\n",
              "      <th>Favorites</th>\n",
              "      <th>Watching</th>\n",
              "      <th>Completed</th>\n",
              "      <th>On-Hold</th>\n",
              "      <th>Dropped</th>\n",
              "      <th>Plan to Watch</th>\n",
              "      <th>Score-10</th>\n",
              "      <th>Score-9</th>\n",
              "      <th>Score-8</th>\n",
              "      <th>Score-7</th>\n",
              "      <th>Score-6</th>\n",
              "      <th>Score-5</th>\n",
              "      <th>Score-4</th>\n",
              "      <th>Score-3</th>\n",
              "      <th>Score-2</th>\n",
              "      <th>Score-1</th>\n",
              "      <th>Finished</th>\n",
              "      <th>Estreia</th>\n",
              "      <th>members_log</th>\n",
              "      <th>Score-10/1</th>\n",
              "      <th>MembersClass</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.944142</td>\n",
              "      <td>28</td>\n",
              "      <td>5</td>\n",
              "      <td>0.008181</td>\n",
              "      <td>473</td>\n",
              "      <td>772</td>\n",
              "      <td>10</td>\n",
              "      <td>155</td>\n",
              "      <td>4</td>\n",
              "      <td>0.483459</td>\n",
              "      <td>0.336956</td>\n",
              "      <td>0.119243</td>\n",
              "      <td>0.329041</td>\n",
              "      <td>0.380552</td>\n",
              "      <td>0.152699</td>\n",
              "      <td>329800.0</td>\n",
              "      <td>0.320601</td>\n",
              "      <td>0.340261</td>\n",
              "      <td>0.286693</td>\n",
              "      <td>0.205156</td>\n",
              "      <td>0.109786</td>\n",
              "      <td>0.071328</td>\n",
              "      <td>0.039222</td>\n",
              "      <td>0.030677</td>\n",
              "      <td>0.029168</td>\n",
              "      <td>0.046787</td>\n",
              "      <td>0.788462</td>\n",
              "      <td>0.778846</td>\n",
              "      <td>6.097590</td>\n",
              "      <td>2.161501</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.891008</td>\n",
              "      <td>742</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2704</td>\n",
              "      <td>124</td>\n",
              "      <td>10</td>\n",
              "      <td>64</td>\n",
              "      <td>4</td>\n",
              "      <td>0.105469</td>\n",
              "      <td>0.006383</td>\n",
              "      <td>0.004669</td>\n",
              "      <td>0.095452</td>\n",
              "      <td>0.010297</td>\n",
              "      <td>0.004407</td>\n",
              "      <td>57964.0</td>\n",
              "      <td>0.042028</td>\n",
              "      <td>0.091919</td>\n",
              "      <td>0.107826</td>\n",
              "      <td>0.074490</td>\n",
              "      <td>0.030802</td>\n",
              "      <td>0.015030</td>\n",
              "      <td>0.007098</td>\n",
              "      <td>0.004977</td>\n",
              "      <td>0.004257</td>\n",
              "      <td>0.011200</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>5.436393</td>\n",
              "      <td>1.899104</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.870572</td>\n",
              "      <td>1322</td>\n",
              "      <td>5</td>\n",
              "      <td>0.008181</td>\n",
              "      <td>3322</td>\n",
              "      <td>408</td>\n",
              "      <td>6</td>\n",
              "      <td>155</td>\n",
              "      <td>3</td>\n",
              "      <td>0.215824</td>\n",
              "      <td>0.070381</td>\n",
              "      <td>0.032810</td>\n",
              "      <td>0.157378</td>\n",
              "      <td>0.135511</td>\n",
              "      <td>0.079704</td>\n",
              "      <td>146918.0</td>\n",
              "      <td>0.070268</td>\n",
              "      <td>0.141336</td>\n",
              "      <td>0.187625</td>\n",
              "      <td>0.162703</td>\n",
              "      <td>0.081595</td>\n",
              "      <td>0.046764</td>\n",
              "      <td>0.024201</td>\n",
              "      <td>0.014999</td>\n",
              "      <td>0.012416</td>\n",
              "      <td>0.015763</td>\n",
              "      <td>0.778846</td>\n",
              "      <td>0.778846</td>\n",
              "      <td>5.747344</td>\n",
              "      <td>1.974227</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.738420</td>\n",
              "      <td>1243</td>\n",
              "      <td>5</td>\n",
              "      <td>0.008181</td>\n",
              "      <td>2877</td>\n",
              "      <td>772</td>\n",
              "      <td>10</td>\n",
              "      <td>158</td>\n",
              "      <td>3</td>\n",
              "      <td>0.036552</td>\n",
              "      <td>0.003192</td>\n",
              "      <td>0.004846</td>\n",
              "      <td>0.021152</td>\n",
              "      <td>0.027251</td>\n",
              "      <td>0.030782</td>\n",
              "      <td>33719.0</td>\n",
              "      <td>0.003051</td>\n",
              "      <td>0.008977</td>\n",
              "      <td>0.022058</td>\n",
              "      <td>0.038237</td>\n",
              "      <td>0.030292</td>\n",
              "      <td>0.023386</td>\n",
              "      <td>0.013333</td>\n",
              "      <td>0.007963</td>\n",
              "      <td>0.006425</td>\n",
              "      <td>0.003852</td>\n",
              "      <td>0.817308</td>\n",
              "      <td>0.817308</td>\n",
              "      <td>4.976272</td>\n",
              "      <td>1.221583</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.698910</td>\n",
              "      <td>1946</td>\n",
              "      <td>5</td>\n",
              "      <td>0.016688</td>\n",
              "      <td>2889</td>\n",
              "      <td>849</td>\n",
              "      <td>6</td>\n",
              "      <td>152</td>\n",
              "      <td>2</td>\n",
              "      <td>0.005094</td>\n",
              "      <td>0.000098</td>\n",
              "      <td>0.000724</td>\n",
              "      <td>0.003351</td>\n",
              "      <td>0.004076</td>\n",
              "      <td>0.006342</td>\n",
              "      <td>3394.0</td>\n",
              "      <td>0.000435</td>\n",
              "      <td>0.000986</td>\n",
              "      <td>0.002703</td>\n",
              "      <td>0.005635</td>\n",
              "      <td>0.005663</td>\n",
              "      <td>0.005071</td>\n",
              "      <td>0.003253</td>\n",
              "      <td>0.001855</td>\n",
              "      <td>0.001931</td>\n",
              "      <td>0.000770</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.836538</td>\n",
              "      <td>4.121363</td>\n",
              "      <td>1.062791</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1859</th>\n",
              "      <td>0.726158</td>\n",
              "      <td>87</td>\n",
              "      <td>5</td>\n",
              "      <td>0.023560</td>\n",
              "      <td>1870</td>\n",
              "      <td>860</td>\n",
              "      <td>6</td>\n",
              "      <td>158</td>\n",
              "      <td>3</td>\n",
              "      <td>0.005598</td>\n",
              "      <td>0.000359</td>\n",
              "      <td>0.001011</td>\n",
              "      <td>0.003070</td>\n",
              "      <td>0.005114</td>\n",
              "      <td>0.005512</td>\n",
              "      <td>5007.0</td>\n",
              "      <td>0.000455</td>\n",
              "      <td>0.001057</td>\n",
              "      <td>0.002561</td>\n",
              "      <td>0.006129</td>\n",
              "      <td>0.005365</td>\n",
              "      <td>0.003317</td>\n",
              "      <td>0.001331</td>\n",
              "      <td>0.000792</td>\n",
              "      <td>0.000709</td>\n",
              "      <td>0.000267</td>\n",
              "      <td>0.653846</td>\n",
              "      <td>0.634615</td>\n",
              "      <td>4.162236</td>\n",
              "      <td>1.513218</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1860</th>\n",
              "      <td>0.719346</td>\n",
              "      <td>2351</td>\n",
              "      <td>5</td>\n",
              "      <td>0.016688</td>\n",
              "      <td>1511</td>\n",
              "      <td>737</td>\n",
              "      <td>10</td>\n",
              "      <td>155</td>\n",
              "      <td>0</td>\n",
              "      <td>0.003997</td>\n",
              "      <td>0.000652</td>\n",
              "      <td>0.001100</td>\n",
              "      <td>0.001513</td>\n",
              "      <td>0.004060</td>\n",
              "      <td>0.003062</td>\n",
              "      <td>4806.0</td>\n",
              "      <td>0.000309</td>\n",
              "      <td>0.000572</td>\n",
              "      <td>0.001311</td>\n",
              "      <td>0.002801</td>\n",
              "      <td>0.002728</td>\n",
              "      <td>0.002235</td>\n",
              "      <td>0.000715</td>\n",
              "      <td>0.000837</td>\n",
              "      <td>0.000670</td>\n",
              "      <td>0.000356</td>\n",
              "      <td>0.644231</td>\n",
              "      <td>0.634615</td>\n",
              "      <td>4.016281</td>\n",
              "      <td>1.232410</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1861</th>\n",
              "      <td>0.598093</td>\n",
              "      <td>2353</td>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1870</td>\n",
              "      <td>737</td>\n",
              "      <td>10</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000389</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000045</td>\n",
              "      <td>0.000197</td>\n",
              "      <td>0.000112</td>\n",
              "      <td>0.000286</td>\n",
              "      <td>498.0</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>0.000050</td>\n",
              "      <td>0.000197</td>\n",
              "      <td>0.000425</td>\n",
              "      <td>0.000304</td>\n",
              "      <td>0.000160</td>\n",
              "      <td>0.000204</td>\n",
              "      <td>0.000118</td>\n",
              "      <td>0.000059</td>\n",
              "      <td>0.644231</td>\n",
              "      <td>0.644231</td>\n",
              "      <td>3.016616</td>\n",
              "      <td>0.823909</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1862</th>\n",
              "      <td>0.604905</td>\n",
              "      <td>2353</td>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1870</td>\n",
              "      <td>737</td>\n",
              "      <td>7</td>\n",
              "      <td>275</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000361</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000037</td>\n",
              "      <td>0.000183</td>\n",
              "      <td>0.000122</td>\n",
              "      <td>0.000280</td>\n",
              "      <td>463.0</td>\n",
              "      <td>0.000029</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>0.000057</td>\n",
              "      <td>0.000194</td>\n",
              "      <td>0.000361</td>\n",
              "      <td>0.000224</td>\n",
              "      <td>0.000185</td>\n",
              "      <td>0.000090</td>\n",
              "      <td>0.000118</td>\n",
              "      <td>0.000148</td>\n",
              "      <td>0.653846</td>\n",
              "      <td>0.653846</td>\n",
              "      <td>2.985875</td>\n",
              "      <td>0.564271</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1863</th>\n",
              "      <td>0.618529</td>\n",
              "      <td>3078</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1870</td>\n",
              "      <td>458</td>\n",
              "      <td>7</td>\n",
              "      <td>289</td>\n",
              "      <td>0</td>\n",
              "      <td>0.001322</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>0.000046</td>\n",
              "      <td>0.001193</td>\n",
              "      <td>0.000096</td>\n",
              "      <td>0.000303</td>\n",
              "      <td>740.0</td>\n",
              "      <td>0.000101</td>\n",
              "      <td>0.000187</td>\n",
              "      <td>0.000590</td>\n",
              "      <td>0.001698</td>\n",
              "      <td>0.002346</td>\n",
              "      <td>0.002203</td>\n",
              "      <td>0.001257</td>\n",
              "      <td>0.001290</td>\n",
              "      <td>0.000985</td>\n",
              "      <td>0.000830</td>\n",
              "      <td>0.451923</td>\n",
              "      <td>0.451923</td>\n",
              "      <td>3.538448</td>\n",
              "      <td>0.400925</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1864 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         Score  Genders  Type  ...  members_log  Score-10/1  MembersClass\n",
              "0     0.944142       28     5  ...     6.097590    2.161501             5\n",
              "1     0.891008      742     0  ...     5.436393    1.899104             5\n",
              "2     0.870572     1322     5  ...     5.747344    1.974227             5\n",
              "3     0.738420     1243     5  ...     4.976272    1.221583             5\n",
              "4     0.698910     1946     5  ...     4.121363    1.062791             4\n",
              "...        ...      ...   ...  ...          ...         ...           ...\n",
              "1859  0.726158       87     5  ...     4.162236    1.513218             4\n",
              "1860  0.719346     2351     5  ...     4.016281    1.232410             4\n",
              "1861  0.598093     2353     3  ...     3.016616    0.823909             1\n",
              "1862  0.604905     2353     3  ...     2.985875    0.564271             1\n",
              "1863  0.618529     3078     0  ...     3.538448    0.400925             0\n",
              "\n",
              "[1864 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KHVWIB6eROa"
      },
      "source": [
        "# **Métricas**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBUs56CENHiG"
      },
      "source": [
        "def eval_metrics(actual, pred):\n",
        "    mse = np.sqrt(mean_squared_error(actual, pred))\n",
        "    mae = mean_absolute_error(actual, pred)\n",
        "    r2 = r2_score(actual, pred)\n",
        "    return mse, mae, r2"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3mgMFmCchIK"
      },
      "source": [
        "#**KNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPxmGz9UVnP_",
        "outputId": "6ced76f2-fc03-468b-e9c5-db6ababfa091"
      },
      "source": [
        "def knnreg(trial):\n",
        "\n",
        "  with mlflow.start_run(run_name=\"Knn\"):\n",
        "\n",
        "    n_neighbors = trial.suggest_int('n_neighbors', 3,100)\n",
        "    p = trial.suggest_int('p', 1,2)\n",
        "    metric = trial.suggest_categorical('metric', ['euclidean', 'l2','manhattan','cityblock','l1', 'chebyshev','minkowski'])\n",
        "\n",
        "    neigh = KNeighborsRegressor(n_neighbors = n_neighbors,p=p,metric=metric)\n",
        "    neigh.fit(X_train, y_train)\n",
        "\n",
        "    y_pred_val = neigh.predict(X_val)\n",
        "\n",
        "    (mse, mae, r2) = eval_metrics(y_val, y_pred_val)\n",
        "    \n",
        "    mlflow.log_param(\"n_neighbors\", n_neighbors)\n",
        "    mlflow.log_param(\"p\", p)\n",
        "    mlflow.log_param(\"metric\", metric)\n",
        "\n",
        "    mlflow.log_metric(\"mse\", mse)\n",
        "    mlflow.log_metric(\"mae\", mae)\n",
        "    mlflow.log_metric(\"r2\", r2)\n",
        "    #mlflow.log_metric(\"nomemetrica\", nomevariavel)\n",
        "    #mlflow.log_metric(\"nomemetrica\", nomevariavel)\n",
        "\n",
        "    return mean_squared_error(y_val, y_pred_val)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "study_knn = optuna.create_study(direction='minimize')\n",
        "study_knn.optimize(knnreg,n_trials=200)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 01:44:43,846]\u001b[0m A new study created in memory with name: no-name-0c007e3b-bfc2-42c0-b6c6-87424a907f6d\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:44:44,474]\u001b[0m Trial 0 finished with value: 0.006867490919306953 and parameters: {'n_neighbors': 32, 'p': 1, 'metric': 'manhattan'}. Best is trial 0 with value: 0.006867490919306953.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:44:44,981]\u001b[0m Trial 1 finished with value: 0.008181921182593593 and parameters: {'n_neighbors': 45, 'p': 2, 'metric': 'l2'}. Best is trial 0 with value: 0.006867490919306953.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:44:45,375]\u001b[0m Trial 2 finished with value: 0.008444466577214186 and parameters: {'n_neighbors': 80, 'p': 2, 'metric': 'minkowski'}. Best is trial 0 with value: 0.006867490919306953.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:44:45,874]\u001b[0m Trial 3 finished with value: 0.007224888673952601 and parameters: {'n_neighbors': 66, 'p': 2, 'metric': 'cityblock'}. Best is trial 0 with value: 0.006867490919306953.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:44:46,260]\u001b[0m Trial 4 finished with value: 0.008176764607436333 and parameters: {'n_neighbors': 44, 'p': 1, 'metric': 'euclidean'}. Best is trial 0 with value: 0.006867490919306953.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:44:46,746]\u001b[0m Trial 5 finished with value: 0.00716980575461812 and parameters: {'n_neighbors': 57, 'p': 1, 'metric': 'minkowski'}. Best is trial 0 with value: 0.006867490919306953.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:44:47,147]\u001b[0m Trial 6 finished with value: 0.00840179963843037 and parameters: {'n_neighbors': 72, 'p': 1, 'metric': 'euclidean'}. Best is trial 0 with value: 0.006867490919306953.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:44:47,537]\u001b[0m Trial 7 finished with value: 0.008224340331346154 and parameters: {'n_neighbors': 49, 'p': 2, 'metric': 'euclidean'}. Best is trial 0 with value: 0.006867490919306953.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:44:48,071]\u001b[0m Trial 8 finished with value: 0.008437249429364371 and parameters: {'n_neighbors': 76, 'p': 2, 'metric': 'l2'}. Best is trial 0 with value: 0.006867490919306953.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:44:48,464]\u001b[0m Trial 9 finished with value: 0.00830635539949247 and parameters: {'n_neighbors': 60, 'p': 1, 'metric': 'euclidean'}. Best is trial 0 with value: 0.006867490919306953.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:44:48,954]\u001b[0m Trial 10 finished with value: 0.006696527274955836 and parameters: {'n_neighbors': 13, 'p': 1, 'metric': 'manhattan'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:44:49,431]\u001b[0m Trial 11 finished with value: 0.006750566122594909 and parameters: {'n_neighbors': 8, 'p': 1, 'metric': 'manhattan'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:44:49,909]\u001b[0m Trial 12 finished with value: 0.006843220602273169 and parameters: {'n_neighbors': 5, 'p': 1, 'metric': 'manhattan'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:44:50,381]\u001b[0m Trial 13 finished with value: 0.009361287494757835 and parameters: {'n_neighbors': 4, 'p': 1, 'metric': 'chebyshev'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:44:50,859]\u001b[0m Trial 14 finished with value: 0.006764857418988586 and parameters: {'n_neighbors': 21, 'p': 1, 'metric': 'l1'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:44:51,347]\u001b[0m Trial 15 finished with value: 0.006798025444851704 and parameters: {'n_neighbors': 25, 'p': 1, 'metric': 'manhattan'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:44:51,824]\u001b[0m Trial 16 finished with value: 0.006701798792357302 and parameters: {'n_neighbors': 12, 'p': 1, 'metric': 'manhattan'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:44:52,331]\u001b[0m Trial 17 finished with value: 0.00747576022615584 and parameters: {'n_neighbors': 94, 'p': 1, 'metric': 'manhattan'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:44:52,815]\u001b[0m Trial 18 finished with value: 0.0068064021318210936 and parameters: {'n_neighbors': 17, 'p': 1, 'metric': 'cityblock'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:44:53,311]\u001b[0m Trial 19 finished with value: 0.006867490919306953 and parameters: {'n_neighbors': 32, 'p': 1, 'metric': 'l1'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:44:53,775]\u001b[0m Trial 20 finished with value: 0.009038477797027338 and parameters: {'n_neighbors': 15, 'p': 2, 'metric': 'chebyshev'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:44:54,260]\u001b[0m Trial 21 finished with value: 0.006713741143852452 and parameters: {'n_neighbors': 11, 'p': 1, 'metric': 'manhattan'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:44:54,736]\u001b[0m Trial 22 finished with value: 0.006919841452298125 and parameters: {'n_neighbors': 36, 'p': 1, 'metric': 'manhattan'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:44:55,235]\u001b[0m Trial 23 finished with value: 0.006696527274955836 and parameters: {'n_neighbors': 13, 'p': 1, 'metric': 'manhattan'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:44:55,713]\u001b[0m Trial 24 finished with value: 0.006798025444851704 and parameters: {'n_neighbors': 25, 'p': 1, 'metric': 'manhattan'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:44:56,195]\u001b[0m Trial 25 finished with value: 0.006789163577813481 and parameters: {'n_neighbors': 18, 'p': 1, 'metric': 'manhattan'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:44:56,691]\u001b[0m Trial 26 finished with value: 0.006943774040214436 and parameters: {'n_neighbors': 38, 'p': 1, 'metric': 'manhattan'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:44:57,168]\u001b[0m Trial 27 finished with value: 0.006813330192586285 and parameters: {'n_neighbors': 26, 'p': 1, 'metric': 'manhattan'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:44:57,654]\u001b[0m Trial 28 finished with value: 0.006713741143852452 and parameters: {'n_neighbors': 11, 'p': 1, 'metric': 'cityblock'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:44:58,146]\u001b[0m Trial 29 finished with value: 0.006877677972568981 and parameters: {'n_neighbors': 31, 'p': 1, 'metric': 'manhattan'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:44:58,529]\u001b[0m Trial 30 finished with value: 0.007145084493080411 and parameters: {'n_neighbors': 3, 'p': 1, 'metric': 'l1'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:44:59,003]\u001b[0m Trial 31 finished with value: 0.006696527274955836 and parameters: {'n_neighbors': 13, 'p': 1, 'metric': 'cityblock'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:44:59,488]\u001b[0m Trial 32 finished with value: 0.006725767552676035 and parameters: {'n_neighbors': 14, 'p': 1, 'metric': 'cityblock'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:44:59,976]\u001b[0m Trial 33 finished with value: 0.007796114930112774 and parameters: {'n_neighbors': 22, 'p': 1, 'metric': 'l2'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:00,456]\u001b[0m Trial 34 finished with value: 0.006713741143852452 and parameters: {'n_neighbors': 11, 'p': 2, 'metric': 'cityblock'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:00,935]\u001b[0m Trial 35 finished with value: 0.006842832820092017 and parameters: {'n_neighbors': 28, 'p': 1, 'metric': 'minkowski'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:01,433]\u001b[0m Trial 36 finished with value: 0.0069869143636527315 and parameters: {'n_neighbors': 42, 'p': 1, 'metric': 'cityblock'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:01,901]\u001b[0m Trial 37 finished with value: 0.008898259486895611 and parameters: {'n_neighbors': 19, 'p': 2, 'metric': 'chebyshev'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:02,411]\u001b[0m Trial 38 finished with value: 0.008538375327389094 and parameters: {'n_neighbors': 89, 'p': 1, 'metric': 'l2'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:02,885]\u001b[0m Trial 39 finished with value: 0.006750566122594909 and parameters: {'n_neighbors': 8, 'p': 1, 'metric': 'minkowski'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:03,368]\u001b[0m Trial 40 finished with value: 0.007135254484415019 and parameters: {'n_neighbors': 55, 'p': 1, 'metric': 'manhattan'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:03,847]\u001b[0m Trial 41 finished with value: 0.006701798792357302 and parameters: {'n_neighbors': 12, 'p': 1, 'metric': 'manhattan'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:04,326]\u001b[0m Trial 42 finished with value: 0.006725767552676035 and parameters: {'n_neighbors': 14, 'p': 1, 'metric': 'manhattan'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:04,813]\u001b[0m Trial 43 finished with value: 0.006764857418988586 and parameters: {'n_neighbors': 21, 'p': 1, 'metric': 'manhattan'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:05,200]\u001b[0m Trial 44 finished with value: 0.00787085869316927 and parameters: {'n_neighbors': 8, 'p': 1, 'metric': 'euclidean'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:05,588]\u001b[0m Trial 45 finished with value: 0.007145084493080411 and parameters: {'n_neighbors': 3, 'p': 1, 'metric': 'manhattan'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:06,077]\u001b[0m Trial 46 finished with value: 0.007228902927762371 and parameters: {'n_neighbors': 67, 'p': 1, 'metric': 'cityblock'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:06,560]\u001b[0m Trial 47 finished with value: 0.006856364325103977 and parameters: {'n_neighbors': 30, 'p': 2, 'metric': 'manhattan'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:07,049]\u001b[0m Trial 48 finished with value: 0.006777831832275792 and parameters: {'n_neighbors': 9, 'p': 1, 'metric': 'minkowski'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:07,547]\u001b[0m Trial 49 finished with value: 0.00821739598860798 and parameters: {'n_neighbors': 48, 'p': 1, 'metric': 'l2'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:07,928]\u001b[0m Trial 50 finished with value: 0.007818895549741212 and parameters: {'n_neighbors': 15, 'p': 1, 'metric': 'euclidean'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:08,423]\u001b[0m Trial 51 finished with value: 0.006701798792357302 and parameters: {'n_neighbors': 12, 'p': 1, 'metric': 'cityblock'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:08,902]\u001b[0m Trial 52 finished with value: 0.00677722819556798 and parameters: {'n_neighbors': 22, 'p': 1, 'metric': 'manhattan'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:09,381]\u001b[0m Trial 53 finished with value: 0.006755077777765741 and parameters: {'n_neighbors': 6, 'p': 1, 'metric': 'cityblock'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:09,864]\u001b[0m Trial 54 finished with value: 0.006701798792357302 and parameters: {'n_neighbors': 12, 'p': 1, 'metric': 'cityblock'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:10,347]\u001b[0m Trial 55 finished with value: 0.0068064021318210936 and parameters: {'n_neighbors': 17, 'p': 1, 'metric': 'cityblock'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:10,845]\u001b[0m Trial 56 finished with value: 0.006903346437542638 and parameters: {'n_neighbors': 35, 'p': 1, 'metric': 'cityblock'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:11,326]\u001b[0m Trial 57 finished with value: 0.006802717107339493 and parameters: {'n_neighbors': 24, 'p': 1, 'metric': 'cityblock'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:11,810]\u001b[0m Trial 58 finished with value: 0.006789163577813481 and parameters: {'n_neighbors': 18, 'p': 1, 'metric': 'cityblock'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:12,283]\u001b[0m Trial 59 finished with value: 0.006755077777765741 and parameters: {'n_neighbors': 6, 'p': 1, 'metric': 'l1'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:12,762]\u001b[0m Trial 60 finished with value: 0.006701798792357302 and parameters: {'n_neighbors': 12, 'p': 1, 'metric': 'cityblock'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:13,232]\u001b[0m Trial 61 finished with value: 0.009026360938857598 and parameters: {'n_neighbors': 13, 'p': 1, 'metric': 'chebyshev'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:13,713]\u001b[0m Trial 62 finished with value: 0.006777831832275792 and parameters: {'n_neighbors': 9, 'p': 1, 'metric': 'manhattan'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:14,190]\u001b[0m Trial 63 finished with value: 0.00678064329897831 and parameters: {'n_neighbors': 19, 'p': 1, 'metric': 'manhattan'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:14,696]\u001b[0m Trial 64 finished with value: 0.006780770236235154 and parameters: {'n_neighbors': 16, 'p': 1, 'metric': 'cityblock'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:15,185]\u001b[0m Trial 65 finished with value: 0.006755077777765741 and parameters: {'n_neighbors': 6, 'p': 1, 'metric': 'cityblock'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:15,669]\u001b[0m Trial 66 finished with value: 0.006713741143852452 and parameters: {'n_neighbors': 11, 'p': 1, 'metric': 'cityblock'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:16,146]\u001b[0m Trial 67 finished with value: 0.006829257625885574 and parameters: {'n_neighbors': 27, 'p': 1, 'metric': 'cityblock'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:16,634]\u001b[0m Trial 68 finished with value: 0.006795229438717031 and parameters: {'n_neighbors': 23, 'p': 1, 'metric': 'manhattan'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:17,125]\u001b[0m Trial 69 finished with value: 0.007349902175771802 and parameters: {'n_neighbors': 80, 'p': 1, 'metric': 'l1'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:17,606]\u001b[0m Trial 70 finished with value: 0.006701798792357302 and parameters: {'n_neighbors': 12, 'p': 1, 'metric': 'cityblock'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:18,082]\u001b[0m Trial 71 finished with value: 0.006696527274955836 and parameters: {'n_neighbors': 13, 'p': 1, 'metric': 'cityblock'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:18,563]\u001b[0m Trial 72 finished with value: 0.006771554909662021 and parameters: {'n_neighbors': 20, 'p': 1, 'metric': 'cityblock'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:19,048]\u001b[0m Trial 73 finished with value: 0.006744255655267417 and parameters: {'n_neighbors': 15, 'p': 1, 'metric': 'manhattan'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:19,529]\u001b[0m Trial 74 finished with value: 0.006750566122594909 and parameters: {'n_neighbors': 8, 'p': 1, 'metric': 'cityblock'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:19,915]\u001b[0m Trial 75 finished with value: 0.007145084493080411 and parameters: {'n_neighbors': 3, 'p': 1, 'metric': 'cityblock'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:20,382]\u001b[0m Trial 76 finished with value: 0.00901124408934194 and parameters: {'n_neighbors': 16, 'p': 1, 'metric': 'chebyshev'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:20,872]\u001b[0m Trial 77 finished with value: 0.006713741143852452 and parameters: {'n_neighbors': 11, 'p': 2, 'metric': 'cityblock'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:21,357]\u001b[0m Trial 78 finished with value: 0.00678064329897831 and parameters: {'n_neighbors': 19, 'p': 1, 'metric': 'manhattan'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:21,742]\u001b[0m Trial 79 finished with value: 0.007991996273277716 and parameters: {'n_neighbors': 5, 'p': 1, 'metric': 'euclidean'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:22,232]\u001b[0m Trial 80 finished with value: 0.0077905394296359865 and parameters: {'n_neighbors': 14, 'p': 1, 'metric': 'l2'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:22,718]\u001b[0m Trial 81 finished with value: 0.006777831832275792 and parameters: {'n_neighbors': 9, 'p': 1, 'metric': 'manhattan'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:23,195]\u001b[0m Trial 82 finished with value: 0.006701798792357302 and parameters: {'n_neighbors': 12, 'p': 1, 'metric': 'cityblock'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:23,676]\u001b[0m Trial 83 finished with value: 0.006701798792357302 and parameters: {'n_neighbors': 12, 'p': 1, 'metric': 'cityblock'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:24,157]\u001b[0m Trial 84 finished with value: 0.0068064021318210936 and parameters: {'n_neighbors': 17, 'p': 1, 'metric': 'cityblock'}. Best is trial 10 with value: 0.006696527274955836.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:24,640]\u001b[0m Trial 85 finished with value: 0.006688857733601972 and parameters: {'n_neighbors': 10, 'p': 1, 'metric': 'cityblock'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:25,115]\u001b[0m Trial 86 finished with value: 0.006731215452233639 and parameters: {'n_neighbors': 7, 'p': 1, 'metric': 'minkowski'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:25,603]\u001b[0m Trial 87 finished with value: 0.006764857418988586 and parameters: {'n_neighbors': 21, 'p': 1, 'metric': 'cityblock'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:26,095]\u001b[0m Trial 88 finished with value: 0.007197644880250887 and parameters: {'n_neighbors': 61, 'p': 1, 'metric': 'cityblock'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:26,580]\u001b[0m Trial 89 finished with value: 0.006921505309923638 and parameters: {'n_neighbors': 4, 'p': 1, 'metric': 'cityblock'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:27,058]\u001b[0m Trial 90 finished with value: 0.006688857733601972 and parameters: {'n_neighbors': 10, 'p': 1, 'metric': 'cityblock'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:27,553]\u001b[0m Trial 91 finished with value: 0.006725767552676035 and parameters: {'n_neighbors': 14, 'p': 1, 'metric': 'cityblock'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:28,030]\u001b[0m Trial 92 finished with value: 0.006750566122594909 and parameters: {'n_neighbors': 8, 'p': 1, 'metric': 'manhattan'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:28,503]\u001b[0m Trial 93 finished with value: 0.006688857733601972 and parameters: {'n_neighbors': 10, 'p': 1, 'metric': 'cityblock'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:28,989]\u001b[0m Trial 94 finished with value: 0.006688857733601972 and parameters: {'n_neighbors': 10, 'p': 1, 'metric': 'cityblock'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:29,471]\u001b[0m Trial 95 finished with value: 0.006843220602273169 and parameters: {'n_neighbors': 5, 'p': 1, 'metric': 'cityblock'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:29,958]\u001b[0m Trial 96 finished with value: 0.006688857733601972 and parameters: {'n_neighbors': 10, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:30,340]\u001b[0m Trial 97 finished with value: 0.007796603609516976 and parameters: {'n_neighbors': 10, 'p': 1, 'metric': 'euclidean'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:30,838]\u001b[0m Trial 98 finished with value: 0.006780770236235154 and parameters: {'n_neighbors': 16, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:31,314]\u001b[0m Trial 99 finished with value: 0.006688857733601972 and parameters: {'n_neighbors': 10, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:31,801]\u001b[0m Trial 100 finished with value: 0.006777831832275792 and parameters: {'n_neighbors': 9, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:32,279]\u001b[0m Trial 101 finished with value: 0.006731215452233639 and parameters: {'n_neighbors': 7, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:32,765]\u001b[0m Trial 102 finished with value: 0.006725767552676035 and parameters: {'n_neighbors': 14, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:33,241]\u001b[0m Trial 103 finished with value: 0.006688857733601972 and parameters: {'n_neighbors': 10, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:33,632]\u001b[0m Trial 104 finished with value: 0.007145084493080411 and parameters: {'n_neighbors': 3, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:34,112]\u001b[0m Trial 105 finished with value: 0.006777831832275792 and parameters: {'n_neighbors': 9, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:34,592]\u001b[0m Trial 106 finished with value: 0.0068064021318210936 and parameters: {'n_neighbors': 17, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:35,082]\u001b[0m Trial 107 finished with value: 0.006688857733601972 and parameters: {'n_neighbors': 10, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:35,559]\u001b[0m Trial 108 finished with value: 0.006755077777765741 and parameters: {'n_neighbors': 6, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:36,054]\u001b[0m Trial 109 finished with value: 0.006688857733601972 and parameters: {'n_neighbors': 10, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:36,528]\u001b[0m Trial 110 finished with value: 0.006688857733601972 and parameters: {'n_neighbors': 10, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:37,009]\u001b[0m Trial 111 finished with value: 0.006688857733601972 and parameters: {'n_neighbors': 10, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:37,485]\u001b[0m Trial 112 finished with value: 0.006688857733601972 and parameters: {'n_neighbors': 10, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:38,001]\u001b[0m Trial 113 finished with value: 0.007518118620764374 and parameters: {'n_neighbors': 99, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:38,482]\u001b[0m Trial 114 finished with value: 0.006688857733601972 and parameters: {'n_neighbors': 10, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:38,972]\u001b[0m Trial 115 finished with value: 0.006731215452233639 and parameters: {'n_neighbors': 7, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:39,449]\u001b[0m Trial 116 finished with value: 0.006843220602273169 and parameters: {'n_neighbors': 5, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:39,932]\u001b[0m Trial 117 finished with value: 0.006688857733601972 and parameters: {'n_neighbors': 10, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:40,415]\u001b[0m Trial 118 finished with value: 0.006688857733601972 and parameters: {'n_neighbors': 10, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:40,896]\u001b[0m Trial 119 finished with value: 0.006744255655267417 and parameters: {'n_neighbors': 15, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:41,387]\u001b[0m Trial 120 finished with value: 0.0069869143636527315 and parameters: {'n_neighbors': 42, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:41,878]\u001b[0m Trial 121 finished with value: 0.006731215452233639 and parameters: {'n_neighbors': 7, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:42,358]\u001b[0m Trial 122 finished with value: 0.006688857733601972 and parameters: {'n_neighbors': 10, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:42,841]\u001b[0m Trial 123 finished with value: 0.006921505309923638 and parameters: {'n_neighbors': 4, 'p': 2, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:43,318]\u001b[0m Trial 124 finished with value: 0.006789163577813481 and parameters: {'n_neighbors': 18, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:43,798]\u001b[0m Trial 125 finished with value: 0.006688857733601972 and parameters: {'n_neighbors': 10, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:44,284]\u001b[0m Trial 126 finished with value: 0.006750566122594909 and parameters: {'n_neighbors': 8, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:44,773]\u001b[0m Trial 127 finished with value: 0.006725767552676035 and parameters: {'n_neighbors': 14, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:45,264]\u001b[0m Trial 128 finished with value: 0.006755077777765741 and parameters: {'n_neighbors': 6, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:45,750]\u001b[0m Trial 129 finished with value: 0.006713741143852452 and parameters: {'n_neighbors': 11, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:46,236]\u001b[0m Trial 130 finished with value: 0.006696527274955836 and parameters: {'n_neighbors': 13, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:46,716]\u001b[0m Trial 131 finished with value: 0.006688857733601972 and parameters: {'n_neighbors': 10, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:47,116]\u001b[0m Trial 132 finished with value: 0.007145084493080411 and parameters: {'n_neighbors': 3, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:47,596]\u001b[0m Trial 133 finished with value: 0.006750566122594909 and parameters: {'n_neighbors': 8, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:48,082]\u001b[0m Trial 134 finished with value: 0.006713741143852452 and parameters: {'n_neighbors': 11, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:48,562]\u001b[0m Trial 135 finished with value: 0.006843220602273169 and parameters: {'n_neighbors': 5, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:49,032]\u001b[0m Trial 136 finished with value: 0.00901124408934194 and parameters: {'n_neighbors': 16, 'p': 1, 'metric': 'chebyshev'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:49,515]\u001b[0m Trial 137 finished with value: 0.006696527274955836 and parameters: {'n_neighbors': 13, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:50,011]\u001b[0m Trial 138 finished with value: 0.007848590658186593 and parameters: {'n_neighbors': 9, 'p': 1, 'metric': 'l2'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:50,489]\u001b[0m Trial 139 finished with value: 0.00678064329897831 and parameters: {'n_neighbors': 19, 'p': 1, 'metric': 'minkowski'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:50,996]\u001b[0m Trial 140 finished with value: 0.0073561662013895066 and parameters: {'n_neighbors': 81, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:51,474]\u001b[0m Trial 141 finished with value: 0.006713741143852452 and parameters: {'n_neighbors': 11, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:51,964]\u001b[0m Trial 142 finished with value: 0.006688857733601972 and parameters: {'n_neighbors': 10, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:52,442]\u001b[0m Trial 143 finished with value: 0.006731215452233639 and parameters: {'n_neighbors': 7, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:52,930]\u001b[0m Trial 144 finished with value: 0.006725767552676035 and parameters: {'n_neighbors': 14, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:53,412]\u001b[0m Trial 145 finished with value: 0.006777831832275792 and parameters: {'n_neighbors': 9, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:53,893]\u001b[0m Trial 146 finished with value: 0.006701798792357302 and parameters: {'n_neighbors': 12, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:54,379]\u001b[0m Trial 147 finished with value: 0.006780770236235154 and parameters: {'n_neighbors': 16, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:54,858]\u001b[0m Trial 148 finished with value: 0.006731215452233639 and parameters: {'n_neighbors': 7, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:55,341]\u001b[0m Trial 149 finished with value: 0.006843220602273169 and parameters: {'n_neighbors': 5, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:55,817]\u001b[0m Trial 150 finished with value: 0.009007013319222728 and parameters: {'n_neighbors': 10, 'p': 1, 'metric': 'chebyshev'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:56,308]\u001b[0m Trial 151 finished with value: 0.006688857733601972 and parameters: {'n_neighbors': 10, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:56,701]\u001b[0m Trial 152 finished with value: 0.007806445092697867 and parameters: {'n_neighbors': 13, 'p': 1, 'metric': 'euclidean'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:57,187]\u001b[0m Trial 153 finished with value: 0.006713741143852452 and parameters: {'n_neighbors': 11, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:57,662]\u001b[0m Trial 154 finished with value: 0.006777831832275792 and parameters: {'n_neighbors': 9, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:58,149]\u001b[0m Trial 155 finished with value: 0.006731215452233639 and parameters: {'n_neighbors': 7, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:58,643]\u001b[0m Trial 156 finished with value: 0.0071281983848637594 and parameters: {'n_neighbors': 54, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:59,142]\u001b[0m Trial 157 finished with value: 0.0077905394296359865 and parameters: {'n_neighbors': 14, 'p': 2, 'metric': 'l2'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:45:59,624]\u001b[0m Trial 158 finished with value: 0.006744255655267417 and parameters: {'n_neighbors': 15, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:00,110]\u001b[0m Trial 159 finished with value: 0.006701798792357302 and parameters: {'n_neighbors': 12, 'p': 1, 'metric': 'minkowski'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:00,591]\u001b[0m Trial 160 finished with value: 0.006777831832275792 and parameters: {'n_neighbors': 9, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:01,075]\u001b[0m Trial 161 finished with value: 0.006688857733601972 and parameters: {'n_neighbors': 10, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:01,561]\u001b[0m Trial 162 finished with value: 0.006843220602273169 and parameters: {'n_neighbors': 5, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:02,050]\u001b[0m Trial 163 finished with value: 0.006750566122594909 and parameters: {'n_neighbors': 8, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:02,532]\u001b[0m Trial 164 finished with value: 0.006688857733601972 and parameters: {'n_neighbors': 10, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:03,014]\u001b[0m Trial 165 finished with value: 0.006701798792357302 and parameters: {'n_neighbors': 12, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:03,513]\u001b[0m Trial 166 finished with value: 0.006755077777765741 and parameters: {'n_neighbors': 6, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:03,998]\u001b[0m Trial 167 finished with value: 0.0068064021318210936 and parameters: {'n_neighbors': 17, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:04,396]\u001b[0m Trial 168 finished with value: 0.007145084493080411 and parameters: {'n_neighbors': 3, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:04,881]\u001b[0m Trial 169 finished with value: 0.006713741143852452 and parameters: {'n_neighbors': 11, 'p': 1, 'metric': 'cityblock'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:05,381]\u001b[0m Trial 170 finished with value: 0.006750566122594909 and parameters: {'n_neighbors': 8, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:05,872]\u001b[0m Trial 171 finished with value: 0.006688857733601972 and parameters: {'n_neighbors': 10, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:06,361]\u001b[0m Trial 172 finished with value: 0.006696527274955836 and parameters: {'n_neighbors': 13, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:06,848]\u001b[0m Trial 173 finished with value: 0.006688857733601972 and parameters: {'n_neighbors': 10, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:07,337]\u001b[0m Trial 174 finished with value: 0.006731215452233639 and parameters: {'n_neighbors': 7, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:07,819]\u001b[0m Trial 175 finished with value: 0.006744255655267417 and parameters: {'n_neighbors': 15, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:08,300]\u001b[0m Trial 176 finished with value: 0.006688857733601972 and parameters: {'n_neighbors': 10, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:08,788]\u001b[0m Trial 177 finished with value: 0.006696527274955836 and parameters: {'n_neighbors': 13, 'p': 1, 'metric': 'cityblock'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:09,278]\u001b[0m Trial 178 finished with value: 0.006843220602273169 and parameters: {'n_neighbors': 5, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:09,763]\u001b[0m Trial 179 finished with value: 0.006777831832275792 and parameters: {'n_neighbors': 9, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:10,250]\u001b[0m Trial 180 finished with value: 0.006713741143852452 and parameters: {'n_neighbors': 11, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:10,640]\u001b[0m Trial 181 finished with value: 0.00787085869316927 and parameters: {'n_neighbors': 8, 'p': 1, 'metric': 'euclidean'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:11,127]\u001b[0m Trial 182 finished with value: 0.006713741143852452 and parameters: {'n_neighbors': 11, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:11,614]\u001b[0m Trial 183 finished with value: 0.006725767552676035 and parameters: {'n_neighbors': 14, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:12,100]\u001b[0m Trial 184 finished with value: 0.006731215452233639 and parameters: {'n_neighbors': 7, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:12,584]\u001b[0m Trial 185 finished with value: 0.006688857733601972 and parameters: {'n_neighbors': 10, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:13,071]\u001b[0m Trial 186 finished with value: 0.006688857733601972 and parameters: {'n_neighbors': 10, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:13,564]\u001b[0m Trial 187 finished with value: 0.006701798792357302 and parameters: {'n_neighbors': 12, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:14,042]\u001b[0m Trial 188 finished with value: 0.006755077777765741 and parameters: {'n_neighbors': 6, 'p': 1, 'metric': 'cityblock'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:14,532]\u001b[0m Trial 189 finished with value: 0.006744255655267417 and parameters: {'n_neighbors': 15, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:15,008]\u001b[0m Trial 190 finished with value: 0.006777831832275792 and parameters: {'n_neighbors': 9, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:15,496]\u001b[0m Trial 191 finished with value: 0.006688857733601972 and parameters: {'n_neighbors': 10, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:15,970]\u001b[0m Trial 192 finished with value: 0.009011156077633151 and parameters: {'n_neighbors': 12, 'p': 1, 'metric': 'chebyshev'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:16,457]\u001b[0m Trial 193 finished with value: 0.006750566122594909 and parameters: {'n_neighbors': 8, 'p': 1, 'metric': 'cityblock'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:16,938]\u001b[0m Trial 194 finished with value: 0.006696527274955836 and parameters: {'n_neighbors': 13, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:17,423]\u001b[0m Trial 195 finished with value: 0.006777831832275792 and parameters: {'n_neighbors': 9, 'p': 1, 'metric': 'minkowski'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:17,904]\u001b[0m Trial 196 finished with value: 0.006713741143852452 and parameters: {'n_neighbors': 11, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:18,400]\u001b[0m Trial 197 finished with value: 0.007982132114545461 and parameters: {'n_neighbors': 6, 'p': 1, 'metric': 'l2'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:18,893]\u001b[0m Trial 198 finished with value: 0.006780770236235154 and parameters: {'n_neighbors': 16, 'p': 1, 'metric': 'l1'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:19,400]\u001b[0m Trial 199 finished with value: 0.007268665359917024 and parameters: {'n_neighbors': 70, 'p': 1, 'metric': 'cityblock'}. Best is trial 85 with value: 0.006688857733601972.\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_Vv4ZE3fcVK",
        "outputId": "a22a0d65-810f-4e12-94c3-f3e0d24afc9c"
      },
      "source": [
        "trial = study_knn.best_trial\n",
        "print(f'MSE: {trial.value}')\n",
        "print(f'Best hyperparameters: {trial.params}')\n",
        "print(trial)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE: 0.006688857733601972\n",
            "Best hyperparameters: {'n_neighbors': 10, 'p': 1, 'metric': 'cityblock'}\n",
            "FrozenTrial(number=85, values=[0.006688857733601972], datetime_start=datetime.datetime(2021, 8, 16, 1, 45, 24, 159511), datetime_complete=datetime.datetime(2021, 8, 16, 1, 45, 24, 639783), params={'n_neighbors': 10, 'p': 1, 'metric': 'cityblock'}, distributions={'n_neighbors': IntUniformDistribution(high=100, low=3, step=1), 'p': IntUniformDistribution(high=2, low=1, step=1), 'metric': CategoricalDistribution(choices=('euclidean', 'l2', 'manhattan', 'cityblock', 'l1', 'chebyshev', 'minkowski'))}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=85, state=TrialState.COMPLETE, value=None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "u0DyET1aemRA",
        "outputId": "fd32df37-5318-46fe-b0bd-52710ada5cb6"
      },
      "source": [
        "optuna.visualization.plot_optimization_history(study_knn)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"ed4ae2d5-9293-41a3-9e02-c1df9d962294\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"ed4ae2d5-9293-41a3-9e02-c1df9d962294\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'ed4ae2d5-9293-41a3-9e02-c1df9d962294',\n",
              "                        [{\"mode\": \"markers\", \"name\": \"Objective Value\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199], \"y\": [0.006867490919306953, 0.008181921182593593, 0.008444466577214186, 0.007224888673952601, 0.008176764607436333, 0.00716980575461812, 0.00840179963843037, 0.008224340331346154, 0.008437249429364371, 0.00830635539949247, 0.006696527274955836, 0.006750566122594909, 0.006843220602273169, 0.009361287494757835, 0.006764857418988586, 0.006798025444851704, 0.006701798792357302, 0.00747576022615584, 0.0068064021318210936, 0.006867490919306953, 0.009038477797027338, 0.006713741143852452, 0.006919841452298125, 0.006696527274955836, 0.006798025444851704, 0.006789163577813481, 0.006943774040214436, 0.006813330192586285, 0.006713741143852452, 0.006877677972568981, 0.007145084493080411, 0.006696527274955836, 0.006725767552676035, 0.007796114930112774, 0.006713741143852452, 0.006842832820092017, 0.0069869143636527315, 0.008898259486895611, 0.008538375327389094, 0.006750566122594909, 0.007135254484415019, 0.006701798792357302, 0.006725767552676035, 0.006764857418988586, 0.00787085869316927, 0.007145084493080411, 0.007228902927762371, 0.006856364325103977, 0.006777831832275792, 0.00821739598860798, 0.007818895549741212, 0.006701798792357302, 0.00677722819556798, 0.006755077777765741, 0.006701798792357302, 0.0068064021318210936, 0.006903346437542638, 0.006802717107339493, 0.006789163577813481, 0.006755077777765741, 0.006701798792357302, 0.009026360938857598, 0.006777831832275792, 0.00678064329897831, 0.006780770236235154, 0.006755077777765741, 0.006713741143852452, 0.006829257625885574, 0.006795229438717031, 0.007349902175771802, 0.006701798792357302, 0.006696527274955836, 0.006771554909662021, 0.006744255655267417, 0.006750566122594909, 0.007145084493080411, 0.00901124408934194, 0.006713741143852452, 0.00678064329897831, 0.007991996273277716, 0.0077905394296359865, 0.006777831832275792, 0.006701798792357302, 0.006701798792357302, 0.0068064021318210936, 0.006688857733601972, 0.006731215452233639, 0.006764857418988586, 0.007197644880250887, 0.006921505309923638, 0.006688857733601972, 0.006725767552676035, 0.006750566122594909, 0.006688857733601972, 0.006688857733601972, 0.006843220602273169, 0.006688857733601972, 0.007796603609516976, 0.006780770236235154, 0.006688857733601972, 0.006777831832275792, 0.006731215452233639, 0.006725767552676035, 0.006688857733601972, 0.007145084493080411, 0.006777831832275792, 0.0068064021318210936, 0.006688857733601972, 0.006755077777765741, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.007518118620764374, 0.006688857733601972, 0.006731215452233639, 0.006843220602273169, 0.006688857733601972, 0.006688857733601972, 0.006744255655267417, 0.0069869143636527315, 0.006731215452233639, 0.006688857733601972, 0.006921505309923638, 0.006789163577813481, 0.006688857733601972, 0.006750566122594909, 0.006725767552676035, 0.006755077777765741, 0.006713741143852452, 0.006696527274955836, 0.006688857733601972, 0.007145084493080411, 0.006750566122594909, 0.006713741143852452, 0.006843220602273169, 0.00901124408934194, 0.006696527274955836, 0.007848590658186593, 0.00678064329897831, 0.0073561662013895066, 0.006713741143852452, 0.006688857733601972, 0.006731215452233639, 0.006725767552676035, 0.006777831832275792, 0.006701798792357302, 0.006780770236235154, 0.006731215452233639, 0.006843220602273169, 0.009007013319222728, 0.006688857733601972, 0.007806445092697867, 0.006713741143852452, 0.006777831832275792, 0.006731215452233639, 0.0071281983848637594, 0.0077905394296359865, 0.006744255655267417, 0.006701798792357302, 0.006777831832275792, 0.006688857733601972, 0.006843220602273169, 0.006750566122594909, 0.006688857733601972, 0.006701798792357302, 0.006755077777765741, 0.0068064021318210936, 0.007145084493080411, 0.006713741143852452, 0.006750566122594909, 0.006688857733601972, 0.006696527274955836, 0.006688857733601972, 0.006731215452233639, 0.006744255655267417, 0.006688857733601972, 0.006696527274955836, 0.006843220602273169, 0.006777831832275792, 0.006713741143852452, 0.00787085869316927, 0.006713741143852452, 0.006725767552676035, 0.006731215452233639, 0.006688857733601972, 0.006688857733601972, 0.006701798792357302, 0.006755077777765741, 0.006744255655267417, 0.006777831832275792, 0.006688857733601972, 0.009011156077633151, 0.006750566122594909, 0.006696527274955836, 0.006777831832275792, 0.006713741143852452, 0.007982132114545461, 0.006780770236235154, 0.007268665359917024]}, {\"name\": \"Best Value\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199], \"y\": [0.006867490919306953, 0.006867490919306953, 0.006867490919306953, 0.006867490919306953, 0.006867490919306953, 0.006867490919306953, 0.006867490919306953, 0.006867490919306953, 0.006867490919306953, 0.006867490919306953, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006696527274955836, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Optimization History Plot\"}, \"xaxis\": {\"title\": {\"text\": \"#Trials\"}}, \"yaxis\": {\"title\": {\"text\": \"Objective Value\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('ed4ae2d5-9293-41a3-9e02-c1df9d962294');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "SdckVxWfkIyz",
        "outputId": "42c16b22-d139-4481-dc3f-c4436f22b707"
      },
      "source": [
        "optuna.visualization.plot_slice(study_knn)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"493deb9b-5193-4f08-a161-e48fbf813e58\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"493deb9b-5193-4f08-a161-e48fbf813e58\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '493deb9b-5193-4f08-a161-e48fbf813e58',\n",
              "                        [{\"marker\": {\"color\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199], \"colorbar\": {\"title\": {\"text\": \"#Trials\"}, \"x\": 1.0, \"xpad\": 40}, \"colorscale\": [[0.0, \"rgb(247,251,255)\"], [0.125, \"rgb(222,235,247)\"], [0.25, \"rgb(198,219,239)\"], [0.375, \"rgb(158,202,225)\"], [0.5, \"rgb(107,174,214)\"], [0.625, \"rgb(66,146,198)\"], [0.75, \"rgb(33,113,181)\"], [0.875, \"rgb(8,81,156)\"], [1.0, \"rgb(8,48,107)\"]], \"line\": {\"color\": \"Grey\", \"width\": 0.5}, \"showscale\": true}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [\"manhattan\", \"l2\", \"minkowski\", \"cityblock\", \"euclidean\", \"minkowski\", \"euclidean\", \"euclidean\", \"l2\", \"euclidean\", \"manhattan\", \"manhattan\", \"manhattan\", \"chebyshev\", \"l1\", \"manhattan\", \"manhattan\", \"manhattan\", \"cityblock\", \"l1\", \"chebyshev\", \"manhattan\", \"manhattan\", \"manhattan\", \"manhattan\", \"manhattan\", \"manhattan\", \"manhattan\", \"cityblock\", \"manhattan\", \"l1\", \"cityblock\", \"cityblock\", \"l2\", \"cityblock\", \"minkowski\", \"cityblock\", \"chebyshev\", \"l2\", \"minkowski\", \"manhattan\", \"manhattan\", \"manhattan\", \"manhattan\", \"euclidean\", \"manhattan\", \"cityblock\", \"manhattan\", \"minkowski\", \"l2\", \"euclidean\", \"cityblock\", \"manhattan\", \"cityblock\", \"cityblock\", \"cityblock\", \"cityblock\", \"cityblock\", \"cityblock\", \"l1\", \"cityblock\", \"chebyshev\", \"manhattan\", \"manhattan\", \"cityblock\", \"cityblock\", \"cityblock\", \"cityblock\", \"manhattan\", \"l1\", \"cityblock\", \"cityblock\", \"cityblock\", \"manhattan\", \"cityblock\", \"cityblock\", \"chebyshev\", \"cityblock\", \"manhattan\", \"euclidean\", \"l2\", \"manhattan\", \"cityblock\", \"cityblock\", \"cityblock\", \"cityblock\", \"minkowski\", \"cityblock\", \"cityblock\", \"cityblock\", \"cityblock\", \"cityblock\", \"manhattan\", \"cityblock\", \"cityblock\", \"cityblock\", \"l1\", \"euclidean\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"chebyshev\", \"l1\", \"l2\", \"minkowski\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"chebyshev\", \"l1\", \"euclidean\", \"l1\", \"l1\", \"l1\", \"l1\", \"l2\", \"l1\", \"minkowski\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"cityblock\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"cityblock\", \"l1\", \"l1\", \"l1\", \"euclidean\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"l1\", \"cityblock\", \"l1\", \"l1\", \"l1\", \"chebyshev\", \"cityblock\", \"l1\", \"minkowski\", \"l1\", \"l2\", \"l1\", \"cityblock\"], \"xaxis\": \"x\", \"y\": [0.006867490919306953, 0.008181921182593593, 0.008444466577214186, 0.007224888673952601, 0.008176764607436333, 0.00716980575461812, 0.00840179963843037, 0.008224340331346154, 0.008437249429364371, 0.00830635539949247, 0.006696527274955836, 0.006750566122594909, 0.006843220602273169, 0.009361287494757835, 0.006764857418988586, 0.006798025444851704, 0.006701798792357302, 0.00747576022615584, 0.0068064021318210936, 0.006867490919306953, 0.009038477797027338, 0.006713741143852452, 0.006919841452298125, 0.006696527274955836, 0.006798025444851704, 0.006789163577813481, 0.006943774040214436, 0.006813330192586285, 0.006713741143852452, 0.006877677972568981, 0.007145084493080411, 0.006696527274955836, 0.006725767552676035, 0.007796114930112774, 0.006713741143852452, 0.006842832820092017, 0.0069869143636527315, 0.008898259486895611, 0.008538375327389094, 0.006750566122594909, 0.007135254484415019, 0.006701798792357302, 0.006725767552676035, 0.006764857418988586, 0.00787085869316927, 0.007145084493080411, 0.007228902927762371, 0.006856364325103977, 0.006777831832275792, 0.00821739598860798, 0.007818895549741212, 0.006701798792357302, 0.00677722819556798, 0.006755077777765741, 0.006701798792357302, 0.0068064021318210936, 0.006903346437542638, 0.006802717107339493, 0.006789163577813481, 0.006755077777765741, 0.006701798792357302, 0.009026360938857598, 0.006777831832275792, 0.00678064329897831, 0.006780770236235154, 0.006755077777765741, 0.006713741143852452, 0.006829257625885574, 0.006795229438717031, 0.007349902175771802, 0.006701798792357302, 0.006696527274955836, 0.006771554909662021, 0.006744255655267417, 0.006750566122594909, 0.007145084493080411, 0.00901124408934194, 0.006713741143852452, 0.00678064329897831, 0.007991996273277716, 0.0077905394296359865, 0.006777831832275792, 0.006701798792357302, 0.006701798792357302, 0.0068064021318210936, 0.006688857733601972, 0.006731215452233639, 0.006764857418988586, 0.007197644880250887, 0.006921505309923638, 0.006688857733601972, 0.006725767552676035, 0.006750566122594909, 0.006688857733601972, 0.006688857733601972, 0.006843220602273169, 0.006688857733601972, 0.007796603609516976, 0.006780770236235154, 0.006688857733601972, 0.006777831832275792, 0.006731215452233639, 0.006725767552676035, 0.006688857733601972, 0.007145084493080411, 0.006777831832275792, 0.0068064021318210936, 0.006688857733601972, 0.006755077777765741, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.007518118620764374, 0.006688857733601972, 0.006731215452233639, 0.006843220602273169, 0.006688857733601972, 0.006688857733601972, 0.006744255655267417, 0.0069869143636527315, 0.006731215452233639, 0.006688857733601972, 0.006921505309923638, 0.006789163577813481, 0.006688857733601972, 0.006750566122594909, 0.006725767552676035, 0.006755077777765741, 0.006713741143852452, 0.006696527274955836, 0.006688857733601972, 0.007145084493080411, 0.006750566122594909, 0.006713741143852452, 0.006843220602273169, 0.00901124408934194, 0.006696527274955836, 0.007848590658186593, 0.00678064329897831, 0.0073561662013895066, 0.006713741143852452, 0.006688857733601972, 0.006731215452233639, 0.006725767552676035, 0.006777831832275792, 0.006701798792357302, 0.006780770236235154, 0.006731215452233639, 0.006843220602273169, 0.009007013319222728, 0.006688857733601972, 0.007806445092697867, 0.006713741143852452, 0.006777831832275792, 0.006731215452233639, 0.0071281983848637594, 0.0077905394296359865, 0.006744255655267417, 0.006701798792357302, 0.006777831832275792, 0.006688857733601972, 0.006843220602273169, 0.006750566122594909, 0.006688857733601972, 0.006701798792357302, 0.006755077777765741, 0.0068064021318210936, 0.007145084493080411, 0.006713741143852452, 0.006750566122594909, 0.006688857733601972, 0.006696527274955836, 0.006688857733601972, 0.006731215452233639, 0.006744255655267417, 0.006688857733601972, 0.006696527274955836, 0.006843220602273169, 0.006777831832275792, 0.006713741143852452, 0.00787085869316927, 0.006713741143852452, 0.006725767552676035, 0.006731215452233639, 0.006688857733601972, 0.006688857733601972, 0.006701798792357302, 0.006755077777765741, 0.006744255655267417, 0.006777831832275792, 0.006688857733601972, 0.009011156077633151, 0.006750566122594909, 0.006696527274955836, 0.006777831832275792, 0.006713741143852452, 0.007982132114545461, 0.006780770236235154, 0.007268665359917024], \"yaxis\": \"y\"}, {\"marker\": {\"color\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199], \"colorbar\": {\"title\": {\"text\": \"#Trials\"}, \"x\": 1.0, \"xpad\": 40}, \"colorscale\": [[0.0, \"rgb(247,251,255)\"], [0.125, \"rgb(222,235,247)\"], [0.25, \"rgb(198,219,239)\"], [0.375, \"rgb(158,202,225)\"], [0.5, \"rgb(107,174,214)\"], [0.625, \"rgb(66,146,198)\"], [0.75, \"rgb(33,113,181)\"], [0.875, \"rgb(8,81,156)\"], [1.0, \"rgb(8,48,107)\"]], \"line\": {\"color\": \"Grey\", \"width\": 0.5}, \"showscale\": false}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [32, 45, 80, 66, 44, 57, 72, 49, 76, 60, 13, 8, 5, 4, 21, 25, 12, 94, 17, 32, 15, 11, 36, 13, 25, 18, 38, 26, 11, 31, 3, 13, 14, 22, 11, 28, 42, 19, 89, 8, 55, 12, 14, 21, 8, 3, 67, 30, 9, 48, 15, 12, 22, 6, 12, 17, 35, 24, 18, 6, 12, 13, 9, 19, 16, 6, 11, 27, 23, 80, 12, 13, 20, 15, 8, 3, 16, 11, 19, 5, 14, 9, 12, 12, 17, 10, 7, 21, 61, 4, 10, 14, 8, 10, 10, 5, 10, 10, 16, 10, 9, 7, 14, 10, 3, 9, 17, 10, 6, 10, 10, 10, 10, 99, 10, 7, 5, 10, 10, 15, 42, 7, 10, 4, 18, 10, 8, 14, 6, 11, 13, 10, 3, 8, 11, 5, 16, 13, 9, 19, 81, 11, 10, 7, 14, 9, 12, 16, 7, 5, 10, 10, 13, 11, 9, 7, 54, 14, 15, 12, 9, 10, 5, 8, 10, 12, 6, 17, 3, 11, 8, 10, 13, 10, 7, 15, 10, 13, 5, 9, 11, 8, 11, 14, 7, 10, 10, 12, 6, 15, 9, 10, 12, 8, 13, 9, 11, 6, 16, 70], \"xaxis\": \"x2\", \"y\": [0.006867490919306953, 0.008181921182593593, 0.008444466577214186, 0.007224888673952601, 0.008176764607436333, 0.00716980575461812, 0.00840179963843037, 0.008224340331346154, 0.008437249429364371, 0.00830635539949247, 0.006696527274955836, 0.006750566122594909, 0.006843220602273169, 0.009361287494757835, 0.006764857418988586, 0.006798025444851704, 0.006701798792357302, 0.00747576022615584, 0.0068064021318210936, 0.006867490919306953, 0.009038477797027338, 0.006713741143852452, 0.006919841452298125, 0.006696527274955836, 0.006798025444851704, 0.006789163577813481, 0.006943774040214436, 0.006813330192586285, 0.006713741143852452, 0.006877677972568981, 0.007145084493080411, 0.006696527274955836, 0.006725767552676035, 0.007796114930112774, 0.006713741143852452, 0.006842832820092017, 0.0069869143636527315, 0.008898259486895611, 0.008538375327389094, 0.006750566122594909, 0.007135254484415019, 0.006701798792357302, 0.006725767552676035, 0.006764857418988586, 0.00787085869316927, 0.007145084493080411, 0.007228902927762371, 0.006856364325103977, 0.006777831832275792, 0.00821739598860798, 0.007818895549741212, 0.006701798792357302, 0.00677722819556798, 0.006755077777765741, 0.006701798792357302, 0.0068064021318210936, 0.006903346437542638, 0.006802717107339493, 0.006789163577813481, 0.006755077777765741, 0.006701798792357302, 0.009026360938857598, 0.006777831832275792, 0.00678064329897831, 0.006780770236235154, 0.006755077777765741, 0.006713741143852452, 0.006829257625885574, 0.006795229438717031, 0.007349902175771802, 0.006701798792357302, 0.006696527274955836, 0.006771554909662021, 0.006744255655267417, 0.006750566122594909, 0.007145084493080411, 0.00901124408934194, 0.006713741143852452, 0.00678064329897831, 0.007991996273277716, 0.0077905394296359865, 0.006777831832275792, 0.006701798792357302, 0.006701798792357302, 0.0068064021318210936, 0.006688857733601972, 0.006731215452233639, 0.006764857418988586, 0.007197644880250887, 0.006921505309923638, 0.006688857733601972, 0.006725767552676035, 0.006750566122594909, 0.006688857733601972, 0.006688857733601972, 0.006843220602273169, 0.006688857733601972, 0.007796603609516976, 0.006780770236235154, 0.006688857733601972, 0.006777831832275792, 0.006731215452233639, 0.006725767552676035, 0.006688857733601972, 0.007145084493080411, 0.006777831832275792, 0.0068064021318210936, 0.006688857733601972, 0.006755077777765741, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.007518118620764374, 0.006688857733601972, 0.006731215452233639, 0.006843220602273169, 0.006688857733601972, 0.006688857733601972, 0.006744255655267417, 0.0069869143636527315, 0.006731215452233639, 0.006688857733601972, 0.006921505309923638, 0.006789163577813481, 0.006688857733601972, 0.006750566122594909, 0.006725767552676035, 0.006755077777765741, 0.006713741143852452, 0.006696527274955836, 0.006688857733601972, 0.007145084493080411, 0.006750566122594909, 0.006713741143852452, 0.006843220602273169, 0.00901124408934194, 0.006696527274955836, 0.007848590658186593, 0.00678064329897831, 0.0073561662013895066, 0.006713741143852452, 0.006688857733601972, 0.006731215452233639, 0.006725767552676035, 0.006777831832275792, 0.006701798792357302, 0.006780770236235154, 0.006731215452233639, 0.006843220602273169, 0.009007013319222728, 0.006688857733601972, 0.007806445092697867, 0.006713741143852452, 0.006777831832275792, 0.006731215452233639, 0.0071281983848637594, 0.0077905394296359865, 0.006744255655267417, 0.006701798792357302, 0.006777831832275792, 0.006688857733601972, 0.006843220602273169, 0.006750566122594909, 0.006688857733601972, 0.006701798792357302, 0.006755077777765741, 0.0068064021318210936, 0.007145084493080411, 0.006713741143852452, 0.006750566122594909, 0.006688857733601972, 0.006696527274955836, 0.006688857733601972, 0.006731215452233639, 0.006744255655267417, 0.006688857733601972, 0.006696527274955836, 0.006843220602273169, 0.006777831832275792, 0.006713741143852452, 0.00787085869316927, 0.006713741143852452, 0.006725767552676035, 0.006731215452233639, 0.006688857733601972, 0.006688857733601972, 0.006701798792357302, 0.006755077777765741, 0.006744255655267417, 0.006777831832275792, 0.006688857733601972, 0.009011156077633151, 0.006750566122594909, 0.006696527274955836, 0.006777831832275792, 0.006713741143852452, 0.007982132114545461, 0.006780770236235154, 0.007268665359917024], \"yaxis\": \"y2\"}, {\"marker\": {\"color\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199], \"colorbar\": {\"title\": {\"text\": \"#Trials\"}, \"x\": 1.0, \"xpad\": 40}, \"colorscale\": [[0.0, \"rgb(247,251,255)\"], [0.125, \"rgb(222,235,247)\"], [0.25, \"rgb(198,219,239)\"], [0.375, \"rgb(158,202,225)\"], [0.5, \"rgb(107,174,214)\"], [0.625, \"rgb(66,146,198)\"], [0.75, \"rgb(33,113,181)\"], [0.875, \"rgb(8,81,156)\"], [1.0, \"rgb(8,48,107)\"]], \"line\": {\"color\": \"Grey\", \"width\": 0.5}, \"showscale\": false}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [1, 2, 2, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"xaxis\": \"x3\", \"y\": [0.006867490919306953, 0.008181921182593593, 0.008444466577214186, 0.007224888673952601, 0.008176764607436333, 0.00716980575461812, 0.00840179963843037, 0.008224340331346154, 0.008437249429364371, 0.00830635539949247, 0.006696527274955836, 0.006750566122594909, 0.006843220602273169, 0.009361287494757835, 0.006764857418988586, 0.006798025444851704, 0.006701798792357302, 0.00747576022615584, 0.0068064021318210936, 0.006867490919306953, 0.009038477797027338, 0.006713741143852452, 0.006919841452298125, 0.006696527274955836, 0.006798025444851704, 0.006789163577813481, 0.006943774040214436, 0.006813330192586285, 0.006713741143852452, 0.006877677972568981, 0.007145084493080411, 0.006696527274955836, 0.006725767552676035, 0.007796114930112774, 0.006713741143852452, 0.006842832820092017, 0.0069869143636527315, 0.008898259486895611, 0.008538375327389094, 0.006750566122594909, 0.007135254484415019, 0.006701798792357302, 0.006725767552676035, 0.006764857418988586, 0.00787085869316927, 0.007145084493080411, 0.007228902927762371, 0.006856364325103977, 0.006777831832275792, 0.00821739598860798, 0.007818895549741212, 0.006701798792357302, 0.00677722819556798, 0.006755077777765741, 0.006701798792357302, 0.0068064021318210936, 0.006903346437542638, 0.006802717107339493, 0.006789163577813481, 0.006755077777765741, 0.006701798792357302, 0.009026360938857598, 0.006777831832275792, 0.00678064329897831, 0.006780770236235154, 0.006755077777765741, 0.006713741143852452, 0.006829257625885574, 0.006795229438717031, 0.007349902175771802, 0.006701798792357302, 0.006696527274955836, 0.006771554909662021, 0.006744255655267417, 0.006750566122594909, 0.007145084493080411, 0.00901124408934194, 0.006713741143852452, 0.00678064329897831, 0.007991996273277716, 0.0077905394296359865, 0.006777831832275792, 0.006701798792357302, 0.006701798792357302, 0.0068064021318210936, 0.006688857733601972, 0.006731215452233639, 0.006764857418988586, 0.007197644880250887, 0.006921505309923638, 0.006688857733601972, 0.006725767552676035, 0.006750566122594909, 0.006688857733601972, 0.006688857733601972, 0.006843220602273169, 0.006688857733601972, 0.007796603609516976, 0.006780770236235154, 0.006688857733601972, 0.006777831832275792, 0.006731215452233639, 0.006725767552676035, 0.006688857733601972, 0.007145084493080411, 0.006777831832275792, 0.0068064021318210936, 0.006688857733601972, 0.006755077777765741, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.006688857733601972, 0.007518118620764374, 0.006688857733601972, 0.006731215452233639, 0.006843220602273169, 0.006688857733601972, 0.006688857733601972, 0.006744255655267417, 0.0069869143636527315, 0.006731215452233639, 0.006688857733601972, 0.006921505309923638, 0.006789163577813481, 0.006688857733601972, 0.006750566122594909, 0.006725767552676035, 0.006755077777765741, 0.006713741143852452, 0.006696527274955836, 0.006688857733601972, 0.007145084493080411, 0.006750566122594909, 0.006713741143852452, 0.006843220602273169, 0.00901124408934194, 0.006696527274955836, 0.007848590658186593, 0.00678064329897831, 0.0073561662013895066, 0.006713741143852452, 0.006688857733601972, 0.006731215452233639, 0.006725767552676035, 0.006777831832275792, 0.006701798792357302, 0.006780770236235154, 0.006731215452233639, 0.006843220602273169, 0.009007013319222728, 0.006688857733601972, 0.007806445092697867, 0.006713741143852452, 0.006777831832275792, 0.006731215452233639, 0.0071281983848637594, 0.0077905394296359865, 0.006744255655267417, 0.006701798792357302, 0.006777831832275792, 0.006688857733601972, 0.006843220602273169, 0.006750566122594909, 0.006688857733601972, 0.006701798792357302, 0.006755077777765741, 0.0068064021318210936, 0.007145084493080411, 0.006713741143852452, 0.006750566122594909, 0.006688857733601972, 0.006696527274955836, 0.006688857733601972, 0.006731215452233639, 0.006744255655267417, 0.006688857733601972, 0.006696527274955836, 0.006843220602273169, 0.006777831832275792, 0.006713741143852452, 0.00787085869316927, 0.006713741143852452, 0.006725767552676035, 0.006731215452233639, 0.006688857733601972, 0.006688857733601972, 0.006701798792357302, 0.006755077777765741, 0.006744255655267417, 0.006777831832275792, 0.006688857733601972, 0.009011156077633151, 0.006750566122594909, 0.006696527274955836, 0.006777831832275792, 0.006713741143852452, 0.007982132114545461, 0.006780770236235154, 0.007268665359917024], \"yaxis\": \"y3\"}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Slice Plot\"}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.2888888888888889], \"title\": {\"text\": \"metric\"}}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.35555555555555557, 0.6444444444444445], \"title\": {\"text\": \"n_neighbors\"}}, \"xaxis3\": {\"anchor\": \"y3\", \"domain\": [0.7111111111111111, 1.0], \"title\": {\"text\": \"p\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Objective Value\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0], \"matches\": \"y\", \"showticklabels\": false}, \"yaxis3\": {\"anchor\": \"x3\", \"domain\": [0.0, 1.0], \"matches\": \"y\", \"showticklabels\": false}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('493deb9b-5193-4f08-a161-e48fbf813e58');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "kpxijIw6k3PW",
        "outputId": "be62dd97-a3b6-4fbe-a86c-d7135701f162"
      },
      "source": [
        "optuna.visualization.plot_param_importances(study_knn)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"92836754-dc8f-438d-bed2-e345160cd194\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"92836754-dc8f-438d-bed2-e345160cd194\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '92836754-dc8f-438d-bed2-e345160cd194',\n",
              "                        [{\"cliponaxis\": false, \"hovertemplate\": [\"p (IntUniformDistribution): 0.0033472819044772033<extra></extra>\", \"n_neighbors (IntUniformDistribution): 0.04001712663321419<extra></extra>\", \"metric (CategoricalDistribution): 0.9566355914623085<extra></extra>\"], \"marker\": {\"color\": \"rgb(66,146,198)\"}, \"orientation\": \"h\", \"text\": [\"0.0033472819044772033\", \"0.04001712663321419\", \"0.9566355914623085\"], \"textposition\": \"outside\", \"texttemplate\": \"%{text:.2f}\", \"type\": \"bar\", \"x\": [0.0033472819044772033, 0.04001712663321419, 0.9566355914623085], \"y\": [\"p\", \"n_neighbors\", \"metric\"]}],\n",
              "                        {\"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Hyperparameter Importances\"}, \"xaxis\": {\"title\": {\"text\": \"Importance for Objective Value\"}}, \"yaxis\": {\"title\": {\"text\": \"Hyperparameter\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('92836754-dc8f-438d-bed2-e345160cd194');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_K8mBYKocqqO"
      },
      "source": [
        "# **Árvore de decisão**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KskjySLwfWVK",
        "outputId": "630aaea7-4113-46db-be7a-c203dfa4d0b0"
      },
      "source": [
        "\n",
        "def arvoredec(trial):\n",
        "\n",
        "  with mlflow.start_run(run_name=\"Arvore de decisao\"):\n",
        "\n",
        "    max_depth = trial.suggest_int('max_depth',9,100,log=True)#low = none\n",
        "    min_samples_leaf = trial.suggest_int('min_samples_leaf',1,10)\n",
        "    max_leaf_nodes = trial.suggest_int('max_leaf_nodes',0,100)#low = none\n",
        "\n",
        "    if(max_depth == 9):\n",
        "      max_depth = None\n",
        "    if(max_leaf_nodes == 0):\n",
        "      max_leaf_nodes = None\n",
        "    elif(max_leaf_nodes == 1):\n",
        "      max_leaf_nodes +=1\n",
        "\n",
        "    clf = tree.DecisionTreeRegressor(max_depth=max_depth,min_samples_leaf=min_samples_leaf,max_leaf_nodes=max_leaf_nodes)\n",
        "    clf = clf.fit(X_train, y_train)\n",
        "\n",
        "    y_pred_val = clf.predict(X_val)\n",
        "\n",
        "    (mse, mae, r2) = eval_metrics(y_val, y_pred_val)\n",
        "    \n",
        "    mlflow.log_param(\"max_depth\", max_depth)\n",
        "    mlflow.log_param(\"min_samples_leaf\", min_samples_leaf)\n",
        "    mlflow.log_param(\"max_leaf_nodes\", max_leaf_nodes)\n",
        "\n",
        "    mlflow.log_metric(\"mse\", mse)\n",
        "    mlflow.log_metric(\"mae\", mae)\n",
        "    mlflow.log_metric(\"r2\", r2)\n",
        "    #mlflow.log_metric(\"nomemetrica\", nomevariavel)\n",
        "    #mlflow.log_metric(\"nomemetrica\", nomevariavel)\n",
        "\n",
        "    return mean_squared_error(y_val, y_pred_val)\n",
        "\n",
        "study_decisiontree = optuna.create_study(direction='minimize')\n",
        "study_decisiontree.optimize(arvoredec,n_trials=200)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 01:46:23,985]\u001b[0m A new study created in memory with name: no-name-d9db38a2-5a96-4345-8a0e-95a6b2a26009\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:24,082]\u001b[0m Trial 0 finished with value: 0.006105077510555661 and parameters: {'max_depth': 95, 'min_samples_leaf': 9, 'max_leaf_nodes': 11}. Best is trial 0 with value: 0.006105077510555661.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:24,202]\u001b[0m Trial 1 finished with value: 0.004615220111482611 and parameters: {'max_depth': 42, 'min_samples_leaf': 10, 'max_leaf_nodes': 73}. Best is trial 1 with value: 0.004615220111482611.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:24,325]\u001b[0m Trial 2 finished with value: 0.004733355288067668 and parameters: {'max_depth': 10, 'min_samples_leaf': 5, 'max_leaf_nodes': 85}. Best is trial 1 with value: 0.004615220111482611.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:24,455]\u001b[0m Trial 3 finished with value: 0.004809605282150507 and parameters: {'max_depth': 89, 'min_samples_leaf': 5, 'max_leaf_nodes': 80}. Best is trial 1 with value: 0.004615220111482611.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:24,575]\u001b[0m Trial 4 finished with value: 0.0055040832833616665 and parameters: {'max_depth': 24, 'min_samples_leaf': 3, 'max_leaf_nodes': 20}. Best is trial 1 with value: 0.004615220111482611.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:24,696]\u001b[0m Trial 5 finished with value: 0.005029665162426492 and parameters: {'max_depth': 45, 'min_samples_leaf': 9, 'max_leaf_nodes': 42}. Best is trial 1 with value: 0.004615220111482611.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:24,813]\u001b[0m Trial 6 finished with value: 0.004938743206474557 and parameters: {'max_depth': 28, 'min_samples_leaf': 9, 'max_leaf_nodes': 49}. Best is trial 1 with value: 0.004615220111482611.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:24,934]\u001b[0m Trial 7 finished with value: 0.00483585006445534 and parameters: {'max_depth': 79, 'min_samples_leaf': 5, 'max_leaf_nodes': 74}. Best is trial 1 with value: 0.004615220111482611.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:25,054]\u001b[0m Trial 8 finished with value: 0.004964842824841498 and parameters: {'max_depth': 63, 'min_samples_leaf': 8, 'max_leaf_nodes': 43}. Best is trial 1 with value: 0.004615220111482611.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:25,126]\u001b[0m Trial 9 finished with value: 0.009383941289509286 and parameters: {'max_depth': 99, 'min_samples_leaf': 9, 'max_leaf_nodes': 1}. Best is trial 1 with value: 0.004615220111482611.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:25,272]\u001b[0m Trial 10 finished with value: 0.0048574549420257445 and parameters: {'max_depth': 14, 'min_samples_leaf': 1, 'max_leaf_nodes': 98}. Best is trial 1 with value: 0.004615220111482611.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:25,409]\u001b[0m Trial 11 finished with value: 0.0046838530403632075 and parameters: {'max_depth': 9, 'min_samples_leaf': 7, 'max_leaf_nodes': 74}. Best is trial 1 with value: 0.004615220111482611.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:25,540]\u001b[0m Trial 12 finished with value: 0.004754460598938891 and parameters: {'max_depth': 18, 'min_samples_leaf': 7, 'max_leaf_nodes': 65}. Best is trial 1 with value: 0.004615220111482611.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:25,669]\u001b[0m Trial 13 finished with value: 0.004740187774751588 and parameters: {'max_depth': 39, 'min_samples_leaf': 7, 'max_leaf_nodes': 67}. Best is trial 1 with value: 0.004615220111482611.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:25,807]\u001b[0m Trial 14 finished with value: 0.004617410875175973 and parameters: {'max_depth': 9, 'min_samples_leaf': 10, 'max_leaf_nodes': 100}. Best is trial 1 with value: 0.004615220111482611.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:25,951]\u001b[0m Trial 15 finished with value: 0.004614385899170579 and parameters: {'max_depth': 41, 'min_samples_leaf': 10, 'max_leaf_nodes': 98}. Best is trial 15 with value: 0.004614385899170579.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:26,083]\u001b[0m Trial 16 finished with value: 0.00480749372375126 and parameters: {'max_depth': 44, 'min_samples_leaf': 10, 'max_leaf_nodes': 59}. Best is trial 15 with value: 0.004614385899170579.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:26,216]\u001b[0m Trial 17 finished with value: 0.004756715496287527 and parameters: {'max_depth': 58, 'min_samples_leaf': 3, 'max_leaf_nodes': 84}. Best is trial 15 with value: 0.004614385899170579.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:26,351]\u001b[0m Trial 18 finished with value: 0.00460425308939593 and parameters: {'max_depth': 35, 'min_samples_leaf': 10, 'max_leaf_nodes': 91}. Best is trial 18 with value: 0.00460425308939593.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:26,491]\u001b[0m Trial 19 finished with value: 0.004542857144739812 and parameters: {'max_depth': 32, 'min_samples_leaf': 8, 'max_leaf_nodes': 93}. Best is trial 19 with value: 0.004542857144739812.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:26,608]\u001b[0m Trial 20 finished with value: 0.005248655727882804 and parameters: {'max_depth': 22, 'min_samples_leaf': 8, 'max_leaf_nodes': 29}. Best is trial 19 with value: 0.004542857144739812.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:26,742]\u001b[0m Trial 21 finished with value: 0.004540580742562123 and parameters: {'max_depth': 34, 'min_samples_leaf': 8, 'max_leaf_nodes': 92}. Best is trial 21 with value: 0.004540580742562123.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:26,875]\u001b[0m Trial 22 finished with value: 0.004538983495917568 and parameters: {'max_depth': 33, 'min_samples_leaf': 8, 'max_leaf_nodes': 90}. Best is trial 22 with value: 0.004538983495917568.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:27,018]\u001b[0m Trial 23 finished with value: 0.004624905575201242 and parameters: {'max_depth': 31, 'min_samples_leaf': 6, 'max_leaf_nodes': 90}. Best is trial 22 with value: 0.004538983495917568.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:27,157]\u001b[0m Trial 24 finished with value: 0.004530901279381072 and parameters: {'max_depth': 55, 'min_samples_leaf': 8, 'max_leaf_nodes': 89}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:27,286]\u001b[0m Trial 25 finished with value: 0.0048406488003686155 and parameters: {'max_depth': 61, 'min_samples_leaf': 6, 'max_leaf_nodes': 60}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:27,421]\u001b[0m Trial 26 finished with value: 0.004556972477634315 and parameters: {'max_depth': 53, 'min_samples_leaf': 8, 'max_leaf_nodes': 81}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:27,565]\u001b[0m Trial 27 finished with value: 0.00463735253976059 and parameters: {'max_depth': 73, 'min_samples_leaf': 7, 'max_leaf_nodes': 89}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:27,700]\u001b[0m Trial 28 finished with value: 0.004755965467227116 and parameters: {'max_depth': 51, 'min_samples_leaf': 6, 'max_leaf_nodes': 75}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:27,825]\u001b[0m Trial 29 finished with value: 0.005001137835558552 and parameters: {'max_depth': 26, 'min_samples_leaf': 4, 'max_leaf_nodes': 55}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:27,956]\u001b[0m Trial 30 finished with value: 0.0046723763029584255 and parameters: {'max_depth': 20, 'min_samples_leaf': 8, 'max_leaf_nodes': 69}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:28,094]\u001b[0m Trial 31 finished with value: 0.004542857144739812 and parameters: {'max_depth': 36, 'min_samples_leaf': 8, 'max_leaf_nodes': 93}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:28,227]\u001b[0m Trial 32 finished with value: 0.004581398453867969 and parameters: {'max_depth': 36, 'min_samples_leaf': 9, 'max_leaf_nodes': 81}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:28,365]\u001b[0m Trial 33 finished with value: 0.004637154290113819 and parameters: {'max_depth': 48, 'min_samples_leaf': 7, 'max_leaf_nodes': 91}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:28,504]\u001b[0m Trial 34 finished with value: 0.004605281687687843 and parameters: {'max_depth': 31, 'min_samples_leaf': 9, 'max_leaf_nodes': 86}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:28,638]\u001b[0m Trial 35 finished with value: 0.004541801595556054 and parameters: {'max_depth': 16, 'min_samples_leaf': 8, 'max_leaf_nodes': 96}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:28,770]\u001b[0m Trial 36 finished with value: 0.0047541397464365325 and parameters: {'max_depth': 14, 'min_samples_leaf': 6, 'max_leaf_nodes': 78}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:28,910]\u001b[0m Trial 37 finished with value: 0.004677929605819875 and parameters: {'max_depth': 15, 'min_samples_leaf': 7, 'max_leaf_nodes': 96}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:29,052]\u001b[0m Trial 38 finished with value: 0.004615933210892673 and parameters: {'max_depth': 17, 'min_samples_leaf': 9, 'max_leaf_nodes': 85}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:29,173]\u001b[0m Trial 39 finished with value: 0.005195920723297388 and parameters: {'max_depth': 25, 'min_samples_leaf': 8, 'max_leaf_nodes': 34}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:29,311]\u001b[0m Trial 40 finished with value: 0.004744932224145598 and parameters: {'max_depth': 74, 'min_samples_leaf': 5, 'max_leaf_nodes': 100}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:29,448]\u001b[0m Trial 41 finished with value: 0.0045405807425621236 and parameters: {'max_depth': 11, 'min_samples_leaf': 8, 'max_leaf_nodes': 92}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:29,596]\u001b[0m Trial 42 finished with value: 0.004592498749001295 and parameters: {'max_depth': 11, 'min_samples_leaf': 9, 'max_leaf_nodes': 85}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:29,729]\u001b[0m Trial 43 finished with value: 0.004560946385153747 and parameters: {'max_depth': 13, 'min_samples_leaf': 8, 'max_leaf_nodes': 79}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:29,865]\u001b[0m Trial 44 finished with value: 0.004649110155472559 and parameters: {'max_depth': 11, 'min_samples_leaf': 7, 'max_leaf_nodes': 95}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:29,998]\u001b[0m Trial 45 finished with value: 0.004911243850037271 and parameters: {'max_depth': 12, 'min_samples_leaf': 1, 'max_leaf_nodes': 88}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:30,135]\u001b[0m Trial 46 finished with value: 0.004663629192843794 and parameters: {'max_depth': 27, 'min_samples_leaf': 9, 'max_leaf_nodes': 72}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:30,268]\u001b[0m Trial 47 finished with value: 0.004547368567196646 and parameters: {'max_depth': 16, 'min_samples_leaf': 8, 'max_leaf_nodes': 95}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:30,369]\u001b[0m Trial 48 finished with value: 0.006472550380672174 and parameters: {'max_depth': 22, 'min_samples_leaf': 7, 'max_leaf_nodes': 9}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:30,511]\u001b[0m Trial 49 finished with value: 0.004644529924159673 and parameters: {'max_depth': 10, 'min_samples_leaf': 9, 'max_leaf_nodes': 100}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:30,648]\u001b[0m Trial 50 finished with value: 0.00481065602611049 and parameters: {'max_depth': 18, 'min_samples_leaf': 4, 'max_leaf_nodes': 83}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:30,783]\u001b[0m Trial 51 finished with value: 0.004540580742562123 and parameters: {'max_depth': 29, 'min_samples_leaf': 8, 'max_leaf_nodes': 92}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:30,918]\u001b[0m Trial 52 finished with value: 0.004533734408447345 and parameters: {'max_depth': 85, 'min_samples_leaf': 8, 'max_leaf_nodes': 88}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:31,055]\u001b[0m Trial 53 finished with value: 0.004779431372341306 and parameters: {'max_depth': 91, 'min_samples_leaf': 7, 'max_leaf_nodes': 77}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:31,191]\u001b[0m Trial 54 finished with value: 0.0045816489761496965 and parameters: {'max_depth': 70, 'min_samples_leaf': 9, 'max_leaf_nodes': 88}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:31,332]\u001b[0m Trial 55 finished with value: 0.004580818627504554 and parameters: {'max_depth': 80, 'min_samples_leaf': 10, 'max_leaf_nodes': 91}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:31,466]\u001b[0m Trial 56 finished with value: 0.004657077569419981 and parameters: {'max_depth': 84, 'min_samples_leaf': 8, 'max_leaf_nodes': 72}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:31,626]\u001b[0m Trial 57 finished with value: 0.004583718559674423 and parameters: {'max_depth': 66, 'min_samples_leaf': 9, 'max_leaf_nodes': 82}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:31,752]\u001b[0m Trial 58 finished with value: 0.005032818606970915 and parameters: {'max_depth': 41, 'min_samples_leaf': 6, 'max_leaf_nodes': 45}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:31,891]\u001b[0m Trial 59 finished with value: 0.004531099529027843 and parameters: {'max_depth': 100, 'min_samples_leaf': 8, 'max_leaf_nodes': 87}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:32,022]\u001b[0m Trial 60 finished with value: 0.004760692974273348 and parameters: {'max_depth': 56, 'min_samples_leaf': 7, 'max_leaf_nodes': 62}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:32,159]\u001b[0m Trial 61 finished with value: 0.0045405807425621236 and parameters: {'max_depth': 98, 'min_samples_leaf': 8, 'max_leaf_nodes': 92}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:32,296]\u001b[0m Trial 62 finished with value: 0.004531099529027844 and parameters: {'max_depth': 95, 'min_samples_leaf': 8, 'max_leaf_nodes': 87}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:32,439]\u001b[0m Trial 63 finished with value: 0.004533734408447345 and parameters: {'max_depth': 87, 'min_samples_leaf': 8, 'max_leaf_nodes': 88}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:32,576]\u001b[0m Trial 64 finished with value: 0.0046964666744681634 and parameters: {'max_depth': 88, 'min_samples_leaf': 7, 'max_leaf_nodes': 86}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:32,709]\u001b[0m Trial 65 finished with value: 0.004609694250300059 and parameters: {'max_depth': 96, 'min_samples_leaf': 9, 'max_leaf_nodes': 75}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:32,853]\u001b[0m Trial 66 finished with value: 0.004533734408447345 and parameters: {'max_depth': 79, 'min_samples_leaf': 8, 'max_leaf_nodes': 88}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:32,994]\u001b[0m Trial 67 finished with value: 0.0046723763029584255 and parameters: {'max_depth': 79, 'min_samples_leaf': 8, 'max_leaf_nodes': 69}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:33,132]\u001b[0m Trial 68 finished with value: 0.0045740308028700315 and parameters: {'max_depth': 67, 'min_samples_leaf': 10, 'max_leaf_nodes': 88}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:33,267]\u001b[0m Trial 69 finished with value: 0.0047002486188526815 and parameters: {'max_depth': 86, 'min_samples_leaf': 7, 'max_leaf_nodes': 83}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:33,404]\u001b[0m Trial 70 finished with value: 0.004589244420856973 and parameters: {'max_depth': 75, 'min_samples_leaf': 10, 'max_leaf_nodes': 80}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:33,549]\u001b[0m Trial 71 finished with value: 0.004541801595556054 and parameters: {'max_depth': 92, 'min_samples_leaf': 8, 'max_leaf_nodes': 96}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:33,687]\u001b[0m Trial 72 finished with value: 0.004531099529027843 and parameters: {'max_depth': 81, 'min_samples_leaf': 8, 'max_leaf_nodes': 87}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:33,823]\u001b[0m Trial 73 finished with value: 0.004607916567107345 and parameters: {'max_depth': 81, 'min_samples_leaf': 9, 'max_leaf_nodes': 87}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:33,961]\u001b[0m Trial 74 finished with value: 0.004700248618852681 and parameters: {'max_depth': 63, 'min_samples_leaf': 7, 'max_leaf_nodes': 83}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:34,098]\u001b[0m Trial 75 finished with value: 0.005160857292615128 and parameters: {'max_depth': 96, 'min_samples_leaf': 2, 'max_leaf_nodes': 77}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:34,217]\u001b[0m Trial 76 finished with value: 0.0053855622136069 and parameters: {'max_depth': 99, 'min_samples_leaf': 8, 'max_leaf_nodes': 23}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:34,360]\u001b[0m Trial 77 finished with value: 0.004542818484266338 and parameters: {'max_depth': 75, 'min_samples_leaf': 8, 'max_leaf_nodes': 98}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:34,498]\u001b[0m Trial 78 finished with value: 0.0045309012793810725 and parameters: {'max_depth': 59, 'min_samples_leaf': 8, 'max_leaf_nodes': 89}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:34,651]\u001b[0m Trial 79 finished with value: 0.004713220538941826 and parameters: {'max_depth': 60, 'min_samples_leaf': 6, 'max_leaf_nodes': 80}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:34,789]\u001b[0m Trial 80 finished with value: 0.004646833753294871 and parameters: {'max_depth': 70, 'min_samples_leaf': 7, 'max_leaf_nodes': 94}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:34,929]\u001b[0m Trial 81 finished with value: 0.004538983495917568 and parameters: {'max_depth': 46, 'min_samples_leaf': 8, 'max_leaf_nodes': 90}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:35,065]\u001b[0m Trial 82 finished with value: 0.004556244597953569 and parameters: {'max_depth': 49, 'min_samples_leaf': 8, 'max_leaf_nodes': 85}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:35,199]\u001b[0m Trial 83 finished with value: 0.004530901279381072 and parameters: {'max_depth': 84, 'min_samples_leaf': 8, 'max_leaf_nodes': 89}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:35,333]\u001b[0m Trial 84 finished with value: 0.004589731192686194 and parameters: {'max_depth': 84, 'min_samples_leaf': 9, 'max_leaf_nodes': 89}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:35,480]\u001b[0m Trial 85 finished with value: 0.004542437096586814 and parameters: {'max_depth': 89, 'min_samples_leaf': 8, 'max_leaf_nodes': 97}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:35,624]\u001b[0m Trial 86 finished with value: 0.004552062739320608 and parameters: {'max_depth': 76, 'min_samples_leaf': 8, 'max_leaf_nodes': 83}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:35,755]\u001b[0m Trial 87 finished with value: 0.004892345855121198 and parameters: {'max_depth': 70, 'min_samples_leaf': 7, 'max_leaf_nodes': 55}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:35,895]\u001b[0m Trial 88 finished with value: 0.004581847225796468 and parameters: {'max_depth': 93, 'min_samples_leaf': 9, 'max_leaf_nodes': 86}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:36,033]\u001b[0m Trial 89 finished with value: 0.00457167659508713 and parameters: {'max_depth': 53, 'min_samples_leaf': 8, 'max_leaf_nodes': 94}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:36,166]\u001b[0m Trial 90 finished with value: 0.0045884203468745995 and parameters: {'max_depth': 84, 'min_samples_leaf': 9, 'max_leaf_nodes': 76}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:36,303]\u001b[0m Trial 91 finished with value: 0.0045309012793810725 and parameters: {'max_depth': 79, 'min_samples_leaf': 8, 'max_leaf_nodes': 89}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:36,441]\u001b[0m Trial 92 finished with value: 0.004530901279381072 and parameters: {'max_depth': 78, 'min_samples_leaf': 8, 'max_leaf_nodes': 89}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:36,584]\u001b[0m Trial 93 finished with value: 0.004538983495917568 and parameters: {'max_depth': 64, 'min_samples_leaf': 8, 'max_leaf_nodes': 90}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:36,724]\u001b[0m Trial 94 finished with value: 0.00475737798165778 and parameters: {'max_depth': 100, 'min_samples_leaf': 7, 'max_leaf_nodes': 79}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:36,865]\u001b[0m Trial 95 finished with value: 0.004622424291855753 and parameters: {'max_depth': 89, 'min_samples_leaf': 9, 'max_leaf_nodes': 93}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:37,004]\u001b[0m Trial 96 finished with value: 0.0045562445979535696 and parameters: {'max_depth': 78, 'min_samples_leaf': 8, 'max_leaf_nodes': 85}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:37,129]\u001b[0m Trial 97 finished with value: 0.005153530627981131 and parameters: {'max_depth': 72, 'min_samples_leaf': 7, 'max_leaf_nodes': 36}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:37,266]\u001b[0m Trial 98 finished with value: 0.0046185461940526406 and parameters: {'max_depth': 82, 'min_samples_leaf': 9, 'max_leaf_nodes': 99}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:37,403]\u001b[0m Trial 99 finished with value: 0.004556972477634315 and parameters: {'max_depth': 93, 'min_samples_leaf': 8, 'max_leaf_nodes': 81}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:37,538]\u001b[0m Trial 100 finished with value: 0.004531099529027843 and parameters: {'max_depth': 57, 'min_samples_leaf': 8, 'max_leaf_nodes': 87}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:37,690]\u001b[0m Trial 101 finished with value: 0.004531099529027842 and parameters: {'max_depth': 68, 'min_samples_leaf': 8, 'max_leaf_nodes': 87}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:37,828]\u001b[0m Trial 102 finished with value: 0.004538983495917567 and parameters: {'max_depth': 58, 'min_samples_leaf': 8, 'max_leaf_nodes': 90}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:37,967]\u001b[0m Trial 103 finished with value: 0.004553924492147116 and parameters: {'max_depth': 57, 'min_samples_leaf': 8, 'max_leaf_nodes': 84}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:38,107]\u001b[0m Trial 104 finished with value: 0.0046819731287472644 and parameters: {'max_depth': 66, 'min_samples_leaf': 7, 'max_leaf_nodes': 87}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:38,244]\u001b[0m Trial 105 finished with value: 0.004571676595087128 and parameters: {'max_depth': 54, 'min_samples_leaf': 8, 'max_leaf_nodes': 94}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:38,387]\u001b[0m Trial 106 finished with value: 0.004593604841508439 and parameters: {'max_depth': 61, 'min_samples_leaf': 9, 'max_leaf_nodes': 92}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:38,525]\u001b[0m Trial 107 finished with value: 0.00454175105223267 and parameters: {'max_depth': 68, 'min_samples_leaf': 8, 'max_leaf_nodes': 86}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:38,665]\u001b[0m Trial 108 finished with value: 0.004704222526372112 and parameters: {'max_depth': 73, 'min_samples_leaf': 7, 'max_leaf_nodes': 81}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:38,752]\u001b[0m Trial 109 finished with value: 0.009383941289509283 and parameters: {'max_depth': 88, 'min_samples_leaf': 4, 'max_leaf_nodes': 2}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:38,892]\u001b[0m Trial 110 finished with value: 0.004530901279381072 and parameters: {'max_depth': 78, 'min_samples_leaf': 8, 'max_leaf_nodes': 89}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:39,031]\u001b[0m Trial 111 finished with value: 0.004530901279381072 and parameters: {'max_depth': 77, 'min_samples_leaf': 8, 'max_leaf_nodes': 89}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:39,174]\u001b[0m Trial 112 finished with value: 0.004554029528426176 and parameters: {'max_depth': 76, 'min_samples_leaf': 8, 'max_leaf_nodes': 91}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:39,313]\u001b[0m Trial 113 finished with value: 0.004542437096586812 and parameters: {'max_depth': 63, 'min_samples_leaf': 8, 'max_leaf_nodes': 97}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:39,451]\u001b[0m Trial 114 finished with value: 0.004553924492147114 and parameters: {'max_depth': 81, 'min_samples_leaf': 8, 'max_leaf_nodes': 84}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:39,590]\u001b[0m Trial 115 finished with value: 0.00463735253976059 and parameters: {'max_depth': 71, 'min_samples_leaf': 7, 'max_leaf_nodes': 89}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:39,737]\u001b[0m Trial 116 finished with value: 0.0046159837542160565 and parameters: {'max_depth': 67, 'min_samples_leaf': 9, 'max_leaf_nodes': 95}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:39,876]\u001b[0m Trial 117 finished with value: 0.004560026542338087 and parameters: {'max_depth': 78, 'min_samples_leaf': 8, 'max_leaf_nodes': 82}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:40,021]\u001b[0m Trial 118 finished with value: 0.004531099529027843 and parameters: {'max_depth': 60, 'min_samples_leaf': 8, 'max_leaf_nodes': 87}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:40,159]\u001b[0m Trial 119 finished with value: 0.004617039303399814 and parameters: {'max_depth': 44, 'min_samples_leaf': 9, 'max_leaf_nodes': 92}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:40,298]\u001b[0m Trial 120 finished with value: 0.004560946385153747 and parameters: {'max_depth': 60, 'min_samples_leaf': 8, 'max_leaf_nodes': 79}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:40,440]\u001b[0m Trial 121 finished with value: 0.004531099529027843 and parameters: {'max_depth': 51, 'min_samples_leaf': 8, 'max_leaf_nodes': 87}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:40,579]\u001b[0m Trial 122 finished with value: 0.00453898349591757 and parameters: {'max_depth': 49, 'min_samples_leaf': 8, 'max_leaf_nodes': 90}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:40,724]\u001b[0m Trial 123 finished with value: 0.00454175105223267 and parameters: {'max_depth': 55, 'min_samples_leaf': 8, 'max_leaf_nodes': 86}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:40,862]\u001b[0m Trial 124 finished with value: 0.004533734408447345 and parameters: {'max_depth': 64, 'min_samples_leaf': 8, 'max_leaf_nodes': 88}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:41,001]\u001b[0m Trial 125 finished with value: 0.004553924492147114 and parameters: {'max_depth': 52, 'min_samples_leaf': 8, 'max_leaf_nodes': 84}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:41,143]\u001b[0m Trial 126 finished with value: 0.004622424291855755 and parameters: {'max_depth': 60, 'min_samples_leaf': 9, 'max_leaf_nodes': 93}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:41,280]\u001b[0m Trial 127 finished with value: 0.0046399874191800925 and parameters: {'max_depth': 50, 'min_samples_leaf': 7, 'max_leaf_nodes': 90}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:41,421]\u001b[0m Trial 128 finished with value: 0.004703130995038942 and parameters: {'max_depth': 58, 'min_samples_leaf': 7, 'max_leaf_nodes': 82}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:41,565]\u001b[0m Trial 129 finished with value: 0.0045418015955560566 and parameters: {'max_depth': 69, 'min_samples_leaf': 8, 'max_leaf_nodes': 96}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:41,709]\u001b[0m Trial 130 finished with value: 0.004541751052232671 and parameters: {'max_depth': 39, 'min_samples_leaf': 8, 'max_leaf_nodes': 86}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:41,849]\u001b[0m Trial 131 finished with value: 0.004533734408447346 and parameters: {'max_depth': 95, 'min_samples_leaf': 8, 'max_leaf_nodes': 88}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:41,988]\u001b[0m Trial 132 finished with value: 0.004541751052232671 and parameters: {'max_depth': 73, 'min_samples_leaf': 8, 'max_leaf_nodes': 86}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:42,125]\u001b[0m Trial 133 finished with value: 0.0045405807425621236 and parameters: {'max_depth': 47, 'min_samples_leaf': 8, 'max_leaf_nodes': 92}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:42,264]\u001b[0m Trial 134 finished with value: 0.0045816489761496965 and parameters: {'max_depth': 87, 'min_samples_leaf': 9, 'max_leaf_nodes': 88}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:42,406]\u001b[0m Trial 135 finished with value: 0.00455206273932061 and parameters: {'max_depth': 83, 'min_samples_leaf': 8, 'max_leaf_nodes': 83}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:42,550]\u001b[0m Trial 136 finished with value: 0.004571676595087129 and parameters: {'max_depth': 77, 'min_samples_leaf': 8, 'max_leaf_nodes': 94}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:42,697]\u001b[0m Trial 137 finished with value: 0.0045389834959175665 and parameters: {'max_depth': 93, 'min_samples_leaf': 8, 'max_leaf_nodes': 90}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:42,838]\u001b[0m Trial 138 finished with value: 0.004694146568661707 and parameters: {'max_depth': 64, 'min_samples_leaf': 7, 'max_leaf_nodes': 85}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:42,983]\u001b[0m Trial 139 finished with value: 0.0045822202885792045 and parameters: {'max_depth': 55, 'min_samples_leaf': 8, 'max_leaf_nodes': 78}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:43,126]\u001b[0m Trial 140 finished with value: 0.004747731069910295 and parameters: {'max_depth': 81, 'min_samples_leaf': 3, 'max_leaf_nodes': 87}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:43,264]\u001b[0m Trial 141 finished with value: 0.004530901279381072 and parameters: {'max_depth': 63, 'min_samples_leaf': 8, 'max_leaf_nodes': 89}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:43,401]\u001b[0m Trial 142 finished with value: 0.004554029528426177 and parameters: {'max_depth': 74, 'min_samples_leaf': 8, 'max_leaf_nodes': 91}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:43,540]\u001b[0m Trial 143 finished with value: 0.004530901279381072 and parameters: {'max_depth': 100, 'min_samples_leaf': 8, 'max_leaf_nodes': 89}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:43,683]\u001b[0m Trial 144 finished with value: 0.0045309012793810725 and parameters: {'max_depth': 61, 'min_samples_leaf': 8, 'max_leaf_nodes': 89}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:43,824]\u001b[0m Trial 145 finished with value: 0.004542857144739811 and parameters: {'max_depth': 58, 'min_samples_leaf': 8, 'max_leaf_nodes': 93}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:43,967]\u001b[0m Trial 146 finished with value: 0.004596977126780946 and parameters: {'max_depth': 66, 'min_samples_leaf': 9, 'max_leaf_nodes': 98}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:44,107]\u001b[0m Trial 147 finished with value: 0.004530901279381072 and parameters: {'max_depth': 62, 'min_samples_leaf': 8, 'max_leaf_nodes': 89}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:44,253]\u001b[0m Trial 148 finished with value: 0.004530901279381072 and parameters: {'max_depth': 61, 'min_samples_leaf': 8, 'max_leaf_nodes': 89}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:44,393]\u001b[0m Trial 149 finished with value: 0.004639987419180093 and parameters: {'max_depth': 63, 'min_samples_leaf': 7, 'max_leaf_nodes': 90}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:44,542]\u001b[0m Trial 150 finished with value: 0.004592549292324682 and parameters: {'max_depth': 68, 'min_samples_leaf': 9, 'max_leaf_nodes': 95}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:44,681]\u001b[0m Trial 151 finished with value: 0.004530901279381072 and parameters: {'max_depth': 60, 'min_samples_leaf': 8, 'max_leaf_nodes': 89}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:44,832]\u001b[0m Trial 152 finished with value: 0.0045405807425621236 and parameters: {'max_depth': 70, 'min_samples_leaf': 8, 'max_leaf_nodes': 92}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:44,974]\u001b[0m Trial 153 finished with value: 0.004538983495917568 and parameters: {'max_depth': 61, 'min_samples_leaf': 8, 'max_leaf_nodes': 90}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:45,117]\u001b[0m Trial 154 finished with value: 0.004530901279381072 and parameters: {'max_depth': 56, 'min_samples_leaf': 8, 'max_leaf_nodes': 89}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:45,256]\u001b[0m Trial 155 finished with value: 0.004530901279381072 and parameters: {'max_depth': 54, 'min_samples_leaf': 8, 'max_leaf_nodes': 89}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:45,403]\u001b[0m Trial 156 finished with value: 0.004571676595087128 and parameters: {'max_depth': 54, 'min_samples_leaf': 8, 'max_leaf_nodes': 94}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:45,553]\u001b[0m Trial 157 finished with value: 0.0045309012793810725 and parameters: {'max_depth': 56, 'min_samples_leaf': 8, 'max_leaf_nodes': 89}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:45,693]\u001b[0m Trial 158 finished with value: 0.004530901279381072 and parameters: {'max_depth': 56, 'min_samples_leaf': 8, 'max_leaf_nodes': 89}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:45,846]\u001b[0m Trial 159 finished with value: 0.004670025994719991 and parameters: {'max_depth': 56, 'min_samples_leaf': 5, 'max_leaf_nodes': 96}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:45,984]\u001b[0m Trial 160 finished with value: 0.004554029528426179 and parameters: {'max_depth': 61, 'min_samples_leaf': 8, 'max_leaf_nodes': 91}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:46,123]\u001b[0m Trial 161 finished with value: 0.0045562445979535696 and parameters: {'max_depth': 53, 'min_samples_leaf': 8, 'max_leaf_nodes': 85}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:46,267]\u001b[0m Trial 162 finished with value: 0.004530901279381072 and parameters: {'max_depth': 51, 'min_samples_leaf': 8, 'max_leaf_nodes': 89}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:46,408]\u001b[0m Trial 163 finished with value: 0.0045309012793810725 and parameters: {'max_depth': 59, 'min_samples_leaf': 8, 'max_leaf_nodes': 89}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:46,551]\u001b[0m Trial 164 finished with value: 0.0045405807425621236 and parameters: {'max_depth': 52, 'min_samples_leaf': 8, 'max_leaf_nodes': 92}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:46,692]\u001b[0m Trial 165 finished with value: 0.004530901279381072 and parameters: {'max_depth': 47, 'min_samples_leaf': 8, 'max_leaf_nodes': 89}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:46,842]\u001b[0m Trial 166 finished with value: 0.004553924492147114 and parameters: {'max_depth': 48, 'min_samples_leaf': 8, 'max_leaf_nodes': 84}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:46,981]\u001b[0m Trial 167 finished with value: 0.004660282539158925 and parameters: {'max_depth': 45, 'min_samples_leaf': 7, 'max_leaf_nodes': 93}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:47,126]\u001b[0m Trial 168 finished with value: 0.004554029528426177 and parameters: {'max_depth': 42, 'min_samples_leaf': 8, 'max_leaf_nodes': 91}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:47,276]\u001b[0m Trial 169 finished with value: 0.004530901279381072 and parameters: {'max_depth': 50, 'min_samples_leaf': 8, 'max_leaf_nodes': 89}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:47,415]\u001b[0m Trial 170 finished with value: 0.004553924492147115 and parameters: {'max_depth': 48, 'min_samples_leaf': 8, 'max_leaf_nodes': 84}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:47,556]\u001b[0m Trial 171 finished with value: 0.004530901279381072 and parameters: {'max_depth': 53, 'min_samples_leaf': 8, 'max_leaf_nodes': 89}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:47,698]\u001b[0m Trial 172 finished with value: 0.004533734408447346 and parameters: {'max_depth': 51, 'min_samples_leaf': 8, 'max_leaf_nodes': 88}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:47,836]\u001b[0m Trial 173 finished with value: 0.004909968036943486 and parameters: {'max_depth': 53, 'min_samples_leaf': 8, 'max_leaf_nodes': 49}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:47,977]\u001b[0m Trial 174 finished with value: 0.004530901279381072 and parameters: {'max_depth': 56, 'min_samples_leaf': 8, 'max_leaf_nodes': 89}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:48,116]\u001b[0m Trial 175 finished with value: 0.004542857144739812 and parameters: {'max_depth': 50, 'min_samples_leaf': 8, 'max_leaf_nodes': 93}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:48,256]\u001b[0m Trial 176 finished with value: 0.004592498749001296 and parameters: {'max_depth': 55, 'min_samples_leaf': 9, 'max_leaf_nodes': 85}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:48,394]\u001b[0m Trial 177 finished with value: 0.004554029528426177 and parameters: {'max_depth': 45, 'min_samples_leaf': 8, 'max_leaf_nodes': 91}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:48,538]\u001b[0m Trial 178 finished with value: 0.004560026542338086 and parameters: {'max_depth': 51, 'min_samples_leaf': 8, 'max_leaf_nodes': 82}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:48,656]\u001b[0m Trial 179 finished with value: 0.005743934034270239 and parameters: {'max_depth': 56, 'min_samples_leaf': 9, 'max_leaf_nodes': 16}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:48,801]\u001b[0m Trial 180 finished with value: 0.004649110155472559 and parameters: {'max_depth': 38, 'min_samples_leaf': 7, 'max_leaf_nodes': 95}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:48,947]\u001b[0m Trial 181 finished with value: 0.0045309012793810725 and parameters: {'max_depth': 57, 'min_samples_leaf': 8, 'max_leaf_nodes': 89}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:49,088]\u001b[0m Trial 182 finished with value: 0.004530901279381072 and parameters: {'max_depth': 63, 'min_samples_leaf': 8, 'max_leaf_nodes': 89}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:49,238]\u001b[0m Trial 183 finished with value: 0.00454175105223267 and parameters: {'max_depth': 63, 'min_samples_leaf': 8, 'max_leaf_nodes': 86}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:49,379]\u001b[0m Trial 184 finished with value: 0.004538983495917568 and parameters: {'max_depth': 54, 'min_samples_leaf': 8, 'max_leaf_nodes': 90}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:49,520]\u001b[0m Trial 185 finished with value: 0.004533734408447345 and parameters: {'max_depth': 47, 'min_samples_leaf': 8, 'max_leaf_nodes': 88}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:49,666]\u001b[0m Trial 186 finished with value: 0.0045405807425621236 and parameters: {'max_depth': 50, 'min_samples_leaf': 8, 'max_leaf_nodes': 92}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:49,810]\u001b[0m Trial 187 finished with value: 0.00454175105223267 and parameters: {'max_depth': 64, 'min_samples_leaf': 8, 'max_leaf_nodes': 86}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:49,954]\u001b[0m Trial 188 finished with value: 0.004554029528426179 and parameters: {'max_depth': 53, 'min_samples_leaf': 8, 'max_leaf_nodes': 91}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:50,094]\u001b[0m Trial 189 finished with value: 0.004571676595087128 and parameters: {'max_depth': 59, 'min_samples_leaf': 8, 'max_leaf_nodes': 94}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:50,240]\u001b[0m Trial 190 finished with value: 0.005032182878279115 and parameters: {'max_depth': 66, 'min_samples_leaf': 2, 'max_leaf_nodes': 88}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:50,384]\u001b[0m Trial 191 finished with value: 0.0045309012793810725 and parameters: {'max_depth': 57, 'min_samples_leaf': 8, 'max_leaf_nodes': 89}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:50,529]\u001b[0m Trial 192 finished with value: 0.004554029528426177 and parameters: {'max_depth': 56, 'min_samples_leaf': 8, 'max_leaf_nodes': 91}. Best is trial 24 with value: 0.004530901279381072.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:50,688]\u001b[0m Trial 193 finished with value: 0.004530901279381071 and parameters: {'max_depth': 61, 'min_samples_leaf': 8, 'max_leaf_nodes': 89}. Best is trial 193 with value: 0.004530901279381071.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:50,838]\u001b[0m Trial 194 finished with value: 0.004553924492147113 and parameters: {'max_depth': 61, 'min_samples_leaf': 8, 'max_leaf_nodes': 84}. Best is trial 193 with value: 0.004530901279381071.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:50,987]\u001b[0m Trial 195 finished with value: 0.004531099529027843 and parameters: {'max_depth': 65, 'min_samples_leaf': 8, 'max_leaf_nodes': 87}. Best is trial 193 with value: 0.004530901279381071.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:51,132]\u001b[0m Trial 196 finished with value: 0.004542857144739812 and parameters: {'max_depth': 53, 'min_samples_leaf': 8, 'max_leaf_nodes': 93}. Best is trial 193 with value: 0.004530901279381071.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:51,280]\u001b[0m Trial 197 finished with value: 0.004530901279381072 and parameters: {'max_depth': 58, 'min_samples_leaf': 8, 'max_leaf_nodes': 89}. Best is trial 193 with value: 0.004530901279381071.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:51,421]\u001b[0m Trial 198 finished with value: 0.004541751052232671 and parameters: {'max_depth': 59, 'min_samples_leaf': 8, 'max_leaf_nodes': 86}. Best is trial 193 with value: 0.004530901279381071.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:51,568]\u001b[0m Trial 199 finished with value: 0.004554029528426177 and parameters: {'max_depth': 50, 'min_samples_leaf': 8, 'max_leaf_nodes': 91}. Best is trial 193 with value: 0.004530901279381071.\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uq3APpGXvGD2",
        "outputId": "43733b49-d3c0-4e5b-f526-834d049b639a"
      },
      "source": [
        "trial = study_decisiontree.best_trial\n",
        "print(f'MSE: {trial.value}')\n",
        "print(f'Best hyperparameters: {trial.params}')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE: 0.004530901279381071\n",
            "Best hyperparameters: {'max_depth': 61, 'min_samples_leaf': 8, 'max_leaf_nodes': 89}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "BjBbjQ0QvTUg",
        "outputId": "a8d4d064-cd69-4ebe-a627-de971aed1beb"
      },
      "source": [
        "optuna.visualization.plot_optimization_history(study_decisiontree)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"791ed185-c8ca-4188-8302-7e2a73cab174\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"791ed185-c8ca-4188-8302-7e2a73cab174\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '791ed185-c8ca-4188-8302-7e2a73cab174',\n",
              "                        [{\"mode\": \"markers\", \"name\": \"Objective Value\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199], \"y\": [0.006105077510555661, 0.004615220111482611, 0.004733355288067668, 0.004809605282150507, 0.0055040832833616665, 0.005029665162426492, 0.004938743206474557, 0.00483585006445534, 0.004964842824841498, 0.009383941289509286, 0.0048574549420257445, 0.0046838530403632075, 0.004754460598938891, 0.004740187774751588, 0.004617410875175973, 0.004614385899170579, 0.00480749372375126, 0.004756715496287527, 0.00460425308939593, 0.004542857144739812, 0.005248655727882804, 0.004540580742562123, 0.004538983495917568, 0.004624905575201242, 0.004530901279381072, 0.0048406488003686155, 0.004556972477634315, 0.00463735253976059, 0.004755965467227116, 0.005001137835558552, 0.0046723763029584255, 0.004542857144739812, 0.004581398453867969, 0.004637154290113819, 0.004605281687687843, 0.004541801595556054, 0.0047541397464365325, 0.004677929605819875, 0.004615933210892673, 0.005195920723297388, 0.004744932224145598, 0.0045405807425621236, 0.004592498749001295, 0.004560946385153747, 0.004649110155472559, 0.004911243850037271, 0.004663629192843794, 0.004547368567196646, 0.006472550380672174, 0.004644529924159673, 0.00481065602611049, 0.004540580742562123, 0.004533734408447345, 0.004779431372341306, 0.0045816489761496965, 0.004580818627504554, 0.004657077569419981, 0.004583718559674423, 0.005032818606970915, 0.004531099529027843, 0.004760692974273348, 0.0045405807425621236, 0.004531099529027844, 0.004533734408447345, 0.0046964666744681634, 0.004609694250300059, 0.004533734408447345, 0.0046723763029584255, 0.0045740308028700315, 0.0047002486188526815, 0.004589244420856973, 0.004541801595556054, 0.004531099529027843, 0.004607916567107345, 0.004700248618852681, 0.005160857292615128, 0.0053855622136069, 0.004542818484266338, 0.0045309012793810725, 0.004713220538941826, 0.004646833753294871, 0.004538983495917568, 0.004556244597953569, 0.004530901279381072, 0.004589731192686194, 0.004542437096586814, 0.004552062739320608, 0.004892345855121198, 0.004581847225796468, 0.00457167659508713, 0.0045884203468745995, 0.0045309012793810725, 0.004530901279381072, 0.004538983495917568, 0.00475737798165778, 0.004622424291855753, 0.0045562445979535696, 0.005153530627981131, 0.0046185461940526406, 0.004556972477634315, 0.004531099529027843, 0.004531099529027842, 0.004538983495917567, 0.004553924492147116, 0.0046819731287472644, 0.004571676595087128, 0.004593604841508439, 0.00454175105223267, 0.004704222526372112, 0.009383941289509283, 0.004530901279381072, 0.004530901279381072, 0.004554029528426176, 0.004542437096586812, 0.004553924492147114, 0.00463735253976059, 0.0046159837542160565, 0.004560026542338087, 0.004531099529027843, 0.004617039303399814, 0.004560946385153747, 0.004531099529027843, 0.00453898349591757, 0.00454175105223267, 0.004533734408447345, 0.004553924492147114, 0.004622424291855755, 0.0046399874191800925, 0.004703130995038942, 0.0045418015955560566, 0.004541751052232671, 0.004533734408447346, 0.004541751052232671, 0.0045405807425621236, 0.0045816489761496965, 0.00455206273932061, 0.004571676595087129, 0.0045389834959175665, 0.004694146568661707, 0.0045822202885792045, 0.004747731069910295, 0.004530901279381072, 0.004554029528426177, 0.004530901279381072, 0.0045309012793810725, 0.004542857144739811, 0.004596977126780946, 0.004530901279381072, 0.004530901279381072, 0.004639987419180093, 0.004592549292324682, 0.004530901279381072, 0.0045405807425621236, 0.004538983495917568, 0.004530901279381072, 0.004530901279381072, 0.004571676595087128, 0.0045309012793810725, 0.004530901279381072, 0.004670025994719991, 0.004554029528426179, 0.0045562445979535696, 0.004530901279381072, 0.0045309012793810725, 0.0045405807425621236, 0.004530901279381072, 0.004553924492147114, 0.004660282539158925, 0.004554029528426177, 0.004530901279381072, 0.004553924492147115, 0.004530901279381072, 0.004533734408447346, 0.004909968036943486, 0.004530901279381072, 0.004542857144739812, 0.004592498749001296, 0.004554029528426177, 0.004560026542338086, 0.005743934034270239, 0.004649110155472559, 0.0045309012793810725, 0.004530901279381072, 0.00454175105223267, 0.004538983495917568, 0.004533734408447345, 0.0045405807425621236, 0.00454175105223267, 0.004554029528426179, 0.004571676595087128, 0.005032182878279115, 0.0045309012793810725, 0.004554029528426177, 0.004530901279381071, 0.004553924492147113, 0.004531099529027843, 0.004542857144739812, 0.004530901279381072, 0.004541751052232671, 0.004554029528426177]}, {\"name\": \"Best Value\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199], \"y\": [0.006105077510555661, 0.004615220111482611, 0.004615220111482611, 0.004615220111482611, 0.004615220111482611, 0.004615220111482611, 0.004615220111482611, 0.004615220111482611, 0.004615220111482611, 0.004615220111482611, 0.004615220111482611, 0.004615220111482611, 0.004615220111482611, 0.004615220111482611, 0.004615220111482611, 0.004614385899170579, 0.004614385899170579, 0.004614385899170579, 0.00460425308939593, 0.004542857144739812, 0.004542857144739812, 0.004540580742562123, 0.004538983495917568, 0.004538983495917568, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381072, 0.004530901279381071, 0.004530901279381071, 0.004530901279381071, 0.004530901279381071, 0.004530901279381071, 0.004530901279381071, 0.004530901279381071]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Optimization History Plot\"}, \"xaxis\": {\"title\": {\"text\": \"#Trials\"}}, \"yaxis\": {\"title\": {\"text\": \"Objective Value\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('791ed185-c8ca-4188-8302-7e2a73cab174');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "txRIy_G2vKF6",
        "outputId": "4a49448a-d442-4d33-ab24-7522ba0458f0"
      },
      "source": [
        "optuna.visualization.plot_slice(study_decisiontree)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"31f922ac-6bf4-4ab6-add8-56d3003064e4\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"31f922ac-6bf4-4ab6-add8-56d3003064e4\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '31f922ac-6bf4-4ab6-add8-56d3003064e4',\n",
              "                        [{\"marker\": {\"color\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199], \"colorbar\": {\"title\": {\"text\": \"#Trials\"}, \"x\": 1.0, \"xpad\": 40}, \"colorscale\": [[0.0, \"rgb(247,251,255)\"], [0.125, \"rgb(222,235,247)\"], [0.25, \"rgb(198,219,239)\"], [0.375, \"rgb(158,202,225)\"], [0.5, \"rgb(107,174,214)\"], [0.625, \"rgb(66,146,198)\"], [0.75, \"rgb(33,113,181)\"], [0.875, \"rgb(8,81,156)\"], [1.0, \"rgb(8,48,107)\"]], \"line\": {\"color\": \"Grey\", \"width\": 0.5}, \"showscale\": true}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [95, 42, 10, 89, 24, 45, 28, 79, 63, 99, 14, 9, 18, 39, 9, 41, 44, 58, 35, 32, 22, 34, 33, 31, 55, 61, 53, 73, 51, 26, 20, 36, 36, 48, 31, 16, 14, 15, 17, 25, 74, 11, 11, 13, 11, 12, 27, 16, 22, 10, 18, 29, 85, 91, 70, 80, 84, 66, 41, 100, 56, 98, 95, 87, 88, 96, 79, 79, 67, 86, 75, 92, 81, 81, 63, 96, 99, 75, 59, 60, 70, 46, 49, 84, 84, 89, 76, 70, 93, 53, 84, 79, 78, 64, 100, 89, 78, 72, 82, 93, 57, 68, 58, 57, 66, 54, 61, 68, 73, 88, 78, 77, 76, 63, 81, 71, 67, 78, 60, 44, 60, 51, 49, 55, 64, 52, 60, 50, 58, 69, 39, 95, 73, 47, 87, 83, 77, 93, 64, 55, 81, 63, 74, 100, 61, 58, 66, 62, 61, 63, 68, 60, 70, 61, 56, 54, 54, 56, 56, 56, 61, 53, 51, 59, 52, 47, 48, 45, 42, 50, 48, 53, 51, 53, 56, 50, 55, 45, 51, 56, 38, 57, 63, 63, 54, 47, 50, 64, 53, 59, 66, 57, 56, 61, 61, 65, 53, 58, 59, 50], \"xaxis\": \"x\", \"y\": [0.006105077510555661, 0.004615220111482611, 0.004733355288067668, 0.004809605282150507, 0.0055040832833616665, 0.005029665162426492, 0.004938743206474557, 0.00483585006445534, 0.004964842824841498, 0.009383941289509286, 0.0048574549420257445, 0.0046838530403632075, 0.004754460598938891, 0.004740187774751588, 0.004617410875175973, 0.004614385899170579, 0.00480749372375126, 0.004756715496287527, 0.00460425308939593, 0.004542857144739812, 0.005248655727882804, 0.004540580742562123, 0.004538983495917568, 0.004624905575201242, 0.004530901279381072, 0.0048406488003686155, 0.004556972477634315, 0.00463735253976059, 0.004755965467227116, 0.005001137835558552, 0.0046723763029584255, 0.004542857144739812, 0.004581398453867969, 0.004637154290113819, 0.004605281687687843, 0.004541801595556054, 0.0047541397464365325, 0.004677929605819875, 0.004615933210892673, 0.005195920723297388, 0.004744932224145598, 0.0045405807425621236, 0.004592498749001295, 0.004560946385153747, 0.004649110155472559, 0.004911243850037271, 0.004663629192843794, 0.004547368567196646, 0.006472550380672174, 0.004644529924159673, 0.00481065602611049, 0.004540580742562123, 0.004533734408447345, 0.004779431372341306, 0.0045816489761496965, 0.004580818627504554, 0.004657077569419981, 0.004583718559674423, 0.005032818606970915, 0.004531099529027843, 0.004760692974273348, 0.0045405807425621236, 0.004531099529027844, 0.004533734408447345, 0.0046964666744681634, 0.004609694250300059, 0.004533734408447345, 0.0046723763029584255, 0.0045740308028700315, 0.0047002486188526815, 0.004589244420856973, 0.004541801595556054, 0.004531099529027843, 0.004607916567107345, 0.004700248618852681, 0.005160857292615128, 0.0053855622136069, 0.004542818484266338, 0.0045309012793810725, 0.004713220538941826, 0.004646833753294871, 0.004538983495917568, 0.004556244597953569, 0.004530901279381072, 0.004589731192686194, 0.004542437096586814, 0.004552062739320608, 0.004892345855121198, 0.004581847225796468, 0.00457167659508713, 0.0045884203468745995, 0.0045309012793810725, 0.004530901279381072, 0.004538983495917568, 0.00475737798165778, 0.004622424291855753, 0.0045562445979535696, 0.005153530627981131, 0.0046185461940526406, 0.004556972477634315, 0.004531099529027843, 0.004531099529027842, 0.004538983495917567, 0.004553924492147116, 0.0046819731287472644, 0.004571676595087128, 0.004593604841508439, 0.00454175105223267, 0.004704222526372112, 0.009383941289509283, 0.004530901279381072, 0.004530901279381072, 0.004554029528426176, 0.004542437096586812, 0.004553924492147114, 0.00463735253976059, 0.0046159837542160565, 0.004560026542338087, 0.004531099529027843, 0.004617039303399814, 0.004560946385153747, 0.004531099529027843, 0.00453898349591757, 0.00454175105223267, 0.004533734408447345, 0.004553924492147114, 0.004622424291855755, 0.0046399874191800925, 0.004703130995038942, 0.0045418015955560566, 0.004541751052232671, 0.004533734408447346, 0.004541751052232671, 0.0045405807425621236, 0.0045816489761496965, 0.00455206273932061, 0.004571676595087129, 0.0045389834959175665, 0.004694146568661707, 0.0045822202885792045, 0.004747731069910295, 0.004530901279381072, 0.004554029528426177, 0.004530901279381072, 0.0045309012793810725, 0.004542857144739811, 0.004596977126780946, 0.004530901279381072, 0.004530901279381072, 0.004639987419180093, 0.004592549292324682, 0.004530901279381072, 0.0045405807425621236, 0.004538983495917568, 0.004530901279381072, 0.004530901279381072, 0.004571676595087128, 0.0045309012793810725, 0.004530901279381072, 0.004670025994719991, 0.004554029528426179, 0.0045562445979535696, 0.004530901279381072, 0.0045309012793810725, 0.0045405807425621236, 0.004530901279381072, 0.004553924492147114, 0.004660282539158925, 0.004554029528426177, 0.004530901279381072, 0.004553924492147115, 0.004530901279381072, 0.004533734408447346, 0.004909968036943486, 0.004530901279381072, 0.004542857144739812, 0.004592498749001296, 0.004554029528426177, 0.004560026542338086, 0.005743934034270239, 0.004649110155472559, 0.0045309012793810725, 0.004530901279381072, 0.00454175105223267, 0.004538983495917568, 0.004533734408447345, 0.0045405807425621236, 0.00454175105223267, 0.004554029528426179, 0.004571676595087128, 0.005032182878279115, 0.0045309012793810725, 0.004554029528426177, 0.004530901279381071, 0.004553924492147113, 0.004531099529027843, 0.004542857144739812, 0.004530901279381072, 0.004541751052232671, 0.004554029528426177], \"yaxis\": \"y\"}, {\"marker\": {\"color\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199], \"colorbar\": {\"title\": {\"text\": \"#Trials\"}, \"x\": 1.0, \"xpad\": 40}, \"colorscale\": [[0.0, \"rgb(247,251,255)\"], [0.125, \"rgb(222,235,247)\"], [0.25, \"rgb(198,219,239)\"], [0.375, \"rgb(158,202,225)\"], [0.5, \"rgb(107,174,214)\"], [0.625, \"rgb(66,146,198)\"], [0.75, \"rgb(33,113,181)\"], [0.875, \"rgb(8,81,156)\"], [1.0, \"rgb(8,48,107)\"]], \"line\": {\"color\": \"Grey\", \"width\": 0.5}, \"showscale\": false}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [11, 73, 85, 80, 20, 42, 49, 74, 43, 1, 98, 74, 65, 67, 100, 98, 59, 84, 91, 93, 29, 92, 90, 90, 89, 60, 81, 89, 75, 55, 69, 93, 81, 91, 86, 96, 78, 96, 85, 34, 100, 92, 85, 79, 95, 88, 72, 95, 9, 100, 83, 92, 88, 77, 88, 91, 72, 82, 45, 87, 62, 92, 87, 88, 86, 75, 88, 69, 88, 83, 80, 96, 87, 87, 83, 77, 23, 98, 89, 80, 94, 90, 85, 89, 89, 97, 83, 55, 86, 94, 76, 89, 89, 90, 79, 93, 85, 36, 99, 81, 87, 87, 90, 84, 87, 94, 92, 86, 81, 2, 89, 89, 91, 97, 84, 89, 95, 82, 87, 92, 79, 87, 90, 86, 88, 84, 93, 90, 82, 96, 86, 88, 86, 92, 88, 83, 94, 90, 85, 78, 87, 89, 91, 89, 89, 93, 98, 89, 89, 90, 95, 89, 92, 90, 89, 89, 94, 89, 89, 96, 91, 85, 89, 89, 92, 89, 84, 93, 91, 89, 84, 89, 88, 49, 89, 93, 85, 91, 82, 16, 95, 89, 89, 86, 90, 88, 92, 86, 91, 94, 88, 89, 91, 89, 84, 87, 93, 89, 86, 91], \"xaxis\": \"x2\", \"y\": [0.006105077510555661, 0.004615220111482611, 0.004733355288067668, 0.004809605282150507, 0.0055040832833616665, 0.005029665162426492, 0.004938743206474557, 0.00483585006445534, 0.004964842824841498, 0.009383941289509286, 0.0048574549420257445, 0.0046838530403632075, 0.004754460598938891, 0.004740187774751588, 0.004617410875175973, 0.004614385899170579, 0.00480749372375126, 0.004756715496287527, 0.00460425308939593, 0.004542857144739812, 0.005248655727882804, 0.004540580742562123, 0.004538983495917568, 0.004624905575201242, 0.004530901279381072, 0.0048406488003686155, 0.004556972477634315, 0.00463735253976059, 0.004755965467227116, 0.005001137835558552, 0.0046723763029584255, 0.004542857144739812, 0.004581398453867969, 0.004637154290113819, 0.004605281687687843, 0.004541801595556054, 0.0047541397464365325, 0.004677929605819875, 0.004615933210892673, 0.005195920723297388, 0.004744932224145598, 0.0045405807425621236, 0.004592498749001295, 0.004560946385153747, 0.004649110155472559, 0.004911243850037271, 0.004663629192843794, 0.004547368567196646, 0.006472550380672174, 0.004644529924159673, 0.00481065602611049, 0.004540580742562123, 0.004533734408447345, 0.004779431372341306, 0.0045816489761496965, 0.004580818627504554, 0.004657077569419981, 0.004583718559674423, 0.005032818606970915, 0.004531099529027843, 0.004760692974273348, 0.0045405807425621236, 0.004531099529027844, 0.004533734408447345, 0.0046964666744681634, 0.004609694250300059, 0.004533734408447345, 0.0046723763029584255, 0.0045740308028700315, 0.0047002486188526815, 0.004589244420856973, 0.004541801595556054, 0.004531099529027843, 0.004607916567107345, 0.004700248618852681, 0.005160857292615128, 0.0053855622136069, 0.004542818484266338, 0.0045309012793810725, 0.004713220538941826, 0.004646833753294871, 0.004538983495917568, 0.004556244597953569, 0.004530901279381072, 0.004589731192686194, 0.004542437096586814, 0.004552062739320608, 0.004892345855121198, 0.004581847225796468, 0.00457167659508713, 0.0045884203468745995, 0.0045309012793810725, 0.004530901279381072, 0.004538983495917568, 0.00475737798165778, 0.004622424291855753, 0.0045562445979535696, 0.005153530627981131, 0.0046185461940526406, 0.004556972477634315, 0.004531099529027843, 0.004531099529027842, 0.004538983495917567, 0.004553924492147116, 0.0046819731287472644, 0.004571676595087128, 0.004593604841508439, 0.00454175105223267, 0.004704222526372112, 0.009383941289509283, 0.004530901279381072, 0.004530901279381072, 0.004554029528426176, 0.004542437096586812, 0.004553924492147114, 0.00463735253976059, 0.0046159837542160565, 0.004560026542338087, 0.004531099529027843, 0.004617039303399814, 0.004560946385153747, 0.004531099529027843, 0.00453898349591757, 0.00454175105223267, 0.004533734408447345, 0.004553924492147114, 0.004622424291855755, 0.0046399874191800925, 0.004703130995038942, 0.0045418015955560566, 0.004541751052232671, 0.004533734408447346, 0.004541751052232671, 0.0045405807425621236, 0.0045816489761496965, 0.00455206273932061, 0.004571676595087129, 0.0045389834959175665, 0.004694146568661707, 0.0045822202885792045, 0.004747731069910295, 0.004530901279381072, 0.004554029528426177, 0.004530901279381072, 0.0045309012793810725, 0.004542857144739811, 0.004596977126780946, 0.004530901279381072, 0.004530901279381072, 0.004639987419180093, 0.004592549292324682, 0.004530901279381072, 0.0045405807425621236, 0.004538983495917568, 0.004530901279381072, 0.004530901279381072, 0.004571676595087128, 0.0045309012793810725, 0.004530901279381072, 0.004670025994719991, 0.004554029528426179, 0.0045562445979535696, 0.004530901279381072, 0.0045309012793810725, 0.0045405807425621236, 0.004530901279381072, 0.004553924492147114, 0.004660282539158925, 0.004554029528426177, 0.004530901279381072, 0.004553924492147115, 0.004530901279381072, 0.004533734408447346, 0.004909968036943486, 0.004530901279381072, 0.004542857144739812, 0.004592498749001296, 0.004554029528426177, 0.004560026542338086, 0.005743934034270239, 0.004649110155472559, 0.0045309012793810725, 0.004530901279381072, 0.00454175105223267, 0.004538983495917568, 0.004533734408447345, 0.0045405807425621236, 0.00454175105223267, 0.004554029528426179, 0.004571676595087128, 0.005032182878279115, 0.0045309012793810725, 0.004554029528426177, 0.004530901279381071, 0.004553924492147113, 0.004531099529027843, 0.004542857144739812, 0.004530901279381072, 0.004541751052232671, 0.004554029528426177], \"yaxis\": \"y2\"}, {\"marker\": {\"color\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199], \"colorbar\": {\"title\": {\"text\": \"#Trials\"}, \"x\": 1.0, \"xpad\": 40}, \"colorscale\": [[0.0, \"rgb(247,251,255)\"], [0.125, \"rgb(222,235,247)\"], [0.25, \"rgb(198,219,239)\"], [0.375, \"rgb(158,202,225)\"], [0.5, \"rgb(107,174,214)\"], [0.625, \"rgb(66,146,198)\"], [0.75, \"rgb(33,113,181)\"], [0.875, \"rgb(8,81,156)\"], [1.0, \"rgb(8,48,107)\"]], \"line\": {\"color\": \"Grey\", \"width\": 0.5}, \"showscale\": false}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [9, 10, 5, 5, 3, 9, 9, 5, 8, 9, 1, 7, 7, 7, 10, 10, 10, 3, 10, 8, 8, 8, 8, 6, 8, 6, 8, 7, 6, 4, 8, 8, 9, 7, 9, 8, 6, 7, 9, 8, 5, 8, 9, 8, 7, 1, 9, 8, 7, 9, 4, 8, 8, 7, 9, 10, 8, 9, 6, 8, 7, 8, 8, 8, 7, 9, 8, 8, 10, 7, 10, 8, 8, 9, 7, 2, 8, 8, 8, 6, 7, 8, 8, 8, 9, 8, 8, 7, 9, 8, 9, 8, 8, 8, 7, 9, 8, 7, 9, 8, 8, 8, 8, 8, 7, 8, 9, 8, 7, 4, 8, 8, 8, 8, 8, 7, 9, 8, 8, 9, 8, 8, 8, 8, 8, 8, 9, 7, 7, 8, 8, 8, 8, 8, 9, 8, 8, 8, 7, 8, 3, 8, 8, 8, 8, 8, 9, 8, 8, 7, 9, 8, 8, 8, 8, 8, 8, 8, 8, 5, 8, 8, 8, 8, 8, 8, 8, 7, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 9, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 2, 8, 8, 8, 8, 8, 8, 8, 8, 8], \"xaxis\": \"x3\", \"y\": [0.006105077510555661, 0.004615220111482611, 0.004733355288067668, 0.004809605282150507, 0.0055040832833616665, 0.005029665162426492, 0.004938743206474557, 0.00483585006445534, 0.004964842824841498, 0.009383941289509286, 0.0048574549420257445, 0.0046838530403632075, 0.004754460598938891, 0.004740187774751588, 0.004617410875175973, 0.004614385899170579, 0.00480749372375126, 0.004756715496287527, 0.00460425308939593, 0.004542857144739812, 0.005248655727882804, 0.004540580742562123, 0.004538983495917568, 0.004624905575201242, 0.004530901279381072, 0.0048406488003686155, 0.004556972477634315, 0.00463735253976059, 0.004755965467227116, 0.005001137835558552, 0.0046723763029584255, 0.004542857144739812, 0.004581398453867969, 0.004637154290113819, 0.004605281687687843, 0.004541801595556054, 0.0047541397464365325, 0.004677929605819875, 0.004615933210892673, 0.005195920723297388, 0.004744932224145598, 0.0045405807425621236, 0.004592498749001295, 0.004560946385153747, 0.004649110155472559, 0.004911243850037271, 0.004663629192843794, 0.004547368567196646, 0.006472550380672174, 0.004644529924159673, 0.00481065602611049, 0.004540580742562123, 0.004533734408447345, 0.004779431372341306, 0.0045816489761496965, 0.004580818627504554, 0.004657077569419981, 0.004583718559674423, 0.005032818606970915, 0.004531099529027843, 0.004760692974273348, 0.0045405807425621236, 0.004531099529027844, 0.004533734408447345, 0.0046964666744681634, 0.004609694250300059, 0.004533734408447345, 0.0046723763029584255, 0.0045740308028700315, 0.0047002486188526815, 0.004589244420856973, 0.004541801595556054, 0.004531099529027843, 0.004607916567107345, 0.004700248618852681, 0.005160857292615128, 0.0053855622136069, 0.004542818484266338, 0.0045309012793810725, 0.004713220538941826, 0.004646833753294871, 0.004538983495917568, 0.004556244597953569, 0.004530901279381072, 0.004589731192686194, 0.004542437096586814, 0.004552062739320608, 0.004892345855121198, 0.004581847225796468, 0.00457167659508713, 0.0045884203468745995, 0.0045309012793810725, 0.004530901279381072, 0.004538983495917568, 0.00475737798165778, 0.004622424291855753, 0.0045562445979535696, 0.005153530627981131, 0.0046185461940526406, 0.004556972477634315, 0.004531099529027843, 0.004531099529027842, 0.004538983495917567, 0.004553924492147116, 0.0046819731287472644, 0.004571676595087128, 0.004593604841508439, 0.00454175105223267, 0.004704222526372112, 0.009383941289509283, 0.004530901279381072, 0.004530901279381072, 0.004554029528426176, 0.004542437096586812, 0.004553924492147114, 0.00463735253976059, 0.0046159837542160565, 0.004560026542338087, 0.004531099529027843, 0.004617039303399814, 0.004560946385153747, 0.004531099529027843, 0.00453898349591757, 0.00454175105223267, 0.004533734408447345, 0.004553924492147114, 0.004622424291855755, 0.0046399874191800925, 0.004703130995038942, 0.0045418015955560566, 0.004541751052232671, 0.004533734408447346, 0.004541751052232671, 0.0045405807425621236, 0.0045816489761496965, 0.00455206273932061, 0.004571676595087129, 0.0045389834959175665, 0.004694146568661707, 0.0045822202885792045, 0.004747731069910295, 0.004530901279381072, 0.004554029528426177, 0.004530901279381072, 0.0045309012793810725, 0.004542857144739811, 0.004596977126780946, 0.004530901279381072, 0.004530901279381072, 0.004639987419180093, 0.004592549292324682, 0.004530901279381072, 0.0045405807425621236, 0.004538983495917568, 0.004530901279381072, 0.004530901279381072, 0.004571676595087128, 0.0045309012793810725, 0.004530901279381072, 0.004670025994719991, 0.004554029528426179, 0.0045562445979535696, 0.004530901279381072, 0.0045309012793810725, 0.0045405807425621236, 0.004530901279381072, 0.004553924492147114, 0.004660282539158925, 0.004554029528426177, 0.004530901279381072, 0.004553924492147115, 0.004530901279381072, 0.004533734408447346, 0.004909968036943486, 0.004530901279381072, 0.004542857144739812, 0.004592498749001296, 0.004554029528426177, 0.004560026542338086, 0.005743934034270239, 0.004649110155472559, 0.0045309012793810725, 0.004530901279381072, 0.00454175105223267, 0.004538983495917568, 0.004533734408447345, 0.0045405807425621236, 0.00454175105223267, 0.004554029528426179, 0.004571676595087128, 0.005032182878279115, 0.0045309012793810725, 0.004554029528426177, 0.004530901279381071, 0.004553924492147113, 0.004531099529027843, 0.004542857144739812, 0.004530901279381072, 0.004541751052232671, 0.004554029528426177], \"yaxis\": \"y3\"}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Slice Plot\"}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.2888888888888889], \"title\": {\"text\": \"max_depth\"}}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.35555555555555557, 0.6444444444444445], \"title\": {\"text\": \"max_leaf_nodes\"}}, \"xaxis3\": {\"anchor\": \"y3\", \"domain\": [0.7111111111111111, 1.0], \"title\": {\"text\": \"min_samples_leaf\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Objective Value\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0], \"matches\": \"y\", \"showticklabels\": false}, \"yaxis3\": {\"anchor\": \"x3\", \"domain\": [0.0, 1.0], \"matches\": \"y\", \"showticklabels\": false}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('31f922ac-6bf4-4ab6-add8-56d3003064e4');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "A1BOMc-lvPG_",
        "outputId": "97fcaee2-d472-42be-81fe-3b97b374c7d9"
      },
      "source": [
        "optuna.visualization.plot_param_importances(study_decisiontree)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"8a4a6654-6dd6-4262-a2a0-68e9da19daa3\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"8a4a6654-6dd6-4262-a2a0-68e9da19daa3\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '8a4a6654-6dd6-4262-a2a0-68e9da19daa3',\n",
              "                        [{\"cliponaxis\": false, \"hovertemplate\": [\"max_depth (IntLogUniformDistribution): 0.004868531073299376<extra></extra>\", \"min_samples_leaf (IntUniformDistribution): 0.005234969869018833<extra></extra>\", \"max_leaf_nodes (IntUniformDistribution): 0.9898964990576818<extra></extra>\"], \"marker\": {\"color\": \"rgb(66,146,198)\"}, \"orientation\": \"h\", \"text\": [\"0.004868531073299376\", \"0.005234969869018833\", \"0.9898964990576818\"], \"textposition\": \"outside\", \"texttemplate\": \"%{text:.2f}\", \"type\": \"bar\", \"x\": [0.004868531073299376, 0.005234969869018833, 0.9898964990576818], \"y\": [\"max_depth\", \"min_samples_leaf\", \"max_leaf_nodes\"]}],\n",
              "                        {\"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Hyperparameter Importances\"}, \"xaxis\": {\"title\": {\"text\": \"Importance for Objective Value\"}}, \"yaxis\": {\"title\": {\"text\": \"Hyperparameter\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('8a4a6654-6dd6-4262-a2a0-68e9da19daa3');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Avwiqzgbc8oS"
      },
      "source": [
        "# **Rede Neural**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxBzp6p2hZle",
        "outputId": "2b65e183-63d3-49ff-bf92-f9f64a76a5af"
      },
      "source": [
        "def mlp(trial):\n",
        "  with mlflow.start_run(run_name=\"Rede Neural\"):\n",
        "    activation = trial.suggest_categorical('activation', ['identity', 'logistic', 'tanh', 'relu'])\n",
        "    learning_rate_init = trial.suggest_float(\"learning_rate_init\", 1e-5, 0.3, log=True)\n",
        "    solver = trial.suggest_categorical('sovler', ['lbfgs', 'sgd', 'adam'])\n",
        "\n",
        "    mlp_model = MLPRegressor(activation=activation,learning_rate_init=learning_rate_init,solver=solver)\n",
        "    mlp_model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred_val = mlp_model.predict(X_val)\n",
        "\n",
        "    (mse, mae, r2) = eval_metrics(y_val, y_pred_val)\n",
        "    \n",
        "    mlflow.log_param(\"activation\", activation)\n",
        "    mlflow.log_param(\"learning_rate_init\", learning_rate_init)\n",
        "    mlflow.log_param(\"solver\", solver)\n",
        "\n",
        "    mlflow.log_metric(\"mse\", mse)\n",
        "    mlflow.log_metric(\"mae\", mae)\n",
        "    mlflow.log_metric(\"r2\", r2)\n",
        "    #mlflow.log_metric(\"nomemetrica\", nomevariavel)\n",
        "    #mlflow.log_metric(\"nomemetrica\", nomevariavel)\n",
        "\n",
        "    return mean_squared_error(y_val, y_pred_val)\n",
        "\n",
        "\n",
        "study_mlp = optuna.create_study(direction='minimize')\n",
        "study_mlp.optimize(mlp,n_trials=200)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 01:46:56,623]\u001b[0m A new study created in memory with name: no-name-f4200d0d-696c-4a7f-ba56-59069616adef\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:46:57,840]\u001b[0m Trial 0 finished with value: 0.013695509917260046 and parameters: {'activation': 'logistic', 'learning_rate_init': 0.004426463543424635, 'sovler': 'sgd'}. Best is trial 0 with value: 0.013695509917260046.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:47:05,548]\u001b[0m Trial 1 finished with value: 0.008133149339349981 and parameters: {'activation': 'tanh', 'learning_rate_init': 0.2522112971976336, 'sovler': 'lbfgs'}. Best is trial 1 with value: 0.008133149339349981.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:47:07,580]\u001b[0m Trial 2 finished with value: 0.015455278896278148 and parameters: {'activation': 'logistic', 'learning_rate_init': 0.16347845363221347, 'sovler': 'adam'}. Best is trial 1 with value: 0.008133149339349981.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:47:19,271]\u001b[0m Trial 3 finished with value: 0.007678923474873372 and parameters: {'activation': 'tanh', 'learning_rate_init': 0.0007636565222371477, 'sovler': 'lbfgs'}. Best is trial 3 with value: 0.007678923474873372.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:47:24,774]\u001b[0m Trial 4 finished with value: 0.0062468419440012985 and parameters: {'activation': 'relu', 'learning_rate_init': 0.0008102444330370592, 'sovler': 'lbfgs'}. Best is trial 4 with value: 0.0062468419440012985.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:47:25,545]\u001b[0m Trial 5 finished with value: 0.009339109347370454 and parameters: {'activation': 'identity', 'learning_rate_init': 0.013139224084121524, 'sovler': 'adam'}. Best is trial 4 with value: 0.0062468419440012985.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:47:26,917]\u001b[0m Trial 6 finished with value: 0.008954909108110903 and parameters: {'activation': 'tanh', 'learning_rate_init': 0.0037315977067789246, 'sovler': 'adam'}. Best is trial 4 with value: 0.0062468419440012985.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:47:29,051]\u001b[0m Trial 7 finished with value: 0.009089734674604128 and parameters: {'activation': 'tanh', 'learning_rate_init': 0.0003083307490328673, 'sovler': 'lbfgs'}. Best is trial 4 with value: 0.0062468419440012985.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:47:29,797]\u001b[0m Trial 8 finished with value: 0.009212045284351381 and parameters: {'activation': 'identity', 'learning_rate_init': 0.0076256026980893845, 'sovler': 'lbfgs'}. Best is trial 4 with value: 0.0062468419440012985.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:47:30,527]\u001b[0m Trial 9 finished with value: 0.00951905120214715 and parameters: {'activation': 'identity', 'learning_rate_init': 0.06863644771087009, 'sovler': 'adam'}. Best is trial 4 with value: 0.0062468419440012985.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:47:33,603]\u001b[0m Trial 10 finished with value: 0.02065626918730477 and parameters: {'activation': 'relu', 'learning_rate_init': 1.5493165732675558e-05, 'sovler': 'sgd'}. Best is trial 4 with value: 0.0062468419440012985.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:47:38,860]\u001b[0m Trial 11 finished with value: 0.006074175560095507 and parameters: {'activation': 'relu', 'learning_rate_init': 0.00032379657351938536, 'sovler': 'lbfgs'}. Best is trial 11 with value: 0.006074175560095507.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:47:43,835]\u001b[0m Trial 12 finished with value: 0.006297134954055606 and parameters: {'activation': 'relu', 'learning_rate_init': 9.124623591957164e-05, 'sovler': 'lbfgs'}. Best is trial 11 with value: 0.006074175560095507.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:47:48,847]\u001b[0m Trial 13 finished with value: 0.006162516976329459 and parameters: {'activation': 'relu', 'learning_rate_init': 0.00011867378559237772, 'sovler': 'lbfgs'}. Best is trial 11 with value: 0.006074175560095507.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:47:53,959]\u001b[0m Trial 14 finished with value: 0.006309112837340831 and parameters: {'activation': 'relu', 'learning_rate_init': 6.313964880000278e-05, 'sovler': 'lbfgs'}. Best is trial 11 with value: 0.006074175560095507.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:47:59,071]\u001b[0m Trial 15 finished with value: 0.006196824084645335 and parameters: {'activation': 'relu', 'learning_rate_init': 1.0451953049446872e-05, 'sovler': 'lbfgs'}. Best is trial 11 with value: 0.006074175560095507.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:48:00,127]\u001b[0m Trial 16 finished with value: 0.017783102500945967 and parameters: {'activation': 'relu', 'learning_rate_init': 0.00014618945242928443, 'sovler': 'sgd'}. Best is trial 11 with value: 0.006074175560095507.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:48:05,035]\u001b[0m Trial 17 finished with value: 0.006687782009171488 and parameters: {'activation': 'relu', 'learning_rate_init': 0.00041255828327734157, 'sovler': 'lbfgs'}. Best is trial 11 with value: 0.006074175560095507.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:48:09,989]\u001b[0m Trial 18 finished with value: 0.006461768247620354 and parameters: {'activation': 'relu', 'learning_rate_init': 4.7862725042044405e-05, 'sovler': 'lbfgs'}. Best is trial 11 with value: 0.006074175560095507.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:48:11,513]\u001b[0m Trial 19 finished with value: 0.014574974919045499 and parameters: {'activation': 'logistic', 'learning_rate_init': 3.2627775596095714e-05, 'sovler': 'sgd'}. Best is trial 11 with value: 0.006074175560095507.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:48:16,421]\u001b[0m Trial 20 finished with value: 0.006398944966489172 and parameters: {'activation': 'relu', 'learning_rate_init': 0.0013181988245779357, 'sovler': 'lbfgs'}. Best is trial 11 with value: 0.006074175560095507.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:48:21,579]\u001b[0m Trial 21 finished with value: 0.006145404864957239 and parameters: {'activation': 'relu', 'learning_rate_init': 1.2518578637656662e-05, 'sovler': 'lbfgs'}. Best is trial 11 with value: 0.006074175560095507.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:48:26,637]\u001b[0m Trial 22 finished with value: 0.006314334129367772 and parameters: {'activation': 'relu', 'learning_rate_init': 0.00019617502812210272, 'sovler': 'lbfgs'}. Best is trial 11 with value: 0.006074175560095507.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:48:31,884]\u001b[0m Trial 23 finished with value: 0.006224434552035505 and parameters: {'activation': 'relu', 'learning_rate_init': 2.4742887506897426e-05, 'sovler': 'lbfgs'}. Best is trial 11 with value: 0.006074175560095507.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:48:36,799]\u001b[0m Trial 24 finished with value: 0.006105436721383346 and parameters: {'activation': 'relu', 'learning_rate_init': 0.00011172081124072892, 'sovler': 'lbfgs'}. Best is trial 11 with value: 0.006074175560095507.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:48:41,839]\u001b[0m Trial 25 finished with value: 0.006220783320594887 and parameters: {'activation': 'relu', 'learning_rate_init': 2.739262827674626e-05, 'sovler': 'lbfgs'}. Best is trial 11 with value: 0.006074175560095507.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:48:46,866]\u001b[0m Trial 26 finished with value: 0.006263200348366856 and parameters: {'activation': 'relu', 'learning_rate_init': 0.0004488345665994013, 'sovler': 'lbfgs'}. Best is trial 11 with value: 0.006074175560095507.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:48:47,431]\u001b[0m Trial 27 finished with value: 0.009267018286082005 and parameters: {'activation': 'identity', 'learning_rate_init': 0.00022392102901032583, 'sovler': 'lbfgs'}. Best is trial 11 with value: 0.006074175560095507.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:48:50,613]\u001b[0m Trial 28 finished with value: 0.014423400024314007 and parameters: {'activation': 'logistic', 'learning_rate_init': 1.0439786168529375e-05, 'sovler': 'sgd'}. Best is trial 11 with value: 0.006074175560095507.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:48:52,188]\u001b[0m Trial 29 finished with value: 0.009201759070761853 and parameters: {'activation': 'logistic', 'learning_rate_init': 0.0026873727454611103, 'sovler': 'adam'}. Best is trial 11 with value: 0.006074175560095507.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:48:53,815]\u001b[0m Trial 30 finished with value: 0.026217843803159988 and parameters: {'activation': 'relu', 'learning_rate_init': 5.8773472173541146e-05, 'sovler': 'sgd'}. Best is trial 11 with value: 0.006074175560095507.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:48:59,017]\u001b[0m Trial 31 finished with value: 0.006639479613995171 and parameters: {'activation': 'relu', 'learning_rate_init': 0.0001252330304175881, 'sovler': 'lbfgs'}. Best is trial 11 with value: 0.006074175560095507.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:49:04,439]\u001b[0m Trial 32 finished with value: 0.006294961256462405 and parameters: {'activation': 'relu', 'learning_rate_init': 7.975518260255472e-05, 'sovler': 'lbfgs'}. Best is trial 11 with value: 0.006074175560095507.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:49:09,540]\u001b[0m Trial 33 finished with value: 0.006236324949200261 and parameters: {'activation': 'relu', 'learning_rate_init': 0.0007032950527039105, 'sovler': 'lbfgs'}. Best is trial 11 with value: 0.006074175560095507.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:49:18,158]\u001b[0m Trial 34 finished with value: 0.007970206123169498 and parameters: {'activation': 'tanh', 'learning_rate_init': 0.0016864735642886733, 'sovler': 'lbfgs'}. Best is trial 11 with value: 0.006074175560095507.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:49:23,197]\u001b[0m Trial 35 finished with value: 0.006218814549066823 and parameters: {'activation': 'relu', 'learning_rate_init': 2.131223891498782e-05, 'sovler': 'lbfgs'}. Best is trial 11 with value: 0.006074175560095507.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:49:28,419]\u001b[0m Trial 36 finished with value: 0.005989590933027521 and parameters: {'activation': 'relu', 'learning_rate_init': 4.4056663408739035e-05, 'sovler': 'lbfgs'}. Best is trial 36 with value: 0.005989590933027521.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:49:30,104]\u001b[0m Trial 37 finished with value: 0.013179784310920293 and parameters: {'activation': 'logistic', 'learning_rate_init': 3.594772739672492e-05, 'sovler': 'adam'}. Best is trial 36 with value: 0.005989590933027521.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:49:38,718]\u001b[0m Trial 38 finished with value: 0.008143956416012685 and parameters: {'activation': 'tanh', 'learning_rate_init': 4.809580197418384e-05, 'sovler': 'lbfgs'}. Best is trial 36 with value: 0.005989590933027521.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:49:39,723]\u001b[0m Trial 39 finished with value: 0.009186710331701849 and parameters: {'activation': 'identity', 'learning_rate_init': 1.658130481480248e-05, 'sovler': 'lbfgs'}. Best is trial 36 with value: 0.005989590933027521.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:49:42,054]\u001b[0m Trial 40 finished with value: 0.005942776346336866 and parameters: {'activation': 'relu', 'learning_rate_init': 0.02195435656406207, 'sovler': 'adam'}. Best is trial 40 with value: 0.005942776346336866.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:49:42,865]\u001b[0m Trial 41 finished with value: 0.008915116063218655 and parameters: {'activation': 'relu', 'learning_rate_init': 0.054044880039431455, 'sovler': 'adam'}. Best is trial 40 with value: 0.005942776346336866.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:49:44,291]\u001b[0m Trial 42 finished with value: 0.006391897881596097 and parameters: {'activation': 'relu', 'learning_rate_init': 0.021678843781818953, 'sovler': 'adam'}. Best is trial 40 with value: 0.005942776346336866.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:49:45,421]\u001b[0m Trial 43 finished with value: 0.010441193649755508 and parameters: {'activation': 'relu', 'learning_rate_init': 0.2532818682948917, 'sovler': 'adam'}. Best is trial 40 with value: 0.005942776346336866.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:49:47,692]\u001b[0m Trial 44 finished with value: 0.006729603048224194 and parameters: {'activation': 'relu', 'learning_rate_init': 0.006871065522876489, 'sovler': 'adam'}. Best is trial 40 with value: 0.005942776346336866.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:49:49,195]\u001b[0m Trial 45 finished with value: 0.007718684416338415 and parameters: {'activation': 'tanh', 'learning_rate_init': 0.09307084106260881, 'sovler': 'adam'}. Best is trial 40 with value: 0.005942776346336866.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:49:54,323]\u001b[0m Trial 46 finished with value: 0.0063117407521246114 and parameters: {'activation': 'relu', 'learning_rate_init': 0.0007568478581173415, 'sovler': 'lbfgs'}. Best is trial 40 with value: 0.005942776346336866.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:49:54,943]\u001b[0m Trial 47 finished with value: 0.009262362908332633 and parameters: {'activation': 'identity', 'learning_rate_init': 0.01438014771578037, 'sovler': 'lbfgs'}. Best is trial 40 with value: 0.005942776346336866.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:49:56,571]\u001b[0m Trial 48 finished with value: 0.006372415381217816 and parameters: {'activation': 'relu', 'learning_rate_init': 0.029030914209994214, 'sovler': 'adam'}. Best is trial 40 with value: 0.005942776346336866.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:50:01,833]\u001b[0m Trial 49 finished with value: 0.006172927482671538 and parameters: {'activation': 'relu', 'learning_rate_init': 0.0002449772921255375, 'sovler': 'lbfgs'}. Best is trial 40 with value: 0.005942776346336866.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:50:03,077]\u001b[0m Trial 50 finished with value: 0.012866157913731396 and parameters: {'activation': 'relu', 'learning_rate_init': 0.0003586076488838753, 'sovler': 'sgd'}. Best is trial 40 with value: 0.005942776346336866.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:50:08,234]\u001b[0m Trial 51 finished with value: 0.006379542812996053 and parameters: {'activation': 'relu', 'learning_rate_init': 0.00010029045826676522, 'sovler': 'lbfgs'}. Best is trial 40 with value: 0.005942776346336866.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:50:13,193]\u001b[0m Trial 52 finished with value: 0.006083451665754033 and parameters: {'activation': 'relu', 'learning_rate_init': 0.00015425867134821357, 'sovler': 'lbfgs'}. Best is trial 40 with value: 0.005942776346336866.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:50:18,131]\u001b[0m Trial 53 finished with value: 0.00651117131179485 and parameters: {'activation': 'relu', 'learning_rate_init': 0.00019120576573128714, 'sovler': 'lbfgs'}. Best is trial 40 with value: 0.005942776346336866.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:50:23,360]\u001b[0m Trial 54 finished with value: 0.0063693355423317475 and parameters: {'activation': 'relu', 'learning_rate_init': 1.764988049288359e-05, 'sovler': 'lbfgs'}. Best is trial 40 with value: 0.005942776346336866.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:50:28,446]\u001b[0m Trial 55 finished with value: 0.006109853422359667 and parameters: {'activation': 'relu', 'learning_rate_init': 7.830365981262699e-05, 'sovler': 'lbfgs'}. Best is trial 40 with value: 0.005942776346336866.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:50:33,459]\u001b[0m Trial 56 finished with value: 0.005995329857021493 and parameters: {'activation': 'relu', 'learning_rate_init': 0.00015976113639713522, 'sovler': 'lbfgs'}. Best is trial 40 with value: 0.005942776346336866.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:50:38,842]\u001b[0m Trial 57 finished with value: 0.005865094663945668 and parameters: {'activation': 'relu', 'learning_rate_init': 0.00013807117061020554, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:50:50,567]\u001b[0m Trial 58 finished with value: 0.007762420909572033 and parameters: {'activation': 'tanh', 'learning_rate_init': 0.00017129802485203987, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:50:52,168]\u001b[0m Trial 59 finished with value: 0.009725733303839882 and parameters: {'activation': 'logistic', 'learning_rate_init': 0.0010941254793413277, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:50:53,741]\u001b[0m Trial 60 finished with value: 0.01223267853909535 and parameters: {'activation': 'identity', 'learning_rate_init': 0.0004609393473908925, 'sovler': 'sgd'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:50:58,977]\u001b[0m Trial 61 finished with value: 0.006333912348474149 and parameters: {'activation': 'relu', 'learning_rate_init': 0.00012241046278705403, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:51:03,937]\u001b[0m Trial 62 finished with value: 0.006759613087976074 and parameters: {'activation': 'relu', 'learning_rate_init': 0.00027069893048130425, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:51:09,022]\u001b[0m Trial 63 finished with value: 0.006285453558327543 and parameters: {'activation': 'relu', 'learning_rate_init': 4.2501359284052825e-05, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:51:14,158]\u001b[0m Trial 64 finished with value: 0.006490236566838725 and parameters: {'activation': 'relu', 'learning_rate_init': 0.0005468693695594135, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:51:19,325]\u001b[0m Trial 65 finished with value: 0.006343387834157826 and parameters: {'activation': 'relu', 'learning_rate_init': 7.440298686899554e-05, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:51:24,796]\u001b[0m Trial 66 finished with value: 0.00618087919986332 and parameters: {'activation': 'relu', 'learning_rate_init': 0.00015028810939722676, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:51:25,987]\u001b[0m Trial 67 finished with value: 0.00829769504770551 and parameters: {'activation': 'relu', 'learning_rate_init': 0.0003303823539839015, 'sovler': 'adam'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:51:30,914]\u001b[0m Trial 68 finished with value: 0.006227516731100143 and parameters: {'activation': 'relu', 'learning_rate_init': 0.0031175574806028253, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:51:36,164]\u001b[0m Trial 69 finished with value: 0.006023561725052611 and parameters: {'activation': 'relu', 'learning_rate_init': 5.342971244627168e-05, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:51:41,084]\u001b[0m Trial 70 finished with value: 0.006340284096767526 and parameters: {'activation': 'relu', 'learning_rate_init': 5.057444359261599e-05, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:51:46,310]\u001b[0m Trial 71 finished with value: 0.006311029742732632 and parameters: {'activation': 'relu', 'learning_rate_init': 0.00010531938013308458, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:51:51,565]\u001b[0m Trial 72 finished with value: 0.006463703828415786 and parameters: {'activation': 'relu', 'learning_rate_init': 3.053894271899106e-05, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:51:56,759]\u001b[0m Trial 73 finished with value: 0.006099382151191197 and parameters: {'activation': 'relu', 'learning_rate_init': 0.00016428498251804563, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:52:01,971]\u001b[0m Trial 74 finished with value: 0.006009693411745203 and parameters: {'activation': 'relu', 'learning_rate_init': 7.147736503858506e-05, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:52:03,923]\u001b[0m Trial 75 finished with value: 0.009800484923361934 and parameters: {'activation': 'logistic', 'learning_rate_init': 6.658018896109586e-05, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:52:05,245]\u001b[0m Trial 76 finished with value: 0.021162858743568477 and parameters: {'activation': 'relu', 'learning_rate_init': 6.00873336021729e-05, 'sovler': 'sgd'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:52:10,445]\u001b[0m Trial 77 finished with value: 0.006597573734344217 and parameters: {'activation': 'relu', 'learning_rate_init': 4.245219451857692e-05, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:52:12,583]\u001b[0m Trial 78 finished with value: 0.0062756791742859955 and parameters: {'activation': 'relu', 'learning_rate_init': 0.0051660706786025214, 'sovler': 'adam'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:52:22,950]\u001b[0m Trial 79 finished with value: 0.007970300912628486 and parameters: {'activation': 'tanh', 'learning_rate_init': 2.192408746189087e-05, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:52:23,663]\u001b[0m Trial 80 finished with value: 0.009172364923234885 and parameters: {'activation': 'identity', 'learning_rate_init': 9.097677040979472e-05, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:52:28,753]\u001b[0m Trial 81 finished with value: 0.006548341132241544 and parameters: {'activation': 'relu', 'learning_rate_init': 0.00014518857382193247, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:52:33,824]\u001b[0m Trial 82 finished with value: 0.006391103200016834 and parameters: {'activation': 'relu', 'learning_rate_init': 0.14808993099830642, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:52:39,047]\u001b[0m Trial 83 finished with value: 0.00648128204049954 and parameters: {'activation': 'relu', 'learning_rate_init': 0.00022951298398953137, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:52:44,191]\u001b[0m Trial 84 finished with value: 0.006691098994879275 and parameters: {'activation': 'relu', 'learning_rate_init': 0.00015712853909698914, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:52:49,556]\u001b[0m Trial 85 finished with value: 0.006037849533632324 and parameters: {'activation': 'relu', 'learning_rate_init': 3.625528235762319e-05, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:52:53,037]\u001b[0m Trial 86 finished with value: 0.010510784868511978 and parameters: {'activation': 'relu', 'learning_rate_init': 3.6269770595003634e-05, 'sovler': 'adam'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:52:58,223]\u001b[0m Trial 87 finished with value: 0.006301091327853603 and parameters: {'activation': 'relu', 'learning_rate_init': 5.72356498377965e-05, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:53:03,364]\u001b[0m Trial 88 finished with value: 0.006381334894751307 and parameters: {'activation': 'relu', 'learning_rate_init': 1.38294408035907e-05, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:53:06,245]\u001b[0m Trial 89 finished with value: 0.009688464857942026 and parameters: {'activation': 'logistic', 'learning_rate_init': 3.330017724233539e-05, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:53:09,029]\u001b[0m Trial 90 finished with value: 0.021865572125728656 and parameters: {'activation': 'relu', 'learning_rate_init': 2.4344008254585583e-05, 'sovler': 'sgd'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:53:13,860]\u001b[0m Trial 91 finished with value: 0.006402741433354416 and parameters: {'activation': 'relu', 'learning_rate_init': 9.250581144415725e-05, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:53:18,900]\u001b[0m Trial 92 finished with value: 0.006240649176638988 and parameters: {'activation': 'relu', 'learning_rate_init': 0.00019856556929441813, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:53:24,149]\u001b[0m Trial 93 finished with value: 0.0061124260845843905 and parameters: {'activation': 'relu', 'learning_rate_init': 0.00013690327208420802, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:53:29,373]\u001b[0m Trial 94 finished with value: 0.006135132252003531 and parameters: {'activation': 'relu', 'learning_rate_init': 0.00028955118412288256, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:53:34,541]\u001b[0m Trial 95 finished with value: 0.006456263819764983 and parameters: {'activation': 'relu', 'learning_rate_init': 0.0005678062337243398, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:53:37,462]\u001b[0m Trial 96 finished with value: 0.009714103944425748 and parameters: {'activation': 'relu', 'learning_rate_init': 7.69939570702854e-05, 'sovler': 'adam'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:53:44,391]\u001b[0m Trial 97 finished with value: 0.00820027840447612 and parameters: {'activation': 'tanh', 'learning_rate_init': 0.00012542371082428926, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:53:44,908]\u001b[0m Trial 98 finished with value: 0.009169355970021274 and parameters: {'activation': 'identity', 'learning_rate_init': 4.366739698704087e-05, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:53:50,060]\u001b[0m Trial 99 finished with value: 0.006142047695671848 and parameters: {'activation': 'relu', 'learning_rate_init': 0.0011330824664385695, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:53:55,175]\u001b[0m Trial 100 finished with value: 0.006104626881763451 and parameters: {'activation': 'relu', 'learning_rate_init': 0.00035331175940538166, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:54:00,141]\u001b[0m Trial 101 finished with value: 0.0062618202241571915 and parameters: {'activation': 'relu', 'learning_rate_init': 0.0001852686858636112, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:54:05,102]\u001b[0m Trial 102 finished with value: 0.006115686269621371 and parameters: {'activation': 'relu', 'learning_rate_init': 0.0003919325485041484, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:54:10,067]\u001b[0m Trial 103 finished with value: 0.0060400517130737375 and parameters: {'activation': 'relu', 'learning_rate_init': 0.001982364672750281, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:54:15,237]\u001b[0m Trial 104 finished with value: 0.00644132355235336 and parameters: {'activation': 'relu', 'learning_rate_init': 0.0141523495875905, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:54:20,290]\u001b[0m Trial 105 finished with value: 0.006360427559683202 and parameters: {'activation': 'relu', 'learning_rate_init': 0.00847563611026996, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:54:21,397]\u001b[0m Trial 106 finished with value: 0.006777025650588393 and parameters: {'activation': 'relu', 'learning_rate_init': 0.0018301233449911063, 'sovler': 'adam'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:54:26,448]\u001b[0m Trial 107 finished with value: 0.006482852027193088 and parameters: {'activation': 'relu', 'learning_rate_init': 0.04311571961187077, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:54:31,582]\u001b[0m Trial 108 finished with value: 0.006168481074570905 and parameters: {'activation': 'relu', 'learning_rate_init': 0.00010482864327197133, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:54:36,484]\u001b[0m Trial 109 finished with value: 0.006438947178460044 and parameters: {'activation': 'relu', 'learning_rate_init': 1.9041701012368514e-05, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:54:37,875]\u001b[0m Trial 110 finished with value: 0.01463721655823561 and parameters: {'activation': 'logistic', 'learning_rate_init': 5.358005957505928e-05, 'sovler': 'sgd'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:54:43,058]\u001b[0m Trial 111 finished with value: 0.006722659552924655 and parameters: {'activation': 'relu', 'learning_rate_init': 0.0002906781808401537, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:54:48,376]\u001b[0m Trial 112 finished with value: 0.00642954047424171 and parameters: {'activation': 'relu', 'learning_rate_init': 0.0005494714257476875, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:54:53,421]\u001b[0m Trial 113 finished with value: 0.006042265406113458 and parameters: {'activation': 'relu', 'learning_rate_init': 0.00021777731228486845, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:54:58,283]\u001b[0m Trial 114 finished with value: 0.006348281823057037 and parameters: {'activation': 'relu', 'learning_rate_init': 8.60610555851029e-05, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:55:03,369]\u001b[0m Trial 115 finished with value: 0.006332731862933246 and parameters: {'activation': 'relu', 'learning_rate_init': 0.00021877046306153572, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:55:08,235]\u001b[0m Trial 116 finished with value: 0.0061142222499553514 and parameters: {'activation': 'relu', 'learning_rate_init': 7.034325591400373e-05, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:55:09,852]\u001b[0m Trial 117 finished with value: 0.008802255531093985 and parameters: {'activation': 'relu', 'learning_rate_init': 0.00015887092290578345, 'sovler': 'adam'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:55:14,670]\u001b[0m Trial 118 finished with value: 0.006503559626038323 and parameters: {'activation': 'relu', 'learning_rate_init': 0.00010829393953377467, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:55:17,232]\u001b[0m Trial 119 finished with value: 0.009095941574271906 and parameters: {'activation': 'tanh', 'learning_rate_init': 0.0021379823424026853, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:55:17,904]\u001b[0m Trial 120 finished with value: 0.009128065504655348 and parameters: {'activation': 'identity', 'learning_rate_init': 2.9891042876614682e-05, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:55:23,133]\u001b[0m Trial 121 finished with value: 0.006050601470835176 and parameters: {'activation': 'relu', 'learning_rate_init': 0.0003282286817807923, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:55:28,156]\u001b[0m Trial 122 finished with value: 0.005904007269111068 and parameters: {'activation': 'relu', 'learning_rate_init': 0.0008344964785577235, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:55:33,354]\u001b[0m Trial 123 finished with value: 0.0065468747379173456 and parameters: {'activation': 'relu', 'learning_rate_init': 0.0009557103480360867, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:55:38,487]\u001b[0m Trial 124 finished with value: 0.006173699802903005 and parameters: {'activation': 'relu', 'learning_rate_init': 0.0004394919970361022, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:55:43,705]\u001b[0m Trial 125 finished with value: 0.006568215579659207 and parameters: {'activation': 'relu', 'learning_rate_init': 0.0007314795785785341, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:55:48,827]\u001b[0m Trial 126 finished with value: 0.006366849600621731 and parameters: {'activation': 'relu', 'learning_rate_init': 0.001563988987868875, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:55:53,802]\u001b[0m Trial 127 finished with value: 0.006428801149092011 and parameters: {'activation': 'relu', 'learning_rate_init': 0.00025373803704696894, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:500: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "\n",
            "\u001b[32m[I 2021-08-16 01:55:58,691]\u001b[0m Trial 128 finished with value: 0.006292800220161661 and parameters: {'activation': 'relu', 'learning_rate_init': 0.021138665085554217, 'sovler': 'lbfgs'}. Best is trial 57 with value: 0.005865094663945668.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:56:00,271]\u001b[0m Trial 129 finished with value: 0.0058325107206735624 and parameters: {'activation': 'relu', 'learning_rate_init': 0.004468439769567275, 'sovler': 'adam'}. Best is trial 129 with value: 0.0058325107206735624.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:56:01,794]\u001b[0m Trial 130 finished with value: 0.0073873591184955975 and parameters: {'activation': 'relu', 'learning_rate_init': 0.005454286349145327, 'sovler': 'adam'}. Best is trial 129 with value: 0.0058325107206735624.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:56:05,449]\u001b[0m Trial 131 finished with value: 0.012835272754598425 and parameters: {'activation': 'relu', 'learning_rate_init': 3.98788658900069e-05, 'sovler': 'adam'}. Best is trial 129 with value: 0.0058325107206735624.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:56:07,386]\u001b[0m Trial 132 finished with value: 0.008858248745916076 and parameters: {'activation': 'relu', 'learning_rate_init': 0.00022368547698263603, 'sovler': 'adam'}. Best is trial 129 with value: 0.0058325107206735624.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:56:09,206]\u001b[0m Trial 133 finished with value: 0.006352541250917358 and parameters: {'activation': 'relu', 'learning_rate_init': 0.009382964134146285, 'sovler': 'adam'}. Best is trial 129 with value: 0.0058325107206735624.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:56:10,495]\u001b[0m Trial 134 finished with value: 0.005843824572146537 and parameters: {'activation': 'relu', 'learning_rate_init': 0.003615197536147329, 'sovler': 'adam'}. Best is trial 129 with value: 0.0058325107206735624.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:56:11,678]\u001b[0m Trial 135 finished with value: 0.006999967174330008 and parameters: {'activation': 'relu', 'learning_rate_init': 0.00398422479135711, 'sovler': 'adam'}. Best is trial 129 with value: 0.0058325107206735624.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:56:12,946]\u001b[0m Trial 136 finished with value: 0.007166851004063511 and parameters: {'activation': 'relu', 'learning_rate_init': 0.0025351866674660963, 'sovler': 'adam'}. Best is trial 129 with value: 0.0058325107206735624.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:56:14,846]\u001b[0m Trial 137 finished with value: 0.005642661148096466 and parameters: {'activation': 'relu', 'learning_rate_init': 0.0034151950832173625, 'sovler': 'adam'}. Best is trial 137 with value: 0.005642661148096466.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:56:17,520]\u001b[0m Trial 138 finished with value: 0.005293556359944912 and parameters: {'activation': 'relu', 'learning_rate_init': 0.0035090458768446448, 'sovler': 'adam'}. Best is trial 138 with value: 0.005293556359944912.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:56:19,081]\u001b[0m Trial 139 finished with value: 0.009067139498903585 and parameters: {'activation': 'logistic', 'learning_rate_init': 0.0037301133784174083, 'sovler': 'adam'}. Best is trial 138 with value: 0.005293556359944912.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:56:20,840]\u001b[0m Trial 140 finished with value: 0.005782233627655623 and parameters: {'activation': 'relu', 'learning_rate_init': 0.00479154598276631, 'sovler': 'adam'}. Best is trial 138 with value: 0.005293556359944912.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:56:22,577]\u001b[0m Trial 141 finished with value: 0.005836244997578659 and parameters: {'activation': 'relu', 'learning_rate_init': 0.003138859601407901, 'sovler': 'adam'}. Best is trial 138 with value: 0.005293556359944912.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:56:23,946]\u001b[0m Trial 142 finished with value: 0.007628161223025021 and parameters: {'activation': 'relu', 'learning_rate_init': 0.0033274373022972, 'sovler': 'adam'}. Best is trial 138 with value: 0.005293556359944912.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:56:25,196]\u001b[0m Trial 143 finished with value: 0.006440359489245619 and parameters: {'activation': 'relu', 'learning_rate_init': 0.004955089822636136, 'sovler': 'adam'}. Best is trial 138 with value: 0.005293556359944912.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:56:26,568]\u001b[0m Trial 144 finished with value: 0.006504922215625634 and parameters: {'activation': 'relu', 'learning_rate_init': 0.0024394372771787535, 'sovler': 'adam'}. Best is trial 138 with value: 0.005293556359944912.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:56:28,355]\u001b[0m Trial 145 finished with value: 0.005820957727165696 and parameters: {'activation': 'relu', 'learning_rate_init': 0.0019705952121112217, 'sovler': 'adam'}. Best is trial 138 with value: 0.005293556359944912.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:56:29,715]\u001b[0m Trial 146 finished with value: 0.0056656927476328965 and parameters: {'activation': 'relu', 'learning_rate_init': 0.006473920263493145, 'sovler': 'adam'}. Best is trial 138 with value: 0.005293556359944912.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:56:31,614]\u001b[0m Trial 147 finished with value: 0.005310114735825238 and parameters: {'activation': 'relu', 'learning_rate_init': 0.006514468641673813, 'sovler': 'adam'}. Best is trial 138 with value: 0.005293556359944912.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:56:34,004]\u001b[0m Trial 148 finished with value: 0.006175007236624588 and parameters: {'activation': 'relu', 'learning_rate_init': 0.010417595474081038, 'sovler': 'adam'}. Best is trial 138 with value: 0.005293556359944912.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:56:36,767]\u001b[0m Trial 149 finished with value: 0.008987438936194971 and parameters: {'activation': 'tanh', 'learning_rate_init': 0.006360530504084547, 'sovler': 'adam'}. Best is trial 138 with value: 0.005293556359944912.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:56:38,993]\u001b[0m Trial 150 finished with value: 0.0056925894175047795 and parameters: {'activation': 'relu', 'learning_rate_init': 0.0030538926438596604, 'sovler': 'adam'}. Best is trial 138 with value: 0.005293556359944912.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:56:40,025]\u001b[0m Trial 151 finished with value: 0.007375234465318303 and parameters: {'activation': 'relu', 'learning_rate_init': 0.0030711117128453497, 'sovler': 'adam'}. Best is trial 138 with value: 0.005293556359944912.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:56:41,262]\u001b[0m Trial 152 finished with value: 0.007438305628091141 and parameters: {'activation': 'relu', 'learning_rate_init': 0.004526725918422317, 'sovler': 'adam'}. Best is trial 138 with value: 0.005293556359944912.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:56:43,649]\u001b[0m Trial 153 finished with value: 0.004933317418051174 and parameters: {'activation': 'relu', 'learning_rate_init': 0.006072980797803359, 'sovler': 'adam'}. Best is trial 153 with value: 0.004933317418051174.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:56:45,704]\u001b[0m Trial 154 finished with value: 0.005496895382513646 and parameters: {'activation': 'relu', 'learning_rate_init': 0.007423315753293558, 'sovler': 'adam'}. Best is trial 153 with value: 0.004933317418051174.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:56:47,966]\u001b[0m Trial 155 finished with value: 0.005605593812651429 and parameters: {'activation': 'relu', 'learning_rate_init': 0.006040287117251403, 'sovler': 'adam'}. Best is trial 153 with value: 0.004933317418051174.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:56:49,696]\u001b[0m Trial 156 finished with value: 0.005552939657705357 and parameters: {'activation': 'relu', 'learning_rate_init': 0.006687978777137029, 'sovler': 'adam'}. Best is trial 153 with value: 0.004933317418051174.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:56:51,862]\u001b[0m Trial 157 finished with value: 0.006522853269672156 and parameters: {'activation': 'relu', 'learning_rate_init': 0.006797033766557775, 'sovler': 'adam'}. Best is trial 153 with value: 0.004933317418051174.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:56:52,623]\u001b[0m Trial 158 finished with value: 0.00998219567839725 and parameters: {'activation': 'identity', 'learning_rate_init': 0.011020322278099588, 'sovler': 'adam'}. Best is trial 153 with value: 0.004933317418051174.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:56:54,883]\u001b[0m Trial 159 finished with value: 0.006206017823938513 and parameters: {'activation': 'relu', 'learning_rate_init': 0.005922735375265606, 'sovler': 'adam'}. Best is trial 153 with value: 0.004933317418051174.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:56:56,669]\u001b[0m Trial 160 finished with value: 0.006844280222752651 and parameters: {'activation': 'relu', 'learning_rate_init': 0.0077268796144625545, 'sovler': 'adam'}. Best is trial 153 with value: 0.004933317418051174.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:56:58,064]\u001b[0m Trial 161 finished with value: 0.007016772042935171 and parameters: {'activation': 'relu', 'learning_rate_init': 0.004406953555220001, 'sovler': 'adam'}. Best is trial 153 with value: 0.004933317418051174.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:57:00,048]\u001b[0m Trial 162 finished with value: 0.006063836229318424 and parameters: {'activation': 'relu', 'learning_rate_init': 0.003409309703292897, 'sovler': 'adam'}. Best is trial 153 with value: 0.004933317418051174.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:57:01,491]\u001b[0m Trial 163 finished with value: 0.006052985767511581 and parameters: {'activation': 'relu', 'learning_rate_init': 0.0029479239052631794, 'sovler': 'adam'}. Best is trial 153 with value: 0.004933317418051174.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:57:02,866]\u001b[0m Trial 164 finished with value: 0.0065851737069541 and parameters: {'activation': 'relu', 'learning_rate_init': 0.0015153301985810718, 'sovler': 'adam'}. Best is trial 153 with value: 0.004933317418051174.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:57:04,600]\u001b[0m Trial 165 finished with value: 0.005799520382715954 and parameters: {'activation': 'relu', 'learning_rate_init': 0.018319965554315407, 'sovler': 'adam'}. Best is trial 153 with value: 0.004933317418051174.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:57:06,725]\u001b[0m Trial 166 finished with value: 0.005357230731056212 and parameters: {'activation': 'relu', 'learning_rate_init': 0.004150613012316, 'sovler': 'adam'}. Best is trial 153 with value: 0.004933317418051174.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:57:08,646]\u001b[0m Trial 167 finished with value: 0.00561767533154438 and parameters: {'activation': 'relu', 'learning_rate_init': 0.00423787403168698, 'sovler': 'adam'}. Best is trial 153 with value: 0.004933317418051174.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:57:09,972]\u001b[0m Trial 168 finished with value: 0.005691419722215487 and parameters: {'activation': 'relu', 'learning_rate_init': 0.004295867897303659, 'sovler': 'adam'}. Best is trial 153 with value: 0.004933317418051174.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:57:11,815]\u001b[0m Trial 169 finished with value: 0.005353915337138489 and parameters: {'activation': 'relu', 'learning_rate_init': 0.00745061084171531, 'sovler': 'adam'}. Best is trial 153 with value: 0.004933317418051174.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:57:13,849]\u001b[0m Trial 170 finished with value: 0.005867848656829328 and parameters: {'activation': 'relu', 'learning_rate_init': 0.007610083250855327, 'sovler': 'adam'}. Best is trial 153 with value: 0.004933317418051174.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:57:16,043]\u001b[0m Trial 171 finished with value: 0.005992045719212118 and parameters: {'activation': 'relu', 'learning_rate_init': 0.005604277674877183, 'sovler': 'adam'}. Best is trial 153 with value: 0.004933317418051174.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:57:17,851]\u001b[0m Trial 172 finished with value: 0.005926144115946362 and parameters: {'activation': 'relu', 'learning_rate_init': 0.004390424193581273, 'sovler': 'adam'}. Best is trial 153 with value: 0.004933317418051174.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:57:19,266]\u001b[0m Trial 173 finished with value: 0.006052606961962057 and parameters: {'activation': 'relu', 'learning_rate_init': 0.0166805688547514, 'sovler': 'adam'}. Best is trial 153 with value: 0.004933317418051174.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:57:21,129]\u001b[0m Trial 174 finished with value: 0.006353155807586235 and parameters: {'activation': 'relu', 'learning_rate_init': 0.006359682892407592, 'sovler': 'adam'}. Best is trial 153 with value: 0.004933317418051174.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:57:23,328]\u001b[0m Trial 175 finished with value: 0.0051526584649759025 and parameters: {'activation': 'relu', 'learning_rate_init': 0.01261964498355542, 'sovler': 'adam'}. Best is trial 153 with value: 0.004933317418051174.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:57:24,990]\u001b[0m Trial 176 finished with value: 0.005915491119588235 and parameters: {'activation': 'relu', 'learning_rate_init': 0.009497208239599835, 'sovler': 'adam'}. Best is trial 153 with value: 0.004933317418051174.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:57:26,275]\u001b[0m Trial 177 finished with value: 0.006689746487652973 and parameters: {'activation': 'relu', 'learning_rate_init': 0.011604699751921316, 'sovler': 'adam'}. Best is trial 153 with value: 0.004933317418051174.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:57:28,336]\u001b[0m Trial 178 finished with value: 0.006119456555621694 and parameters: {'activation': 'relu', 'learning_rate_init': 0.008215017856383055, 'sovler': 'adam'}. Best is trial 153 with value: 0.004933317418051174.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:57:29,671]\u001b[0m Trial 179 finished with value: 0.008433548155374315 and parameters: {'activation': 'relu', 'learning_rate_init': 0.004782286426009745, 'sovler': 'adam'}. Best is trial 153 with value: 0.004933317418051174.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:57:31,076]\u001b[0m Trial 180 finished with value: 0.009628324045138194 and parameters: {'activation': 'logistic', 'learning_rate_init': 0.016627415307292216, 'sovler': 'adam'}. Best is trial 153 with value: 0.004933317418051174.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:57:32,722]\u001b[0m Trial 181 finished with value: 0.006157195406015491 and parameters: {'activation': 'relu', 'learning_rate_init': 0.00220612294485082, 'sovler': 'adam'}. Best is trial 153 with value: 0.004933317418051174.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:57:34,553]\u001b[0m Trial 182 finished with value: 0.0062561575527176295 and parameters: {'activation': 'relu', 'learning_rate_init': 0.002817794073206881, 'sovler': 'adam'}. Best is trial 153 with value: 0.004933317418051174.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:57:36,267]\u001b[0m Trial 183 finished with value: 0.00681914114906402 and parameters: {'activation': 'relu', 'learning_rate_init': 0.0038419434248544346, 'sovler': 'adam'}. Best is trial 153 with value: 0.004933317418051174.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:57:37,296]\u001b[0m Trial 184 finished with value: 0.006795811812136324 and parameters: {'activation': 'relu', 'learning_rate_init': 0.005810559132487018, 'sovler': 'adam'}. Best is trial 153 with value: 0.004933317418051174.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:57:38,570]\u001b[0m Trial 185 finished with value: 0.006620206431639337 and parameters: {'activation': 'relu', 'learning_rate_init': 0.0049508065633015194, 'sovler': 'adam'}. Best is trial 153 with value: 0.004933317418051174.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:57:40,337]\u001b[0m Trial 186 finished with value: 0.005476951407535285 and parameters: {'activation': 'relu', 'learning_rate_init': 0.00693221452882948, 'sovler': 'adam'}. Best is trial 153 with value: 0.004933317418051174.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:57:42,041]\u001b[0m Trial 187 finished with value: 0.006200304724841852 and parameters: {'activation': 'relu', 'learning_rate_init': 0.007174465722375555, 'sovler': 'adam'}. Best is trial 153 with value: 0.004933317418051174.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:57:43,723]\u001b[0m Trial 188 finished with value: 0.0069184433452802035 and parameters: {'activation': 'relu', 'learning_rate_init': 0.012236195997207485, 'sovler': 'adam'}. Best is trial 153 with value: 0.004933317418051174.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:57:45,294]\u001b[0m Trial 189 finished with value: 0.006074744441508593 and parameters: {'activation': 'relu', 'learning_rate_init': 0.009084118961889594, 'sovler': 'adam'}. Best is trial 153 with value: 0.004933317418051174.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:57:46,580]\u001b[0m Trial 190 finished with value: 0.008668324936641143 and parameters: {'activation': 'tanh', 'learning_rate_init': 0.006372084397773498, 'sovler': 'adam'}. Best is trial 153 with value: 0.004933317418051174.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:57:48,101]\u001b[0m Trial 191 finished with value: 0.0065083181103894865 and parameters: {'activation': 'relu', 'learning_rate_init': 0.004351503555211571, 'sovler': 'adam'}. Best is trial 153 with value: 0.004933317418051174.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:57:50,001]\u001b[0m Trial 192 finished with value: 0.006196826584715507 and parameters: {'activation': 'relu', 'learning_rate_init': 0.002686568677613978, 'sovler': 'adam'}. Best is trial 153 with value: 0.004933317418051174.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:57:51,488]\u001b[0m Trial 193 finished with value: 0.006407856220026705 and parameters: {'activation': 'relu', 'learning_rate_init': 0.03237515925613736, 'sovler': 'adam'}. Best is trial 153 with value: 0.004933317418051174.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:57:52,852]\u001b[0m Trial 194 finished with value: 0.00665399233939188 and parameters: {'activation': 'relu', 'learning_rate_init': 0.003683715026378071, 'sovler': 'adam'}. Best is trial 153 with value: 0.004933317418051174.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:57:54,764]\u001b[0m Trial 195 finished with value: 0.005398910554606289 and parameters: {'activation': 'relu', 'learning_rate_init': 0.005285933948110119, 'sovler': 'adam'}. Best is trial 153 with value: 0.004933317418051174.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:57:56,097]\u001b[0m Trial 196 finished with value: 0.00639955308209186 and parameters: {'activation': 'relu', 'learning_rate_init': 0.005301406714100918, 'sovler': 'adam'}. Best is trial 153 with value: 0.004933317418051174.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:57:56,762]\u001b[0m Trial 197 finished with value: 0.009288001820831612 and parameters: {'activation': 'identity', 'learning_rate_init': 0.007173546855578089, 'sovler': 'adam'}. Best is trial 153 with value: 0.004933317418051174.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:57:59,172]\u001b[0m Trial 198 finished with value: 0.005735167976662761 and parameters: {'activation': 'relu', 'learning_rate_init': 0.014927997053458254, 'sovler': 'adam'}. Best is trial 153 with value: 0.004933317418051174.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:58:00,528]\u001b[0m Trial 199 finished with value: 0.007831401879610431 and parameters: {'activation': 'relu', 'learning_rate_init': 0.015238278533976905, 'sovler': 'adam'}. Best is trial 153 with value: 0.004933317418051174.\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjCwnIL9ZOlo",
        "outputId": "b78f378f-ad63-4250-b712-bfb48b017504"
      },
      "source": [
        "trial = study_mlp.best_trial\n",
        "print(f'MSE: {trial.value}')\n",
        "print(f'Best hyperparameters: {trial.params}')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE: 0.004933317418051174\n",
            "Best hyperparameters: {'activation': 'relu', 'learning_rate_init': 0.006072980797803359, 'sovler': 'adam'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "Z0n9q2w_Zbq_",
        "outputId": "282312f5-dac8-4a2a-f4af-3c52c27103be"
      },
      "source": [
        "optuna.visualization.plot_optimization_history(study_mlp)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"703ead94-b7e3-45d4-a617-b8622005db9a\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"703ead94-b7e3-45d4-a617-b8622005db9a\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '703ead94-b7e3-45d4-a617-b8622005db9a',\n",
              "                        [{\"mode\": \"markers\", \"name\": \"Objective Value\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199], \"y\": [0.013695509917260046, 0.008133149339349981, 0.015455278896278148, 0.007678923474873372, 0.0062468419440012985, 0.009339109347370454, 0.008954909108110903, 0.009089734674604128, 0.009212045284351381, 0.00951905120214715, 0.02065626918730477, 0.006074175560095507, 0.006297134954055606, 0.006162516976329459, 0.006309112837340831, 0.006196824084645335, 0.017783102500945967, 0.006687782009171488, 0.006461768247620354, 0.014574974919045499, 0.006398944966489172, 0.006145404864957239, 0.006314334129367772, 0.006224434552035505, 0.006105436721383346, 0.006220783320594887, 0.006263200348366856, 0.009267018286082005, 0.014423400024314007, 0.009201759070761853, 0.026217843803159988, 0.006639479613995171, 0.006294961256462405, 0.006236324949200261, 0.007970206123169498, 0.006218814549066823, 0.005989590933027521, 0.013179784310920293, 0.008143956416012685, 0.009186710331701849, 0.005942776346336866, 0.008915116063218655, 0.006391897881596097, 0.010441193649755508, 0.006729603048224194, 0.007718684416338415, 0.0063117407521246114, 0.009262362908332633, 0.006372415381217816, 0.006172927482671538, 0.012866157913731396, 0.006379542812996053, 0.006083451665754033, 0.00651117131179485, 0.0063693355423317475, 0.006109853422359667, 0.005995329857021493, 0.005865094663945668, 0.007762420909572033, 0.009725733303839882, 0.01223267853909535, 0.006333912348474149, 0.006759613087976074, 0.006285453558327543, 0.006490236566838725, 0.006343387834157826, 0.00618087919986332, 0.00829769504770551, 0.006227516731100143, 0.006023561725052611, 0.006340284096767526, 0.006311029742732632, 0.006463703828415786, 0.006099382151191197, 0.006009693411745203, 0.009800484923361934, 0.021162858743568477, 0.006597573734344217, 0.0062756791742859955, 0.007970300912628486, 0.009172364923234885, 0.006548341132241544, 0.006391103200016834, 0.00648128204049954, 0.006691098994879275, 0.006037849533632324, 0.010510784868511978, 0.006301091327853603, 0.006381334894751307, 0.009688464857942026, 0.021865572125728656, 0.006402741433354416, 0.006240649176638988, 0.0061124260845843905, 0.006135132252003531, 0.006456263819764983, 0.009714103944425748, 0.00820027840447612, 0.009169355970021274, 0.006142047695671848, 0.006104626881763451, 0.0062618202241571915, 0.006115686269621371, 0.0060400517130737375, 0.00644132355235336, 0.006360427559683202, 0.006777025650588393, 0.006482852027193088, 0.006168481074570905, 0.006438947178460044, 0.01463721655823561, 0.006722659552924655, 0.00642954047424171, 0.006042265406113458, 0.006348281823057037, 0.006332731862933246, 0.0061142222499553514, 0.008802255531093985, 0.006503559626038323, 0.009095941574271906, 0.009128065504655348, 0.006050601470835176, 0.005904007269111068, 0.0065468747379173456, 0.006173699802903005, 0.006568215579659207, 0.006366849600621731, 0.006428801149092011, 0.006292800220161661, 0.0058325107206735624, 0.0073873591184955975, 0.012835272754598425, 0.008858248745916076, 0.006352541250917358, 0.005843824572146537, 0.006999967174330008, 0.007166851004063511, 0.005642661148096466, 0.005293556359944912, 0.009067139498903585, 0.005782233627655623, 0.005836244997578659, 0.007628161223025021, 0.006440359489245619, 0.006504922215625634, 0.005820957727165696, 0.0056656927476328965, 0.005310114735825238, 0.006175007236624588, 0.008987438936194971, 0.0056925894175047795, 0.007375234465318303, 0.007438305628091141, 0.004933317418051174, 0.005496895382513646, 0.005605593812651429, 0.005552939657705357, 0.006522853269672156, 0.00998219567839725, 0.006206017823938513, 0.006844280222752651, 0.007016772042935171, 0.006063836229318424, 0.006052985767511581, 0.0065851737069541, 0.005799520382715954, 0.005357230731056212, 0.00561767533154438, 0.005691419722215487, 0.005353915337138489, 0.005867848656829328, 0.005992045719212118, 0.005926144115946362, 0.006052606961962057, 0.006353155807586235, 0.0051526584649759025, 0.005915491119588235, 0.006689746487652973, 0.006119456555621694, 0.008433548155374315, 0.009628324045138194, 0.006157195406015491, 0.0062561575527176295, 0.00681914114906402, 0.006795811812136324, 0.006620206431639337, 0.005476951407535285, 0.006200304724841852, 0.0069184433452802035, 0.006074744441508593, 0.008668324936641143, 0.0065083181103894865, 0.006196826584715507, 0.006407856220026705, 0.00665399233939188, 0.005398910554606289, 0.00639955308209186, 0.009288001820831612, 0.005735167976662761, 0.007831401879610431]}, {\"name\": \"Best Value\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199], \"y\": [0.013695509917260046, 0.008133149339349981, 0.008133149339349981, 0.007678923474873372, 0.0062468419440012985, 0.0062468419440012985, 0.0062468419440012985, 0.0062468419440012985, 0.0062468419440012985, 0.0062468419440012985, 0.0062468419440012985, 0.006074175560095507, 0.006074175560095507, 0.006074175560095507, 0.006074175560095507, 0.006074175560095507, 0.006074175560095507, 0.006074175560095507, 0.006074175560095507, 0.006074175560095507, 0.006074175560095507, 0.006074175560095507, 0.006074175560095507, 0.006074175560095507, 0.006074175560095507, 0.006074175560095507, 0.006074175560095507, 0.006074175560095507, 0.006074175560095507, 0.006074175560095507, 0.006074175560095507, 0.006074175560095507, 0.006074175560095507, 0.006074175560095507, 0.006074175560095507, 0.006074175560095507, 0.005989590933027521, 0.005989590933027521, 0.005989590933027521, 0.005989590933027521, 0.005942776346336866, 0.005942776346336866, 0.005942776346336866, 0.005942776346336866, 0.005942776346336866, 0.005942776346336866, 0.005942776346336866, 0.005942776346336866, 0.005942776346336866, 0.005942776346336866, 0.005942776346336866, 0.005942776346336866, 0.005942776346336866, 0.005942776346336866, 0.005942776346336866, 0.005942776346336866, 0.005942776346336866, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.005865094663945668, 0.0058325107206735624, 0.0058325107206735624, 0.0058325107206735624, 0.0058325107206735624, 0.0058325107206735624, 0.0058325107206735624, 0.0058325107206735624, 0.0058325107206735624, 0.005642661148096466, 0.005293556359944912, 0.005293556359944912, 0.005293556359944912, 0.005293556359944912, 0.005293556359944912, 0.005293556359944912, 0.005293556359944912, 0.005293556359944912, 0.005293556359944912, 0.005293556359944912, 0.005293556359944912, 0.005293556359944912, 0.005293556359944912, 0.005293556359944912, 0.005293556359944912, 0.004933317418051174, 0.004933317418051174, 0.004933317418051174, 0.004933317418051174, 0.004933317418051174, 0.004933317418051174, 0.004933317418051174, 0.004933317418051174, 0.004933317418051174, 0.004933317418051174, 0.004933317418051174, 0.004933317418051174, 0.004933317418051174, 0.004933317418051174, 0.004933317418051174, 0.004933317418051174, 0.004933317418051174, 0.004933317418051174, 0.004933317418051174, 0.004933317418051174, 0.004933317418051174, 0.004933317418051174, 0.004933317418051174, 0.004933317418051174, 0.004933317418051174, 0.004933317418051174, 0.004933317418051174, 0.004933317418051174, 0.004933317418051174, 0.004933317418051174, 0.004933317418051174, 0.004933317418051174, 0.004933317418051174, 0.004933317418051174, 0.004933317418051174, 0.004933317418051174, 0.004933317418051174, 0.004933317418051174, 0.004933317418051174, 0.004933317418051174, 0.004933317418051174, 0.004933317418051174, 0.004933317418051174, 0.004933317418051174, 0.004933317418051174, 0.004933317418051174, 0.004933317418051174]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Optimization History Plot\"}, \"xaxis\": {\"title\": {\"text\": \"#Trials\"}}, \"yaxis\": {\"title\": {\"text\": \"Objective Value\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('703ead94-b7e3-45d4-a617-b8622005db9a');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "EmWN_PPrZvrp",
        "outputId": "c653c520-8214-4b8a-c1b4-3df54b3dc3d5"
      },
      "source": [
        "optuna.visualization.plot_slice(study_mlp)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"6c804482-97c2-422b-8da3-e331f460a0f0\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"6c804482-97c2-422b-8da3-e331f460a0f0\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '6c804482-97c2-422b-8da3-e331f460a0f0',\n",
              "                        [{\"marker\": {\"color\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199], \"colorbar\": {\"title\": {\"text\": \"#Trials\"}, \"x\": 1.0, \"xpad\": 40}, \"colorscale\": [[0.0, \"rgb(247,251,255)\"], [0.125, \"rgb(222,235,247)\"], [0.25, \"rgb(198,219,239)\"], [0.375, \"rgb(158,202,225)\"], [0.5, \"rgb(107,174,214)\"], [0.625, \"rgb(66,146,198)\"], [0.75, \"rgb(33,113,181)\"], [0.875, \"rgb(8,81,156)\"], [1.0, \"rgb(8,48,107)\"]], \"line\": {\"color\": \"Grey\", \"width\": 0.5}, \"showscale\": true}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [\"logistic\", \"tanh\", \"logistic\", \"tanh\", \"relu\", \"identity\", \"tanh\", \"tanh\", \"identity\", \"identity\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"logistic\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"identity\", \"logistic\", \"logistic\", \"relu\", \"relu\", \"relu\", \"relu\", \"tanh\", \"relu\", \"relu\", \"logistic\", \"tanh\", \"identity\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"tanh\", \"relu\", \"identity\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"tanh\", \"logistic\", \"identity\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"logistic\", \"relu\", \"relu\", \"relu\", \"tanh\", \"identity\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"logistic\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"tanh\", \"identity\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"logistic\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"tanh\", \"identity\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"logistic\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"tanh\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"identity\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"logistic\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"tanh\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"identity\", \"relu\", \"relu\"], \"xaxis\": \"x\", \"y\": [0.013695509917260046, 0.008133149339349981, 0.015455278896278148, 0.007678923474873372, 0.0062468419440012985, 0.009339109347370454, 0.008954909108110903, 0.009089734674604128, 0.009212045284351381, 0.00951905120214715, 0.02065626918730477, 0.006074175560095507, 0.006297134954055606, 0.006162516976329459, 0.006309112837340831, 0.006196824084645335, 0.017783102500945967, 0.006687782009171488, 0.006461768247620354, 0.014574974919045499, 0.006398944966489172, 0.006145404864957239, 0.006314334129367772, 0.006224434552035505, 0.006105436721383346, 0.006220783320594887, 0.006263200348366856, 0.009267018286082005, 0.014423400024314007, 0.009201759070761853, 0.026217843803159988, 0.006639479613995171, 0.006294961256462405, 0.006236324949200261, 0.007970206123169498, 0.006218814549066823, 0.005989590933027521, 0.013179784310920293, 0.008143956416012685, 0.009186710331701849, 0.005942776346336866, 0.008915116063218655, 0.006391897881596097, 0.010441193649755508, 0.006729603048224194, 0.007718684416338415, 0.0063117407521246114, 0.009262362908332633, 0.006372415381217816, 0.006172927482671538, 0.012866157913731396, 0.006379542812996053, 0.006083451665754033, 0.00651117131179485, 0.0063693355423317475, 0.006109853422359667, 0.005995329857021493, 0.005865094663945668, 0.007762420909572033, 0.009725733303839882, 0.01223267853909535, 0.006333912348474149, 0.006759613087976074, 0.006285453558327543, 0.006490236566838725, 0.006343387834157826, 0.00618087919986332, 0.00829769504770551, 0.006227516731100143, 0.006023561725052611, 0.006340284096767526, 0.006311029742732632, 0.006463703828415786, 0.006099382151191197, 0.006009693411745203, 0.009800484923361934, 0.021162858743568477, 0.006597573734344217, 0.0062756791742859955, 0.007970300912628486, 0.009172364923234885, 0.006548341132241544, 0.006391103200016834, 0.00648128204049954, 0.006691098994879275, 0.006037849533632324, 0.010510784868511978, 0.006301091327853603, 0.006381334894751307, 0.009688464857942026, 0.021865572125728656, 0.006402741433354416, 0.006240649176638988, 0.0061124260845843905, 0.006135132252003531, 0.006456263819764983, 0.009714103944425748, 0.00820027840447612, 0.009169355970021274, 0.006142047695671848, 0.006104626881763451, 0.0062618202241571915, 0.006115686269621371, 0.0060400517130737375, 0.00644132355235336, 0.006360427559683202, 0.006777025650588393, 0.006482852027193088, 0.006168481074570905, 0.006438947178460044, 0.01463721655823561, 0.006722659552924655, 0.00642954047424171, 0.006042265406113458, 0.006348281823057037, 0.006332731862933246, 0.0061142222499553514, 0.008802255531093985, 0.006503559626038323, 0.009095941574271906, 0.009128065504655348, 0.006050601470835176, 0.005904007269111068, 0.0065468747379173456, 0.006173699802903005, 0.006568215579659207, 0.006366849600621731, 0.006428801149092011, 0.006292800220161661, 0.0058325107206735624, 0.0073873591184955975, 0.012835272754598425, 0.008858248745916076, 0.006352541250917358, 0.005843824572146537, 0.006999967174330008, 0.007166851004063511, 0.005642661148096466, 0.005293556359944912, 0.009067139498903585, 0.005782233627655623, 0.005836244997578659, 0.007628161223025021, 0.006440359489245619, 0.006504922215625634, 0.005820957727165696, 0.0056656927476328965, 0.005310114735825238, 0.006175007236624588, 0.008987438936194971, 0.0056925894175047795, 0.007375234465318303, 0.007438305628091141, 0.004933317418051174, 0.005496895382513646, 0.005605593812651429, 0.005552939657705357, 0.006522853269672156, 0.00998219567839725, 0.006206017823938513, 0.006844280222752651, 0.007016772042935171, 0.006063836229318424, 0.006052985767511581, 0.0065851737069541, 0.005799520382715954, 0.005357230731056212, 0.00561767533154438, 0.005691419722215487, 0.005353915337138489, 0.005867848656829328, 0.005992045719212118, 0.005926144115946362, 0.006052606961962057, 0.006353155807586235, 0.0051526584649759025, 0.005915491119588235, 0.006689746487652973, 0.006119456555621694, 0.008433548155374315, 0.009628324045138194, 0.006157195406015491, 0.0062561575527176295, 0.00681914114906402, 0.006795811812136324, 0.006620206431639337, 0.005476951407535285, 0.006200304724841852, 0.0069184433452802035, 0.006074744441508593, 0.008668324936641143, 0.0065083181103894865, 0.006196826584715507, 0.006407856220026705, 0.00665399233939188, 0.005398910554606289, 0.00639955308209186, 0.009288001820831612, 0.005735167976662761, 0.007831401879610431], \"yaxis\": \"y\"}, {\"marker\": {\"color\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199], \"colorbar\": {\"title\": {\"text\": \"#Trials\"}, \"x\": 1.0, \"xpad\": 40}, \"colorscale\": [[0.0, \"rgb(247,251,255)\"], [0.125, \"rgb(222,235,247)\"], [0.25, \"rgb(198,219,239)\"], [0.375, \"rgb(158,202,225)\"], [0.5, \"rgb(107,174,214)\"], [0.625, \"rgb(66,146,198)\"], [0.75, \"rgb(33,113,181)\"], [0.875, \"rgb(8,81,156)\"], [1.0, \"rgb(8,48,107)\"]], \"line\": {\"color\": \"Grey\", \"width\": 0.5}, \"showscale\": false}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [0.004426463543424635, 0.2522112971976336, 0.16347845363221347, 0.0007636565222371477, 0.0008102444330370592, 0.013139224084121524, 0.0037315977067789246, 0.0003083307490328673, 0.0076256026980893845, 0.06863644771087009, 1.5493165732675558e-05, 0.00032379657351938536, 9.124623591957164e-05, 0.00011867378559237772, 6.313964880000278e-05, 1.0451953049446872e-05, 0.00014618945242928443, 0.00041255828327734157, 4.7862725042044405e-05, 3.2627775596095714e-05, 0.0013181988245779357, 1.2518578637656662e-05, 0.00019617502812210272, 2.4742887506897426e-05, 0.00011172081124072892, 2.739262827674626e-05, 0.0004488345665994013, 0.00022392102901032583, 1.0439786168529375e-05, 0.0026873727454611103, 5.8773472173541146e-05, 0.0001252330304175881, 7.975518260255472e-05, 0.0007032950527039105, 0.0016864735642886733, 2.131223891498782e-05, 4.4056663408739035e-05, 3.594772739672492e-05, 4.809580197418384e-05, 1.658130481480248e-05, 0.02195435656406207, 0.054044880039431455, 0.021678843781818953, 0.2532818682948917, 0.006871065522876489, 0.09307084106260881, 0.0007568478581173415, 0.01438014771578037, 0.029030914209994214, 0.0002449772921255375, 0.0003586076488838753, 0.00010029045826676522, 0.00015425867134821357, 0.00019120576573128714, 1.764988049288359e-05, 7.830365981262699e-05, 0.00015976113639713522, 0.00013807117061020554, 0.00017129802485203987, 0.0010941254793413277, 0.0004609393473908925, 0.00012241046278705403, 0.00027069893048130425, 4.2501359284052825e-05, 0.0005468693695594135, 7.440298686899554e-05, 0.00015028810939722676, 0.0003303823539839015, 0.0031175574806028253, 5.342971244627168e-05, 5.057444359261599e-05, 0.00010531938013308458, 3.053894271899106e-05, 0.00016428498251804563, 7.147736503858506e-05, 6.658018896109586e-05, 6.00873336021729e-05, 4.245219451857692e-05, 0.0051660706786025214, 2.192408746189087e-05, 9.097677040979472e-05, 0.00014518857382193247, 0.14808993099830642, 0.00022951298398953137, 0.00015712853909698914, 3.625528235762319e-05, 3.6269770595003634e-05, 5.72356498377965e-05, 1.38294408035907e-05, 3.330017724233539e-05, 2.4344008254585583e-05, 9.250581144415725e-05, 0.00019856556929441813, 0.00013690327208420802, 0.00028955118412288256, 0.0005678062337243398, 7.69939570702854e-05, 0.00012542371082428926, 4.366739698704087e-05, 0.0011330824664385695, 0.00035331175940538166, 0.0001852686858636112, 0.0003919325485041484, 0.001982364672750281, 0.0141523495875905, 0.00847563611026996, 0.0018301233449911063, 0.04311571961187077, 0.00010482864327197133, 1.9041701012368514e-05, 5.358005957505928e-05, 0.0002906781808401537, 0.0005494714257476875, 0.00021777731228486845, 8.60610555851029e-05, 0.00021877046306153572, 7.034325591400373e-05, 0.00015887092290578345, 0.00010829393953377467, 0.0021379823424026853, 2.9891042876614682e-05, 0.0003282286817807923, 0.0008344964785577235, 0.0009557103480360867, 0.0004394919970361022, 0.0007314795785785341, 0.001563988987868875, 0.00025373803704696894, 0.021138665085554217, 0.004468439769567275, 0.005454286349145327, 3.98788658900069e-05, 0.00022368547698263603, 0.009382964134146285, 0.003615197536147329, 0.00398422479135711, 0.0025351866674660963, 0.0034151950832173625, 0.0035090458768446448, 0.0037301133784174083, 0.00479154598276631, 0.003138859601407901, 0.0033274373022972, 0.004955089822636136, 0.0024394372771787535, 0.0019705952121112217, 0.006473920263493145, 0.006514468641673813, 0.010417595474081038, 0.006360530504084547, 0.0030538926438596604, 0.0030711117128453497, 0.004526725918422317, 0.006072980797803359, 0.007423315753293558, 0.006040287117251403, 0.006687978777137029, 0.006797033766557775, 0.011020322278099588, 0.005922735375265606, 0.0077268796144625545, 0.004406953555220001, 0.003409309703292897, 0.0029479239052631794, 0.0015153301985810718, 0.018319965554315407, 0.004150613012316, 0.00423787403168698, 0.004295867897303659, 0.00745061084171531, 0.007610083250855327, 0.005604277674877183, 0.004390424193581273, 0.0166805688547514, 0.006359682892407592, 0.01261964498355542, 0.009497208239599835, 0.011604699751921316, 0.008215017856383055, 0.004782286426009745, 0.016627415307292216, 0.00220612294485082, 0.002817794073206881, 0.0038419434248544346, 0.005810559132487018, 0.0049508065633015194, 0.00693221452882948, 0.007174465722375555, 0.012236195997207485, 0.009084118961889594, 0.006372084397773498, 0.004351503555211571, 0.002686568677613978, 0.03237515925613736, 0.003683715026378071, 0.005285933948110119, 0.005301406714100918, 0.007173546855578089, 0.014927997053458254, 0.015238278533976905], \"xaxis\": \"x2\", \"y\": [0.013695509917260046, 0.008133149339349981, 0.015455278896278148, 0.007678923474873372, 0.0062468419440012985, 0.009339109347370454, 0.008954909108110903, 0.009089734674604128, 0.009212045284351381, 0.00951905120214715, 0.02065626918730477, 0.006074175560095507, 0.006297134954055606, 0.006162516976329459, 0.006309112837340831, 0.006196824084645335, 0.017783102500945967, 0.006687782009171488, 0.006461768247620354, 0.014574974919045499, 0.006398944966489172, 0.006145404864957239, 0.006314334129367772, 0.006224434552035505, 0.006105436721383346, 0.006220783320594887, 0.006263200348366856, 0.009267018286082005, 0.014423400024314007, 0.009201759070761853, 0.026217843803159988, 0.006639479613995171, 0.006294961256462405, 0.006236324949200261, 0.007970206123169498, 0.006218814549066823, 0.005989590933027521, 0.013179784310920293, 0.008143956416012685, 0.009186710331701849, 0.005942776346336866, 0.008915116063218655, 0.006391897881596097, 0.010441193649755508, 0.006729603048224194, 0.007718684416338415, 0.0063117407521246114, 0.009262362908332633, 0.006372415381217816, 0.006172927482671538, 0.012866157913731396, 0.006379542812996053, 0.006083451665754033, 0.00651117131179485, 0.0063693355423317475, 0.006109853422359667, 0.005995329857021493, 0.005865094663945668, 0.007762420909572033, 0.009725733303839882, 0.01223267853909535, 0.006333912348474149, 0.006759613087976074, 0.006285453558327543, 0.006490236566838725, 0.006343387834157826, 0.00618087919986332, 0.00829769504770551, 0.006227516731100143, 0.006023561725052611, 0.006340284096767526, 0.006311029742732632, 0.006463703828415786, 0.006099382151191197, 0.006009693411745203, 0.009800484923361934, 0.021162858743568477, 0.006597573734344217, 0.0062756791742859955, 0.007970300912628486, 0.009172364923234885, 0.006548341132241544, 0.006391103200016834, 0.00648128204049954, 0.006691098994879275, 0.006037849533632324, 0.010510784868511978, 0.006301091327853603, 0.006381334894751307, 0.009688464857942026, 0.021865572125728656, 0.006402741433354416, 0.006240649176638988, 0.0061124260845843905, 0.006135132252003531, 0.006456263819764983, 0.009714103944425748, 0.00820027840447612, 0.009169355970021274, 0.006142047695671848, 0.006104626881763451, 0.0062618202241571915, 0.006115686269621371, 0.0060400517130737375, 0.00644132355235336, 0.006360427559683202, 0.006777025650588393, 0.006482852027193088, 0.006168481074570905, 0.006438947178460044, 0.01463721655823561, 0.006722659552924655, 0.00642954047424171, 0.006042265406113458, 0.006348281823057037, 0.006332731862933246, 0.0061142222499553514, 0.008802255531093985, 0.006503559626038323, 0.009095941574271906, 0.009128065504655348, 0.006050601470835176, 0.005904007269111068, 0.0065468747379173456, 0.006173699802903005, 0.006568215579659207, 0.006366849600621731, 0.006428801149092011, 0.006292800220161661, 0.0058325107206735624, 0.0073873591184955975, 0.012835272754598425, 0.008858248745916076, 0.006352541250917358, 0.005843824572146537, 0.006999967174330008, 0.007166851004063511, 0.005642661148096466, 0.005293556359944912, 0.009067139498903585, 0.005782233627655623, 0.005836244997578659, 0.007628161223025021, 0.006440359489245619, 0.006504922215625634, 0.005820957727165696, 0.0056656927476328965, 0.005310114735825238, 0.006175007236624588, 0.008987438936194971, 0.0056925894175047795, 0.007375234465318303, 0.007438305628091141, 0.004933317418051174, 0.005496895382513646, 0.005605593812651429, 0.005552939657705357, 0.006522853269672156, 0.00998219567839725, 0.006206017823938513, 0.006844280222752651, 0.007016772042935171, 0.006063836229318424, 0.006052985767511581, 0.0065851737069541, 0.005799520382715954, 0.005357230731056212, 0.00561767533154438, 0.005691419722215487, 0.005353915337138489, 0.005867848656829328, 0.005992045719212118, 0.005926144115946362, 0.006052606961962057, 0.006353155807586235, 0.0051526584649759025, 0.005915491119588235, 0.006689746487652973, 0.006119456555621694, 0.008433548155374315, 0.009628324045138194, 0.006157195406015491, 0.0062561575527176295, 0.00681914114906402, 0.006795811812136324, 0.006620206431639337, 0.005476951407535285, 0.006200304724841852, 0.0069184433452802035, 0.006074744441508593, 0.008668324936641143, 0.0065083181103894865, 0.006196826584715507, 0.006407856220026705, 0.00665399233939188, 0.005398910554606289, 0.00639955308209186, 0.009288001820831612, 0.005735167976662761, 0.007831401879610431], \"yaxis\": \"y2\"}, {\"marker\": {\"color\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199], \"colorbar\": {\"title\": {\"text\": \"#Trials\"}, \"x\": 1.0, \"xpad\": 40}, \"colorscale\": [[0.0, \"rgb(247,251,255)\"], [0.125, \"rgb(222,235,247)\"], [0.25, \"rgb(198,219,239)\"], [0.375, \"rgb(158,202,225)\"], [0.5, \"rgb(107,174,214)\"], [0.625, \"rgb(66,146,198)\"], [0.75, \"rgb(33,113,181)\"], [0.875, \"rgb(8,81,156)\"], [1.0, \"rgb(8,48,107)\"]], \"line\": {\"color\": \"Grey\", \"width\": 0.5}, \"showscale\": false}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [\"sgd\", \"lbfgs\", \"adam\", \"lbfgs\", \"lbfgs\", \"adam\", \"adam\", \"lbfgs\", \"lbfgs\", \"adam\", \"sgd\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"sgd\", \"lbfgs\", \"lbfgs\", \"sgd\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"sgd\", \"adam\", \"sgd\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"adam\", \"lbfgs\", \"lbfgs\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"lbfgs\", \"lbfgs\", \"adam\", \"lbfgs\", \"sgd\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"sgd\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"adam\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"sgd\", \"lbfgs\", \"adam\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"adam\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"sgd\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"adam\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"adam\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"sgd\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"adam\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"lbfgs\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\", \"adam\"], \"xaxis\": \"x3\", \"y\": [0.013695509917260046, 0.008133149339349981, 0.015455278896278148, 0.007678923474873372, 0.0062468419440012985, 0.009339109347370454, 0.008954909108110903, 0.009089734674604128, 0.009212045284351381, 0.00951905120214715, 0.02065626918730477, 0.006074175560095507, 0.006297134954055606, 0.006162516976329459, 0.006309112837340831, 0.006196824084645335, 0.017783102500945967, 0.006687782009171488, 0.006461768247620354, 0.014574974919045499, 0.006398944966489172, 0.006145404864957239, 0.006314334129367772, 0.006224434552035505, 0.006105436721383346, 0.006220783320594887, 0.006263200348366856, 0.009267018286082005, 0.014423400024314007, 0.009201759070761853, 0.026217843803159988, 0.006639479613995171, 0.006294961256462405, 0.006236324949200261, 0.007970206123169498, 0.006218814549066823, 0.005989590933027521, 0.013179784310920293, 0.008143956416012685, 0.009186710331701849, 0.005942776346336866, 0.008915116063218655, 0.006391897881596097, 0.010441193649755508, 0.006729603048224194, 0.007718684416338415, 0.0063117407521246114, 0.009262362908332633, 0.006372415381217816, 0.006172927482671538, 0.012866157913731396, 0.006379542812996053, 0.006083451665754033, 0.00651117131179485, 0.0063693355423317475, 0.006109853422359667, 0.005995329857021493, 0.005865094663945668, 0.007762420909572033, 0.009725733303839882, 0.01223267853909535, 0.006333912348474149, 0.006759613087976074, 0.006285453558327543, 0.006490236566838725, 0.006343387834157826, 0.00618087919986332, 0.00829769504770551, 0.006227516731100143, 0.006023561725052611, 0.006340284096767526, 0.006311029742732632, 0.006463703828415786, 0.006099382151191197, 0.006009693411745203, 0.009800484923361934, 0.021162858743568477, 0.006597573734344217, 0.0062756791742859955, 0.007970300912628486, 0.009172364923234885, 0.006548341132241544, 0.006391103200016834, 0.00648128204049954, 0.006691098994879275, 0.006037849533632324, 0.010510784868511978, 0.006301091327853603, 0.006381334894751307, 0.009688464857942026, 0.021865572125728656, 0.006402741433354416, 0.006240649176638988, 0.0061124260845843905, 0.006135132252003531, 0.006456263819764983, 0.009714103944425748, 0.00820027840447612, 0.009169355970021274, 0.006142047695671848, 0.006104626881763451, 0.0062618202241571915, 0.006115686269621371, 0.0060400517130737375, 0.00644132355235336, 0.006360427559683202, 0.006777025650588393, 0.006482852027193088, 0.006168481074570905, 0.006438947178460044, 0.01463721655823561, 0.006722659552924655, 0.00642954047424171, 0.006042265406113458, 0.006348281823057037, 0.006332731862933246, 0.0061142222499553514, 0.008802255531093985, 0.006503559626038323, 0.009095941574271906, 0.009128065504655348, 0.006050601470835176, 0.005904007269111068, 0.0065468747379173456, 0.006173699802903005, 0.006568215579659207, 0.006366849600621731, 0.006428801149092011, 0.006292800220161661, 0.0058325107206735624, 0.0073873591184955975, 0.012835272754598425, 0.008858248745916076, 0.006352541250917358, 0.005843824572146537, 0.006999967174330008, 0.007166851004063511, 0.005642661148096466, 0.005293556359944912, 0.009067139498903585, 0.005782233627655623, 0.005836244997578659, 0.007628161223025021, 0.006440359489245619, 0.006504922215625634, 0.005820957727165696, 0.0056656927476328965, 0.005310114735825238, 0.006175007236624588, 0.008987438936194971, 0.0056925894175047795, 0.007375234465318303, 0.007438305628091141, 0.004933317418051174, 0.005496895382513646, 0.005605593812651429, 0.005552939657705357, 0.006522853269672156, 0.00998219567839725, 0.006206017823938513, 0.006844280222752651, 0.007016772042935171, 0.006063836229318424, 0.006052985767511581, 0.0065851737069541, 0.005799520382715954, 0.005357230731056212, 0.00561767533154438, 0.005691419722215487, 0.005353915337138489, 0.005867848656829328, 0.005992045719212118, 0.005926144115946362, 0.006052606961962057, 0.006353155807586235, 0.0051526584649759025, 0.005915491119588235, 0.006689746487652973, 0.006119456555621694, 0.008433548155374315, 0.009628324045138194, 0.006157195406015491, 0.0062561575527176295, 0.00681914114906402, 0.006795811812136324, 0.006620206431639337, 0.005476951407535285, 0.006200304724841852, 0.0069184433452802035, 0.006074744441508593, 0.008668324936641143, 0.0065083181103894865, 0.006196826584715507, 0.006407856220026705, 0.00665399233939188, 0.005398910554606289, 0.00639955308209186, 0.009288001820831612, 0.005735167976662761, 0.007831401879610431], \"yaxis\": \"y3\"}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Slice Plot\"}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.2888888888888889], \"title\": {\"text\": \"activation\"}}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.35555555555555557, 0.6444444444444445], \"title\": {\"text\": \"learning_rate_init\"}, \"type\": \"log\"}, \"xaxis3\": {\"anchor\": \"y3\", \"domain\": [0.7111111111111111, 1.0], \"title\": {\"text\": \"sovler\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Objective Value\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0], \"matches\": \"y\", \"showticklabels\": false}, \"yaxis3\": {\"anchor\": \"x3\", \"domain\": [0.0, 1.0], \"matches\": \"y\", \"showticklabels\": false}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('6c804482-97c2-422b-8da3-e331f460a0f0');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "Bh8Ymb8GZzK1",
        "outputId": "64d2310d-6db6-4a9a-f0b4-e8cd88d39d4b"
      },
      "source": [
        "optuna.visualization.plot_param_importances(study_mlp)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"9c232a37-46a0-45ff-a51b-4b0a8fe67439\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"9c232a37-46a0-45ff-a51b-4b0a8fe67439\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '9c232a37-46a0-45ff-a51b-4b0a8fe67439',\n",
              "                        [{\"cliponaxis\": false, \"hovertemplate\": [\"learning_rate_init (LogUniformDistribution): 0.042908949635272454<extra></extra>\", \"activation (CategoricalDistribution): 0.14597702166626284<extra></extra>\", \"sovler (CategoricalDistribution): 0.8111140286984647<extra></extra>\"], \"marker\": {\"color\": \"rgb(66,146,198)\"}, \"orientation\": \"h\", \"text\": [\"0.042908949635272454\", \"0.14597702166626284\", \"0.8111140286984647\"], \"textposition\": \"outside\", \"texttemplate\": \"%{text:.2f}\", \"type\": \"bar\", \"x\": [0.042908949635272454, 0.14597702166626284, 0.8111140286984647], \"y\": [\"learning_rate_init\", \"activation\", \"sovler\"]}],\n",
              "                        {\"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Hyperparameter Importances\"}, \"xaxis\": {\"title\": {\"text\": \"Importance for Objective Value\"}}, \"yaxis\": {\"title\": {\"text\": \"Hyperparameter\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('9c232a37-46a0-45ff-a51b-4b0a8fe67439');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHQgp-F1dEDx"
      },
      "source": [
        "# **Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsyC2FyZf0cS",
        "outputId": "933e061d-1069-4069-9f65-465392d73a8b"
      },
      "source": [
        "def randomforest(trial):\n",
        "  with mlflow.start_run(run_name=\"Random Forest\"):\n",
        "    n_estimators = trial.suggest_int('n_estimators', 100,1000)\n",
        "    max_depth = trial.suggest_int('max_depth', 2,32,log=True)\n",
        "    min_samples_leaf = trial.suggest_int('min_samples_leaf',1,100)\n",
        "\n",
        "    randforest = RandomForestRegressor(n_estimators=n_estimators,max_depth=max_depth,min_samples_leaf=min_samples_leaf)\n",
        "    randforest.fit(X_train, y_train)\n",
        "\n",
        "    y_pred_val = randforest.predict(X_val)\n",
        "\n",
        "    (mse, mae, r2) = eval_metrics(y_val, y_pred_val)\n",
        "    \n",
        "    mlflow.log_param(\"n_estimators\", n_estimators)\n",
        "    mlflow.log_param(\"max_depth\", max_depth)\n",
        "    mlflow.log_param(\"min_samples_leaf\", min_samples_leaf)\n",
        "\n",
        "    mlflow.log_metric(\"mse\", mse)\n",
        "    mlflow.log_metric(\"mae\", mae)\n",
        "    mlflow.log_metric(\"r2\", r2)\n",
        "    #mlflow.log_metric(\"nomemetrica\", nomevariavel)\n",
        "    #mlflow.log_metric(\"nomemetrica\", nomevariavel)\n",
        "\n",
        "    return mean_squared_error(y_val, y_pred_val)\n",
        "\n",
        "study_randomforest = optuna.create_study(direction='minimize')\n",
        "study_randomforest.optimize(randomforest,n_trials=200)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-08-16 01:58:07,104]\u001b[0m A new study created in memory with name: no-name-209b4c0d-970f-4a18-9079-a1e1f175d65a\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:58:19,201]\u001b[0m Trial 0 finished with value: 0.006686115212433441 and parameters: {'n_estimators': 886, 'max_depth': 2, 'min_samples_leaf': 47}. Best is trial 0 with value: 0.006686115212433441.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:58:44,810]\u001b[0m Trial 1 finished with value: 0.004284528263991583 and parameters: {'n_estimators': 722, 'max_depth': 7, 'min_samples_leaf': 62}. Best is trial 1 with value: 0.004284528263991583.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:59:23,488]\u001b[0m Trial 2 finished with value: 0.003292875491732628 and parameters: {'n_estimators': 688, 'max_depth': 25, 'min_samples_leaf': 10}. Best is trial 2 with value: 0.003292875491732628.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:59:33,220]\u001b[0m Trial 3 finished with value: 0.0067021287008553945 and parameters: {'n_estimators': 724, 'max_depth': 2, 'min_samples_leaf': 41}. Best is trial 2 with value: 0.003292875491732628.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:59:41,287]\u001b[0m Trial 4 finished with value: 0.006686741279354286 and parameters: {'n_estimators': 605, 'max_depth': 2, 'min_samples_leaf': 95}. Best is trial 2 with value: 0.003292875491732628.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:59:49,615]\u001b[0m Trial 5 finished with value: 0.005126323929194952 and parameters: {'n_estimators': 342, 'max_depth': 4, 'min_samples_leaf': 44}. Best is trial 2 with value: 0.003292875491732628.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 01:59:56,598]\u001b[0m Trial 6 finished with value: 0.006042540552445352 and parameters: {'n_estimators': 366, 'max_depth': 3, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.003292875491732628.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:00:03,466]\u001b[0m Trial 7 finished with value: 0.004471201690238087 and parameters: {'n_estimators': 209, 'max_depth': 6, 'min_samples_leaf': 67}. Best is trial 2 with value: 0.003292875491732628.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:00:05,222]\u001b[0m Trial 8 finished with value: 0.006700589732082932 and parameters: {'n_estimators': 127, 'max_depth': 2, 'min_samples_leaf': 92}. Best is trial 2 with value: 0.003292875491732628.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:00:08,834]\u001b[0m Trial 9 finished with value: 0.006047995141010899 and parameters: {'n_estimators': 189, 'max_depth': 3, 'min_samples_leaf': 82}. Best is trial 2 with value: 0.003292875491732628.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:01:12,134]\u001b[0m Trial 10 finished with value: 0.003137337435782936 and parameters: {'n_estimators': 992, 'max_depth': 32, 'min_samples_leaf': 5}. Best is trial 10 with value: 0.003137337435782936.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:02:24,470]\u001b[0m Trial 11 finished with value: 0.0030424698407405457 and parameters: {'n_estimators': 951, 'max_depth': 31, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.0030424698407405457.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:03:12,076]\u001b[0m Trial 12 finished with value: 0.0035859452687375475 and parameters: {'n_estimators': 992, 'max_depth': 32, 'min_samples_leaf': 22}. Best is trial 11 with value: 0.0030424698407405457.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:04:02,116]\u001b[0m Trial 13 finished with value: 0.003469623766601053 and parameters: {'n_estimators': 993, 'max_depth': 17, 'min_samples_leaf': 17}. Best is trial 11 with value: 0.0030424698407405457.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:04:42,689]\u001b[0m Trial 14 finished with value: 0.003640767125366985 and parameters: {'n_estimators': 869, 'max_depth': 15, 'min_samples_leaf': 25}. Best is trial 11 with value: 0.0030424698407405457.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:05:20,601]\u001b[0m Trial 15 finished with value: 0.003737988396616332 and parameters: {'n_estimators': 845, 'max_depth': 13, 'min_samples_leaf': 30}. Best is trial 11 with value: 0.0030424698407405457.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:05:54,185]\u001b[0m Trial 16 finished with value: 0.0031113418465177215 and parameters: {'n_estimators': 503, 'max_depth': 24, 'min_samples_leaf': 4}. Best is trial 11 with value: 0.0030424698407405457.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:06:12,217]\u001b[0m Trial 17 finished with value: 0.0038598455577899455 and parameters: {'n_estimators': 422, 'max_depth': 10, 'min_samples_leaf': 36}. Best is trial 11 with value: 0.0030424698407405457.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:06:40,312]\u001b[0m Trial 18 finished with value: 0.0033596546099947952 and parameters: {'n_estimators': 525, 'max_depth': 19, 'min_samples_leaf': 13}. Best is trial 11 with value: 0.0030424698407405457.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:07:00,303]\u001b[0m Trial 19 finished with value: 0.0041712487576662785 and parameters: {'n_estimators': 520, 'max_depth': 21, 'min_samples_leaf': 61}. Best is trial 11 with value: 0.0030424698407405457.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:07:34,269]\u001b[0m Trial 20 finished with value: 0.003361307393468085 and parameters: {'n_estimators': 630, 'max_depth': 10, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.0030424698407405457.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:08:19,217]\u001b[0m Trial 21 finished with value: 0.003290255590852956 and parameters: {'n_estimators': 801, 'max_depth': 32, 'min_samples_leaf': 10}. Best is trial 11 with value: 0.0030424698407405457.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:09:26,144]\u001b[0m Trial 22 finished with value: 0.0030668141943149575 and parameters: {'n_estimators': 952, 'max_depth': 25, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.0030424698407405457.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:10:10,881]\u001b[0m Trial 23 finished with value: 0.0035107374308580783 and parameters: {'n_estimators': 907, 'max_depth': 23, 'min_samples_leaf': 19}. Best is trial 11 with value: 0.0030424698407405457.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:10:31,937]\u001b[0m Trial 24 finished with value: 0.0037319203192948368 and parameters: {'n_estimators': 468, 'max_depth': 12, 'min_samples_leaf': 30}. Best is trial 11 with value: 0.0030424698407405457.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:11:20,783]\u001b[0m Trial 25 finished with value: 0.0031724661768049757 and parameters: {'n_estimators': 790, 'max_depth': 24, 'min_samples_leaf': 6}. Best is trial 11 with value: 0.0030424698407405457.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:11:37,245]\u001b[0m Trial 26 finished with value: 0.0034282776999508603 and parameters: {'n_estimators': 316, 'max_depth': 26, 'min_samples_leaf': 15}. Best is trial 11 with value: 0.0030424698407405457.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:12:04,078]\u001b[0m Trial 27 finished with value: 0.0037190834164093313 and parameters: {'n_estimators': 590, 'max_depth': 17, 'min_samples_leaf': 29}. Best is trial 11 with value: 0.0030424698407405457.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:12:37,199]\u001b[0m Trial 28 finished with value: 0.004224028247577741 and parameters: {'n_estimators': 916, 'max_depth': 7, 'min_samples_leaf': 53}. Best is trial 11 with value: 0.0030424698407405457.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:13:10,454]\u001b[0m Trial 29 finished with value: 0.0034883705613773194 and parameters: {'n_estimators': 673, 'max_depth': 9, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.0030424698407405457.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:13:53,644]\u001b[0m Trial 30 finished with value: 0.003353384199323047 and parameters: {'n_estimators': 803, 'max_depth': 14, 'min_samples_leaf': 12}. Best is trial 11 with value: 0.0030424698407405457.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:14:50,410]\u001b[0m Trial 31 finished with value: 0.0032086120588555233 and parameters: {'n_estimators': 945, 'max_depth': 32, 'min_samples_leaf': 7}. Best is trial 11 with value: 0.0030424698407405457.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:16:15,239]\u001b[0m Trial 32 finished with value: 0.003042161962403377 and parameters: {'n_estimators': 983, 'max_depth': 28, 'min_samples_leaf': 1}. Best is trial 32 with value: 0.003042161962403377.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:17:00,945]\u001b[0m Trial 33 finished with value: 0.0035408687610625324 and parameters: {'n_estimators': 936, 'max_depth': 26, 'min_samples_leaf': 20}. Best is trial 32 with value: 0.003042161962403377.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:18:03,955]\u001b[0m Trial 34 finished with value: 0.003038554813559496 and parameters: {'n_estimators': 743, 'max_depth': 21, 'min_samples_leaf': 1}. Best is trial 34 with value: 0.003038554813559496.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:18:43,847]\u001b[0m Trial 35 finished with value: 0.003310443768589637 and parameters: {'n_estimators': 726, 'max_depth': 20, 'min_samples_leaf': 11}. Best is trial 34 with value: 0.003038554813559496.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:19:56,631]\u001b[0m Trial 36 finished with value: 0.0030587315915855465 and parameters: {'n_estimators': 847, 'max_depth': 27, 'min_samples_leaf': 1}. Best is trial 34 with value: 0.003038554813559496.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:20:33,014]\u001b[0m Trial 37 finished with value: 0.0038496117860201237 and parameters: {'n_estimators': 850, 'max_depth': 17, 'min_samples_leaf': 37}. Best is trial 34 with value: 0.003038554813559496.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:21:11,306]\u001b[0m Trial 38 finished with value: 0.003427764666315125 and parameters: {'n_estimators': 742, 'max_depth': 28, 'min_samples_leaf': 15}. Best is trial 34 with value: 0.003038554813559496.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:21:55,301]\u001b[0m Trial 39 finished with value: 0.00325893062858381 and parameters: {'n_estimators': 772, 'max_depth': 20, 'min_samples_leaf': 9}. Best is trial 34 with value: 0.003038554813559496.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:22:24,478]\u001b[0m Trial 40 finished with value: 0.004368057023763377 and parameters: {'n_estimators': 880, 'max_depth': 6, 'min_samples_leaf': 49}. Best is trial 34 with value: 0.003038554813559496.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:23:46,042]\u001b[0m Trial 41 finished with value: 0.003057387983887244 and parameters: {'n_estimators': 948, 'max_depth': 27, 'min_samples_leaf': 1}. Best is trial 34 with value: 0.003038554813559496.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:24:49,102]\u001b[0m Trial 42 finished with value: 0.003056185162995904 and parameters: {'n_estimators': 834, 'max_depth': 28, 'min_samples_leaf': 2}. Best is trial 34 with value: 0.003038554813559496.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:25:45,052]\u001b[0m Trial 43 finished with value: 0.0032326450666105844 and parameters: {'n_estimators': 959, 'max_depth': 21, 'min_samples_leaf': 8}. Best is trial 34 with value: 0.003038554813559496.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:26:17,450]\u001b[0m Trial 44 finished with value: 0.004365878599074314 and parameters: {'n_estimators': 913, 'max_depth': 29, 'min_samples_leaf': 83}. Best is trial 34 with value: 0.003038554813559496.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:26:56,593]\u001b[0m Trial 45 finished with value: 0.0036289735762696463 and parameters: {'n_estimators': 833, 'max_depth': 17, 'min_samples_leaf': 24}. Best is trial 34 with value: 0.003038554813559496.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:27:54,010]\u001b[0m Trial 46 finished with value: 0.0030518351342642296 and parameters: {'n_estimators': 672, 'max_depth': 22, 'min_samples_leaf': 1}. Best is trial 34 with value: 0.003038554813559496.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:28:27,818]\u001b[0m Trial 47 finished with value: 0.003466474440633999 and parameters: {'n_estimators': 668, 'max_depth': 23, 'min_samples_leaf': 17}. Best is trial 34 with value: 0.003038554813559496.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:28:46,362]\u001b[0m Trial 48 finished with value: 0.0051050903665554965 and parameters: {'n_estimators': 762, 'max_depth': 4, 'min_samples_leaf': 8}. Best is trial 34 with value: 0.003038554813559496.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:29:29,347]\u001b[0m Trial 49 finished with value: 0.0031792010595777806 and parameters: {'n_estimators': 707, 'max_depth': 15, 'min_samples_leaf': 6}. Best is trial 34 with value: 0.003038554813559496.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:30:03,327]\u001b[0m Trial 50 finished with value: 0.0033774449724413933 and parameters: {'n_estimators': 636, 'max_depth': 19, 'min_samples_leaf': 13}. Best is trial 34 with value: 0.003038554813559496.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:31:28,852]\u001b[0m Trial 51 finished with value: 0.003035623078330721 and parameters: {'n_estimators': 989, 'max_depth': 29, 'min_samples_leaf': 1}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:32:30,111]\u001b[0m Trial 52 finished with value: 0.0031716782930152313 and parameters: {'n_estimators': 989, 'max_depth': 30, 'min_samples_leaf': 6}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:33:26,263]\u001b[0m Trial 53 finished with value: 0.003132834778756104 and parameters: {'n_estimators': 879, 'max_depth': 23, 'min_samples_leaf': 5}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:34:16,093]\u001b[0m Trial 54 finished with value: 0.003063794326888293 and parameters: {'n_estimators': 575, 'max_depth': 29, 'min_samples_leaf': 1}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:35:02,154]\u001b[0m Trial 55 finished with value: 0.0032819868630957123 and parameters: {'n_estimators': 820, 'max_depth': 22, 'min_samples_leaf': 10}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:35:38,177]\u001b[0m Trial 56 finished with value: 0.004250054107055727 and parameters: {'n_estimators': 969, 'max_depth': 18, 'min_samples_leaf': 69}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:36:24,140]\u001b[0m Trial 57 finished with value: 0.0034459470098077163 and parameters: {'n_estimators': 900, 'max_depth': 29, 'min_samples_leaf': 16}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:36:57,795]\u001b[0m Trial 58 finished with value: 0.0035694895406915995 and parameters: {'n_estimators': 701, 'max_depth': 12, 'min_samples_leaf': 21}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:38:00,932]\u001b[0m Trial 59 finished with value: 0.0031311160258558363 and parameters: {'n_estimators': 989, 'max_depth': 32, 'min_samples_leaf': 5}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:38:48,008]\u001b[0m Trial 60 finished with value: 0.003342960619425248 and parameters: {'n_estimators': 870, 'max_depth': 25, 'min_samples_leaf': 12}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:40:07,961]\u001b[0m Trial 61 finished with value: 0.0030490870542123206 and parameters: {'n_estimators': 926, 'max_depth': 27, 'min_samples_leaf': 1}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:41:25,818]\u001b[0m Trial 62 finished with value: 0.0030499337676775104 and parameters: {'n_estimators': 913, 'max_depth': 22, 'min_samples_leaf': 1}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:41:57,183]\u001b[0m Trial 63 finished with value: 0.004479122057407838 and parameters: {'n_estimators': 924, 'max_depth': 22, 'min_samples_leaf': 100}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:43:01,316]\u001b[0m Trial 64 finished with value: 0.0031232284749369305 and parameters: {'n_estimators': 995, 'max_depth': 15, 'min_samples_leaf': 4}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:43:52,683]\u001b[0m Trial 65 finished with value: 0.003264556213763498 and parameters: {'n_estimators': 897, 'max_depth': 25, 'min_samples_leaf': 9}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:45:10,602]\u001b[0m Trial 66 finished with value: 0.0030579376653623266 and parameters: {'n_estimators': 923, 'max_depth': 20, 'min_samples_leaf': 1}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:45:53,380]\u001b[0m Trial 67 finished with value: 0.003655088242479751 and parameters: {'n_estimators': 965, 'max_depth': 8, 'min_samples_leaf': 5}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:46:44,031]\u001b[0m Trial 68 finished with value: 0.003389250094702395 and parameters: {'n_estimators': 965, 'max_depth': 24, 'min_samples_leaf': 14}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:47:19,822]\u001b[0m Trial 69 finished with value: 0.003671586199019296 and parameters: {'n_estimators': 780, 'max_depth': 18, 'min_samples_leaf': 27}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:48:15,955]\u001b[0m Trial 70 finished with value: 0.0032831611527317757 and parameters: {'n_estimators': 1000, 'max_depth': 31, 'min_samples_leaf': 10}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:49:13,537]\u001b[0m Trial 71 finished with value: 0.003080989124562916 and parameters: {'n_estimators': 818, 'max_depth': 27, 'min_samples_leaf': 3}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:50:27,992]\u001b[0m Trial 72 finished with value: 0.0030440491975784086 and parameters: {'n_estimators': 859, 'max_depth': 27, 'min_samples_leaf': 1}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:51:20,071]\u001b[0m Trial 73 finished with value: 0.0031947003549624895 and parameters: {'n_estimators': 865, 'max_depth': 22, 'min_samples_leaf': 7}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:52:23,167]\u001b[0m Trial 74 finished with value: 0.0031009304196166288 and parameters: {'n_estimators': 941, 'max_depth': 25, 'min_samples_leaf': 4}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:53:27,917]\u001b[0m Trial 75 finished with value: 0.0030527723775677688 and parameters: {'n_estimators': 751, 'max_depth': 32, 'min_samples_leaf': 1}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:54:12,628]\u001b[0m Trial 76 finished with value: 0.0034937253614362412 and parameters: {'n_estimators': 896, 'max_depth': 27, 'min_samples_leaf': 18}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:54:50,147]\u001b[0m Trial 77 finished with value: 0.003230046839181685 and parameters: {'n_estimators': 638, 'max_depth': 21, 'min_samples_leaf': 8}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:55:27,037]\u001b[0m Trial 78 finished with value: 0.004085687647787657 and parameters: {'n_estimators': 933, 'max_depth': 16, 'min_samples_leaf': 54}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:56:13,513]\u001b[0m Trial 79 finished with value: 0.0033447497927490914 and parameters: {'n_estimators': 857, 'max_depth': 30, 'min_samples_leaf': 12}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:56:20,705]\u001b[0m Trial 80 finished with value: 0.004650460865266002 and parameters: {'n_estimators': 239, 'max_depth': 5, 'min_samples_leaf': 4}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:57:25,491]\u001b[0m Trial 81 finished with value: 0.0030358297032356484 and parameters: {'n_estimators': 749, 'max_depth': 30, 'min_samples_leaf': 1}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:58:28,269]\u001b[0m Trial 82 finished with value: 0.003050512800868242 and parameters: {'n_estimators': 727, 'max_depth': 26, 'min_samples_leaf': 1}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 02:59:26,371]\u001b[0m Trial 83 finished with value: 0.0032014070255577116 and parameters: {'n_estimators': 966, 'max_depth': 26, 'min_samples_leaf': 7}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:00:15,397]\u001b[0m Trial 84 finished with value: 0.003108687838054023 and parameters: {'n_estimators': 736, 'max_depth': 29, 'min_samples_leaf': 4}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:00:49,014]\u001b[0m Trial 85 finished with value: 0.003951282348364045 and parameters: {'n_estimators': 812, 'max_depth': 24, 'min_samples_leaf': 43}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:01:33,417]\u001b[0m Trial 86 finished with value: 0.0032853923524122797 and parameters: {'n_estimators': 792, 'max_depth': 27, 'min_samples_leaf': 10}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:02:35,242]\u001b[0m Trial 87 finished with value: 0.0030746172987158736 and parameters: {'n_estimators': 886, 'max_depth': 19, 'min_samples_leaf': 3}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:02:54,574]\u001b[0m Trial 88 finished with value: 0.0038150481606825217 and parameters: {'n_estimators': 444, 'max_depth': 29, 'min_samples_leaf': 35}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:03:51,635]\u001b[0m Trial 89 finished with value: 0.003175693379555894 and parameters: {'n_estimators': 924, 'max_depth': 23, 'min_samples_leaf': 6}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:04:42,907]\u001b[0m Trial 90 finished with value: 0.0033919885488563426 and parameters: {'n_estimators': 976, 'max_depth': 32, 'min_samples_leaf': 14}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:05:33,534]\u001b[0m Trial 91 finished with value: 0.0030366114328592856 and parameters: {'n_estimators': 672, 'max_depth': 21, 'min_samples_leaf': 2}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:06:35,102]\u001b[0m Trial 92 finished with value: 0.0030712905044305325 and parameters: {'n_estimators': 710, 'max_depth': 26, 'min_samples_leaf': 1}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:06:48,101]\u001b[0m Trial 93 finished with value: 0.006050982718085376 and parameters: {'n_estimators': 690, 'max_depth': 3, 'min_samples_leaf': 8}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:07:34,632]\u001b[0m Trial 94 finished with value: 0.003168339113585927 and parameters: {'n_estimators': 753, 'max_depth': 21, 'min_samples_leaf': 6}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:08:20,453]\u001b[0m Trial 95 finished with value: 0.0030610071129549502 and parameters: {'n_estimators': 656, 'max_depth': 19, 'min_samples_leaf': 3}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:09:02,385]\u001b[0m Trial 96 finished with value: 0.00307797096575107 and parameters: {'n_estimators': 597, 'max_depth': 24, 'min_samples_leaf': 3}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:09:51,660]\u001b[0m Trial 97 finished with value: 0.0030545286940484367 and parameters: {'n_estimators': 569, 'max_depth': 30, 'min_samples_leaf': 1}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:10:42,893]\u001b[0m Trial 98 finished with value: 0.003338205562423805 and parameters: {'n_estimators': 944, 'max_depth': 13, 'min_samples_leaf': 11}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:11:19,255]\u001b[0m Trial 99 finished with value: 0.003235925133898641 and parameters: {'n_estimators': 620, 'max_depth': 28, 'min_samples_leaf': 8}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:11:45,640]\u001b[0m Trial 100 finished with value: 0.004279793051407756 and parameters: {'n_estimators': 716, 'max_depth': 25, 'min_samples_leaf': 72}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:12:29,209]\u001b[0m Trial 101 finished with value: 0.0031341227290968793 and parameters: {'n_estimators': 681, 'max_depth': 22, 'min_samples_leaf': 5}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:13:35,082]\u001b[0m Trial 102 finished with value: 0.0030392990299807033 and parameters: {'n_estimators': 768, 'max_depth': 23, 'min_samples_leaf': 1}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:14:28,506]\u001b[0m Trial 103 finished with value: 0.0030849423851650876 and parameters: {'n_estimators': 762, 'max_depth': 20, 'min_samples_leaf': 3}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:15:40,246]\u001b[0m Trial 104 finished with value: 0.0030621481796944405 and parameters: {'n_estimators': 835, 'max_depth': 23, 'min_samples_leaf': 1}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:16:24,042]\u001b[0m Trial 105 finished with value: 0.0032064347527757933 and parameters: {'n_estimators': 727, 'max_depth': 28, 'min_samples_leaf': 7}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:17:13,597]\u001b[0m Trial 106 finished with value: 0.003138225419343814 and parameters: {'n_estimators': 778, 'max_depth': 18, 'min_samples_leaf': 5}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:18:05,832]\u001b[0m Trial 107 finished with value: 0.003268970658305879 and parameters: {'n_estimators': 912, 'max_depth': 31, 'min_samples_leaf': 9}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:19:12,318]\u001b[0m Trial 108 finished with value: 0.003089989295175367 and parameters: {'n_estimators': 975, 'max_depth': 16, 'min_samples_leaf': 3}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:19:56,698]\u001b[0m Trial 109 finished with value: 0.003314590035760019 and parameters: {'n_estimators': 805, 'max_depth': 26, 'min_samples_leaf': 11}. Best is trial 51 with value: 0.003035623078330721.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:21:18,763]\u001b[0m Trial 110 finished with value: 0.0030351300093353116 and parameters: {'n_estimators': 948, 'max_depth': 30, 'min_samples_leaf': 1}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:22:41,053]\u001b[0m Trial 111 finished with value: 0.0030418422735848196 and parameters: {'n_estimators': 952, 'max_depth': 30, 'min_samples_leaf': 1}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:23:41,775]\u001b[0m Trial 112 finished with value: 0.0031421510412098282 and parameters: {'n_estimators': 949, 'max_depth': 30, 'min_samples_leaf': 5}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:24:45,456]\u001b[0m Trial 113 finished with value: 0.003077556027756016 and parameters: {'n_estimators': 904, 'max_depth': 28, 'min_samples_leaf': 3}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:25:41,762]\u001b[0m Trial 114 finished with value: 0.0032048380811785177 and parameters: {'n_estimators': 936, 'max_depth': 32, 'min_samples_leaf': 7}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:27:06,079]\u001b[0m Trial 115 finished with value: 0.0030424265838345896 and parameters: {'n_estimators': 980, 'max_depth': 24, 'min_samples_leaf': 1}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:28:16,074]\u001b[0m Trial 116 finished with value: 0.003069622384262403 and parameters: {'n_estimators': 994, 'max_depth': 24, 'min_samples_leaf': 3}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:29:16,625]\u001b[0m Trial 117 finished with value: 0.0031763494071959334 and parameters: {'n_estimators': 978, 'max_depth': 30, 'min_samples_leaf': 6}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:30:11,103]\u001b[0m Trial 118 finished with value: 0.003260662663878276 and parameters: {'n_estimators': 952, 'max_depth': 27, 'min_samples_leaf': 9}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:31:07,341]\u001b[0m Trial 119 finished with value: 0.0031394004124947286 and parameters: {'n_estimators': 879, 'max_depth': 25, 'min_samples_leaf': 5}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:31:58,350]\u001b[0m Trial 120 finished with value: 0.0033694019795612725 and parameters: {'n_estimators': 958, 'max_depth': 28, 'min_samples_leaf': 13}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:33:16,340]\u001b[0m Trial 121 finished with value: 0.0030442920721150163 and parameters: {'n_estimators': 919, 'max_depth': 21, 'min_samples_leaf': 1}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:34:30,155]\u001b[0m Trial 122 finished with value: 0.003045915092206465 and parameters: {'n_estimators': 978, 'max_depth': 21, 'min_samples_leaf': 2}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:35:53,522]\u001b[0m Trial 123 finished with value: 0.003040945942693145 and parameters: {'n_estimators': 980, 'max_depth': 21, 'min_samples_leaf': 1}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:37:00,136]\u001b[0m Trial 124 finished with value: 0.003090394395720189 and parameters: {'n_estimators': 996, 'max_depth': 23, 'min_samples_leaf': 4}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:38:20,526]\u001b[0m Trial 125 finished with value: 0.0030476991933826377 and parameters: {'n_estimators': 959, 'max_depth': 19, 'min_samples_leaf': 1}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:39:17,058]\u001b[0m Trial 126 finished with value: 0.003222884054970443 and parameters: {'n_estimators': 933, 'max_depth': 20, 'min_samples_leaf': 7}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:40:22,620]\u001b[0m Trial 127 finished with value: 0.0031076501384619403 and parameters: {'n_estimators': 982, 'max_depth': 30, 'min_samples_leaf': 4}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:41:39,391]\u001b[0m Trial 128 finished with value: 0.0030486537284161275 and parameters: {'n_estimators': 892, 'max_depth': 24, 'min_samples_leaf': 1}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:42:09,341]\u001b[0m Trial 129 finished with value: 0.004406049233048117 and parameters: {'n_estimators': 854, 'max_depth': 11, 'min_samples_leaf': 88}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:43:11,067]\u001b[0m Trial 130 finished with value: 0.0031739158788561123 and parameters: {'n_estimators': 1000, 'max_depth': 18, 'min_samples_leaf': 6}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:44:34,009]\u001b[0m Trial 131 finished with value: 0.003050543210819241 and parameters: {'n_estimators': 976, 'max_depth': 21, 'min_samples_leaf': 1}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:45:37,298]\u001b[0m Trial 132 finished with value: 0.0031003596311745987 and parameters: {'n_estimators': 947, 'max_depth': 21, 'min_samples_leaf': 4}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:46:42,045]\u001b[0m Trial 133 finished with value: 0.0030747096037961478 and parameters: {'n_estimators': 919, 'max_depth': 26, 'min_samples_leaf': 3}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:47:49,860]\u001b[0m Trial 134 finished with value: 0.003070905569829401 and parameters: {'n_estimators': 966, 'max_depth': 23, 'min_samples_leaf': 3}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:48:44,938]\u001b[0m Trial 135 finished with value: 0.003289447513282577 and parameters: {'n_estimators': 981, 'max_depth': 32, 'min_samples_leaf': 10}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:49:07,210]\u001b[0m Trial 136 finished with value: 0.0032356211691038743 and parameters: {'n_estimators': 379, 'max_depth': 25, 'min_samples_leaf': 8}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:49:42,952]\u001b[0m Trial 137 finished with value: 0.0041735805659026595 and parameters: {'n_estimators': 935, 'max_depth': 16, 'min_samples_leaf': 62}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:51:01,652]\u001b[0m Trial 138 finished with value: 0.0030438037982954374 and parameters: {'n_estimators': 909, 'max_depth': 29, 'min_samples_leaf': 1}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:51:55,314]\u001b[0m Trial 139 finished with value: 0.0031614741038706556 and parameters: {'n_estimators': 866, 'max_depth': 29, 'min_samples_leaf': 6}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:53:13,539]\u001b[0m Trial 140 finished with value: 0.00303762747963763 and parameters: {'n_estimators': 903, 'max_depth': 28, 'min_samples_leaf': 1}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:54:31,992]\u001b[0m Trial 141 finished with value: 0.0030454817043842233 and parameters: {'n_estimators': 905, 'max_depth': 28, 'min_samples_leaf': 1}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:55:34,588]\u001b[0m Trial 142 finished with value: 0.0030743915691001794 and parameters: {'n_estimators': 885, 'max_depth': 26, 'min_samples_leaf': 3}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:56:28,099]\u001b[0m Trial 143 finished with value: 0.0031321042144613707 and parameters: {'n_estimators': 837, 'max_depth': 30, 'min_samples_leaf': 5}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:57:33,089]\u001b[0m Trial 144 finished with value: 0.0030706608869907233 and parameters: {'n_estimators': 923, 'max_depth': 28, 'min_samples_leaf': 3}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:58:56,023]\u001b[0m Trial 145 finished with value: 0.003038835958410224 and parameters: {'n_estimators': 959, 'max_depth': 32, 'min_samples_leaf': 1}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 03:59:32,687]\u001b[0m Trial 146 finished with value: 0.004146410685848724 and parameters: {'n_estimators': 949, 'max_depth': 31, 'min_samples_leaf': 59}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:00:34,215]\u001b[0m Trial 147 finished with value: 0.003135770785647889 and parameters: {'n_estimators': 961, 'max_depth': 32, 'min_samples_leaf': 5}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:01:21,967]\u001b[0m Trial 148 finished with value: 0.0032076555542660465 and parameters: {'n_estimators': 791, 'max_depth': 29, 'min_samples_leaf': 7}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:02:43,622]\u001b[0m Trial 149 finished with value: 0.003040533665261347 and parameters: {'n_estimators': 944, 'max_depth': 27, 'min_samples_leaf': 1}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:03:38,014]\u001b[0m Trial 150 finished with value: 0.003258503417109769 and parameters: {'n_estimators': 949, 'max_depth': 24, 'min_samples_leaf': 9}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:04:21,977]\u001b[0m Trial 151 finished with value: 0.003056979311483249 and parameters: {'n_estimators': 509, 'max_depth': 27, 'min_samples_leaf': 1}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:04:31,075]\u001b[0m Trial 152 finished with value: 0.003082588376860224 and parameters: {'n_estimators': 128, 'max_depth': 30, 'min_samples_leaf': 3}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:05:48,860]\u001b[0m Trial 153 finished with value: 0.0030499495854322467 and parameters: {'n_estimators': 900, 'max_depth': 26, 'min_samples_leaf': 1}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:06:50,762]\u001b[0m Trial 154 finished with value: 0.0031377451775924645 and parameters: {'n_estimators': 967, 'max_depth': 32, 'min_samples_leaf': 5}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:07:42,967]\u001b[0m Trial 155 finished with value: 0.0030742264648109625 and parameters: {'n_estimators': 741, 'max_depth': 27, 'min_samples_leaf': 3}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:09:04,880]\u001b[0m Trial 156 finished with value: 0.003048401466625845 and parameters: {'n_estimators': 942, 'max_depth': 29, 'min_samples_leaf': 1}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:10:08,696]\u001b[0m Trial 157 finished with value: 0.0031448666237528108 and parameters: {'n_estimators': 998, 'max_depth': 25, 'min_samples_leaf': 5}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:11:04,624]\u001b[0m Trial 158 finished with value: 0.0031976109652836126 and parameters: {'n_estimators': 930, 'max_depth': 28, 'min_samples_leaf': 7}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:11:53,628]\u001b[0m Trial 159 finished with value: 0.003079587791959947 and parameters: {'n_estimators': 695, 'max_depth': 23, 'min_samples_leaf': 3}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:13:12,449]\u001b[0m Trial 160 finished with value: 0.003048051809737823 and parameters: {'n_estimators': 910, 'max_depth': 30, 'min_samples_leaf': 1}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:14:31,799]\u001b[0m Trial 161 finished with value: 0.003050169432101656 and parameters: {'n_estimators': 920, 'max_depth': 26, 'min_samples_leaf': 1}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:15:36,097]\u001b[0m Trial 162 finished with value: 0.003106481577059623 and parameters: {'n_estimators': 958, 'max_depth': 32, 'min_samples_leaf': 4}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:16:37,440]\u001b[0m Trial 163 finished with value: 0.0030708744823299103 and parameters: {'n_estimators': 873, 'max_depth': 22, 'min_samples_leaf': 3}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:18:01,776]\u001b[0m Trial 164 finished with value: 0.0030587863363752943 and parameters: {'n_estimators': 978, 'max_depth': 24, 'min_samples_leaf': 1}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:18:42,069]\u001b[0m Trial 165 finished with value: 0.003164795711001836 and parameters: {'n_estimators': 650, 'max_depth': 27, 'min_samples_leaf': 6}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:19:48,108]\u001b[0m Trial 166 finished with value: 0.0030695933558443074 and parameters: {'n_estimators': 937, 'max_depth': 29, 'min_samples_leaf': 3}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:20:45,757]\u001b[0m Trial 167 finished with value: 0.0031445989996681505 and parameters: {'n_estimators': 898, 'max_depth': 25, 'min_samples_leaf': 5}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:21:43,480]\u001b[0m Trial 168 finished with value: 0.003235678300444546 and parameters: {'n_estimators': 981, 'max_depth': 20, 'min_samples_leaf': 8}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:22:50,028]\u001b[0m Trial 169 finished with value: 0.003051396008709355 and parameters: {'n_estimators': 772, 'max_depth': 22, 'min_samples_leaf': 1}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:23:13,645]\u001b[0m Trial 170 finished with value: 0.005114584722880311 and parameters: {'n_estimators': 963, 'max_depth': 4, 'min_samples_leaf': 3}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:24:22,676]\u001b[0m Trial 171 finished with value: 0.003042591844779555 and parameters: {'n_estimators': 907, 'max_depth': 28, 'min_samples_leaf': 2}. Best is trial 110 with value: 0.0030351300093353116.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:25:42,036]\u001b[0m Trial 172 finished with value: 0.0030347432002446263 and parameters: {'n_estimators': 915, 'max_depth': 30, 'min_samples_leaf': 1}. Best is trial 172 with value: 0.0030347432002446263.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:26:14,165]\u001b[0m Trial 173 finished with value: 0.004314028262632723 and parameters: {'n_estimators': 883, 'max_depth': 30, 'min_samples_leaf': 76}. Best is trial 172 with value: 0.0030347432002446263.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:26:49,300]\u001b[0m Trial 174 finished with value: 0.0031393186209165824 and parameters: {'n_estimators': 549, 'max_depth': 28, 'min_samples_leaf': 5}. Best is trial 172 with value: 0.0030347432002446263.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:27:49,315]\u001b[0m Trial 175 finished with value: 0.0030682578289163882 and parameters: {'n_estimators': 852, 'max_depth': 31, 'min_samples_leaf': 3}. Best is trial 172 with value: 0.0030347432002446263.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:29:00,509]\u001b[0m Trial 176 finished with value: 0.0030499925153345602 and parameters: {'n_estimators': 821, 'max_depth': 27, 'min_samples_leaf': 1}. Best is trial 172 with value: 0.0030347432002446263.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:29:40,423]\u001b[0m Trial 177 finished with value: 0.0038801918224695875 and parameters: {'n_estimators': 939, 'max_depth': 32, 'min_samples_leaf': 39}. Best is trial 172 with value: 0.0030347432002446263.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:30:21,072]\u001b[0m Trial 178 finished with value: 0.0036625112514868563 and parameters: {'n_estimators': 922, 'max_depth': 8, 'min_samples_leaf': 7}. Best is trial 172 with value: 0.0030347432002446263.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:31:21,217]\u001b[0m Trial 179 finished with value: 0.003098830753214743 and parameters: {'n_estimators': 900, 'max_depth': 29, 'min_samples_leaf': 4}. Best is trial 172 with value: 0.0030347432002446263.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:32:22,175]\u001b[0m Trial 180 finished with value: 0.003139324592227402 and parameters: {'n_estimators': 953, 'max_depth': 25, 'min_samples_leaf': 5}. Best is trial 172 with value: 0.0030347432002446263.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:33:41,869]\u001b[0m Trial 181 finished with value: 0.0030457435754000914 and parameters: {'n_estimators': 921, 'max_depth': 28, 'min_samples_leaf': 1}. Best is trial 172 with value: 0.0030347432002446263.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:34:46,273]\u001b[0m Trial 182 finished with value: 0.0030753093897032896 and parameters: {'n_estimators': 913, 'max_depth': 30, 'min_samples_leaf': 3}. Best is trial 172 with value: 0.0030347432002446263.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:36:11,960]\u001b[0m Trial 183 finished with value: 0.00304661354174854 and parameters: {'n_estimators': 987, 'max_depth': 26, 'min_samples_leaf': 1}. Best is trial 172 with value: 0.0030347432002446263.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:37:20,036]\u001b[0m Trial 184 finished with value: 0.003063247332099009 and parameters: {'n_estimators': 966, 'max_depth': 23, 'min_samples_leaf': 3}. Best is trial 172 with value: 0.0030347432002446263.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:38:41,300]\u001b[0m Trial 185 finished with value: 0.0030550832397876087 and parameters: {'n_estimators': 940, 'max_depth': 27, 'min_samples_leaf': 1}. Best is trial 172 with value: 0.0030347432002446263.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:39:37,351]\u001b[0m Trial 186 finished with value: 0.0031404824108353844 and parameters: {'n_estimators': 876, 'max_depth': 30, 'min_samples_leaf': 5}. Best is trial 172 with value: 0.0030347432002446263.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:40:39,898]\u001b[0m Trial 187 finished with value: 0.0030665144604152964 and parameters: {'n_estimators': 890, 'max_depth': 24, 'min_samples_leaf': 3}. Best is trial 172 with value: 0.0030347432002446263.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:41:37,506]\u001b[0m Trial 188 finished with value: 0.0031730323657184136 and parameters: {'n_estimators': 932, 'max_depth': 22, 'min_samples_leaf': 6}. Best is trial 172 with value: 0.0030347432002446263.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:43:04,015]\u001b[0m Trial 189 finished with value: 0.0030549686764350472 and parameters: {'n_estimators': 1000, 'max_depth': 32, 'min_samples_leaf': 1}. Best is trial 172 with value: 0.0030347432002446263.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:44:12,570]\u001b[0m Trial 190 finished with value: 0.0030670734032654757 and parameters: {'n_estimators': 973, 'max_depth': 28, 'min_samples_leaf': 3}. Best is trial 172 with value: 0.0030347432002446263.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:45:31,293]\u001b[0m Trial 191 finished with value: 0.0030479591275277035 and parameters: {'n_estimators': 911, 'max_depth': 28, 'min_samples_leaf': 1}. Best is trial 172 with value: 0.0030347432002446263.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:46:49,153]\u001b[0m Trial 192 finished with value: 0.0030472209978435155 and parameters: {'n_estimators': 902, 'max_depth': 26, 'min_samples_leaf': 1}. Best is trial 172 with value: 0.0030347432002446263.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:47:52,793]\u001b[0m Trial 193 finished with value: 0.0031001532963630314 and parameters: {'n_estimators': 953, 'max_depth': 30, 'min_samples_leaf': 4}. Best is trial 172 with value: 0.0030347432002446263.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:48:53,566]\u001b[0m Trial 194 finished with value: 0.003065821579447761 and parameters: {'n_estimators': 863, 'max_depth': 29, 'min_samples_leaf': 3}. Best is trial 172 with value: 0.0030347432002446263.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:49:31,204]\u001b[0m Trial 195 finished with value: 0.003989506989804649 and parameters: {'n_estimators': 920, 'max_depth': 27, 'min_samples_leaf': 46}. Best is trial 172 with value: 0.0030347432002446263.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:50:28,217]\u001b[0m Trial 196 finished with value: 0.0032081397679603486 and parameters: {'n_estimators': 948, 'max_depth': 25, 'min_samples_leaf': 7}. Best is trial 172 with value: 0.0030347432002446263.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:51:53,423]\u001b[0m Trial 197 finished with value: 0.003043229198974911 and parameters: {'n_estimators': 983, 'max_depth': 32, 'min_samples_leaf': 1}. Best is trial 172 with value: 0.0030347432002446263.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:52:55,646]\u001b[0m Trial 198 finished with value: 0.0031355741781732833 and parameters: {'n_estimators': 971, 'max_depth': 32, 'min_samples_leaf': 5}. Best is trial 172 with value: 0.0030347432002446263.\u001b[0m\n",
            "\u001b[32m[I 2021-08-16 04:54:05,145]\u001b[0m Trial 199 finished with value: 0.0030652310047505327 and parameters: {'n_estimators': 987, 'max_depth': 31, 'min_samples_leaf': 3}. Best is trial 172 with value: 0.0030347432002446263.\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vi9R-kGGgx7h",
        "outputId": "567cb0f6-02d6-4dad-fffb-4fe03870499f"
      },
      "source": [
        "trial = study_randomforest.best_trial\n",
        "print(f'MSE: {trial.value}')\n",
        "print(f'Best hyperparameters: {trial.params}')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE: 0.0030347432002446263\n",
            "Best hyperparameters: {'n_estimators': 915, 'max_depth': 30, 'min_samples_leaf': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "ze-VJpGwg9Mw",
        "outputId": "8d4e0d22-dde1-43df-94cf-06b2cef1e07a"
      },
      "source": [
        "optuna.visualization.plot_optimization_history(study_randomforest)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"d2f8ba9c-ed56-4543-bd01-4622fb13b9cc\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"d2f8ba9c-ed56-4543-bd01-4622fb13b9cc\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'd2f8ba9c-ed56-4543-bd01-4622fb13b9cc',\n",
              "                        [{\"mode\": \"markers\", \"name\": \"Objective Value\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199], \"y\": [0.006686115212433441, 0.004284528263991583, 0.003292875491732628, 0.0067021287008553945, 0.006686741279354286, 0.005126323929194952, 0.006042540552445352, 0.004471201690238087, 0.006700589732082932, 0.006047995141010899, 0.003137337435782936, 0.0030424698407405457, 0.0035859452687375475, 0.003469623766601053, 0.003640767125366985, 0.003737988396616332, 0.0031113418465177215, 0.0038598455577899455, 0.0033596546099947952, 0.0041712487576662785, 0.003361307393468085, 0.003290255590852956, 0.0030668141943149575, 0.0035107374308580783, 0.0037319203192948368, 0.0031724661768049757, 0.0034282776999508603, 0.0037190834164093313, 0.004224028247577741, 0.0034883705613773194, 0.003353384199323047, 0.0032086120588555233, 0.003042161962403377, 0.0035408687610625324, 0.003038554813559496, 0.003310443768589637, 0.0030587315915855465, 0.0038496117860201237, 0.003427764666315125, 0.00325893062858381, 0.004368057023763377, 0.003057387983887244, 0.003056185162995904, 0.0032326450666105844, 0.004365878599074314, 0.0036289735762696463, 0.0030518351342642296, 0.003466474440633999, 0.0051050903665554965, 0.0031792010595777806, 0.0033774449724413933, 0.003035623078330721, 0.0031716782930152313, 0.003132834778756104, 0.003063794326888293, 0.0032819868630957123, 0.004250054107055727, 0.0034459470098077163, 0.0035694895406915995, 0.0031311160258558363, 0.003342960619425248, 0.0030490870542123206, 0.0030499337676775104, 0.004479122057407838, 0.0031232284749369305, 0.003264556213763498, 0.0030579376653623266, 0.003655088242479751, 0.003389250094702395, 0.003671586199019296, 0.0032831611527317757, 0.003080989124562916, 0.0030440491975784086, 0.0031947003549624895, 0.0031009304196166288, 0.0030527723775677688, 0.0034937253614362412, 0.003230046839181685, 0.004085687647787657, 0.0033447497927490914, 0.004650460865266002, 0.0030358297032356484, 0.003050512800868242, 0.0032014070255577116, 0.003108687838054023, 0.003951282348364045, 0.0032853923524122797, 0.0030746172987158736, 0.0038150481606825217, 0.003175693379555894, 0.0033919885488563426, 0.0030366114328592856, 0.0030712905044305325, 0.006050982718085376, 0.003168339113585927, 0.0030610071129549502, 0.00307797096575107, 0.0030545286940484367, 0.003338205562423805, 0.003235925133898641, 0.004279793051407756, 0.0031341227290968793, 0.0030392990299807033, 0.0030849423851650876, 0.0030621481796944405, 0.0032064347527757933, 0.003138225419343814, 0.003268970658305879, 0.003089989295175367, 0.003314590035760019, 0.0030351300093353116, 0.0030418422735848196, 0.0031421510412098282, 0.003077556027756016, 0.0032048380811785177, 0.0030424265838345896, 0.003069622384262403, 0.0031763494071959334, 0.003260662663878276, 0.0031394004124947286, 0.0033694019795612725, 0.0030442920721150163, 0.003045915092206465, 0.003040945942693145, 0.003090394395720189, 0.0030476991933826377, 0.003222884054970443, 0.0031076501384619403, 0.0030486537284161275, 0.004406049233048117, 0.0031739158788561123, 0.003050543210819241, 0.0031003596311745987, 0.0030747096037961478, 0.003070905569829401, 0.003289447513282577, 0.0032356211691038743, 0.0041735805659026595, 0.0030438037982954374, 0.0031614741038706556, 0.00303762747963763, 0.0030454817043842233, 0.0030743915691001794, 0.0031321042144613707, 0.0030706608869907233, 0.003038835958410224, 0.004146410685848724, 0.003135770785647889, 0.0032076555542660465, 0.003040533665261347, 0.003258503417109769, 0.003056979311483249, 0.003082588376860224, 0.0030499495854322467, 0.0031377451775924645, 0.0030742264648109625, 0.003048401466625845, 0.0031448666237528108, 0.0031976109652836126, 0.003079587791959947, 0.003048051809737823, 0.003050169432101656, 0.003106481577059623, 0.0030708744823299103, 0.0030587863363752943, 0.003164795711001836, 0.0030695933558443074, 0.0031445989996681505, 0.003235678300444546, 0.003051396008709355, 0.005114584722880311, 0.003042591844779555, 0.0030347432002446263, 0.004314028262632723, 0.0031393186209165824, 0.0030682578289163882, 0.0030499925153345602, 0.0038801918224695875, 0.0036625112514868563, 0.003098830753214743, 0.003139324592227402, 0.0030457435754000914, 0.0030753093897032896, 0.00304661354174854, 0.003063247332099009, 0.0030550832397876087, 0.0031404824108353844, 0.0030665144604152964, 0.0031730323657184136, 0.0030549686764350472, 0.0030670734032654757, 0.0030479591275277035, 0.0030472209978435155, 0.0031001532963630314, 0.003065821579447761, 0.003989506989804649, 0.0032081397679603486, 0.003043229198974911, 0.0031355741781732833, 0.0030652310047505327]}, {\"name\": \"Best Value\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199], \"y\": [0.006686115212433441, 0.004284528263991583, 0.003292875491732628, 0.003292875491732628, 0.003292875491732628, 0.003292875491732628, 0.003292875491732628, 0.003292875491732628, 0.003292875491732628, 0.003292875491732628, 0.003137337435782936, 0.0030424698407405457, 0.0030424698407405457, 0.0030424698407405457, 0.0030424698407405457, 0.0030424698407405457, 0.0030424698407405457, 0.0030424698407405457, 0.0030424698407405457, 0.0030424698407405457, 0.0030424698407405457, 0.0030424698407405457, 0.0030424698407405457, 0.0030424698407405457, 0.0030424698407405457, 0.0030424698407405457, 0.0030424698407405457, 0.0030424698407405457, 0.0030424698407405457, 0.0030424698407405457, 0.0030424698407405457, 0.0030424698407405457, 0.003042161962403377, 0.003042161962403377, 0.003038554813559496, 0.003038554813559496, 0.003038554813559496, 0.003038554813559496, 0.003038554813559496, 0.003038554813559496, 0.003038554813559496, 0.003038554813559496, 0.003038554813559496, 0.003038554813559496, 0.003038554813559496, 0.003038554813559496, 0.003038554813559496, 0.003038554813559496, 0.003038554813559496, 0.003038554813559496, 0.003038554813559496, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.003035623078330721, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030351300093353116, 0.0030347432002446263, 0.0030347432002446263, 0.0030347432002446263, 0.0030347432002446263, 0.0030347432002446263, 0.0030347432002446263, 0.0030347432002446263, 0.0030347432002446263, 0.0030347432002446263, 0.0030347432002446263, 0.0030347432002446263, 0.0030347432002446263, 0.0030347432002446263, 0.0030347432002446263, 0.0030347432002446263, 0.0030347432002446263, 0.0030347432002446263, 0.0030347432002446263, 0.0030347432002446263, 0.0030347432002446263, 0.0030347432002446263, 0.0030347432002446263, 0.0030347432002446263, 0.0030347432002446263, 0.0030347432002446263, 0.0030347432002446263, 0.0030347432002446263, 0.0030347432002446263]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Optimization History Plot\"}, \"xaxis\": {\"title\": {\"text\": \"#Trials\"}}, \"yaxis\": {\"title\": {\"text\": \"Objective Value\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d2f8ba9c-ed56-4543-bd01-4622fb13b9cc');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "tS33MYZhhBXQ",
        "outputId": "87224550-9369-4c10-eff5-b0e10d429e39"
      },
      "source": [
        "optuna.visualization.plot_slice(study_randomforest)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"d5c65141-5130-4b8b-acee-a89d26fcba73\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"d5c65141-5130-4b8b-acee-a89d26fcba73\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'd5c65141-5130-4b8b-acee-a89d26fcba73',\n",
              "                        [{\"marker\": {\"color\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199], \"colorbar\": {\"title\": {\"text\": \"#Trials\"}, \"x\": 1.0, \"xpad\": 40}, \"colorscale\": [[0.0, \"rgb(247,251,255)\"], [0.125, \"rgb(222,235,247)\"], [0.25, \"rgb(198,219,239)\"], [0.375, \"rgb(158,202,225)\"], [0.5, \"rgb(107,174,214)\"], [0.625, \"rgb(66,146,198)\"], [0.75, \"rgb(33,113,181)\"], [0.875, \"rgb(8,81,156)\"], [1.0, \"rgb(8,48,107)\"]], \"line\": {\"color\": \"Grey\", \"width\": 0.5}, \"showscale\": true}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [2, 7, 25, 2, 2, 4, 3, 6, 2, 3, 32, 31, 32, 17, 15, 13, 24, 10, 19, 21, 10, 32, 25, 23, 12, 24, 26, 17, 7, 9, 14, 32, 28, 26, 21, 20, 27, 17, 28, 20, 6, 27, 28, 21, 29, 17, 22, 23, 4, 15, 19, 29, 30, 23, 29, 22, 18, 29, 12, 32, 25, 27, 22, 22, 15, 25, 20, 8, 24, 18, 31, 27, 27, 22, 25, 32, 27, 21, 16, 30, 5, 30, 26, 26, 29, 24, 27, 19, 29, 23, 32, 21, 26, 3, 21, 19, 24, 30, 13, 28, 25, 22, 23, 20, 23, 28, 18, 31, 16, 26, 30, 30, 30, 28, 32, 24, 24, 30, 27, 25, 28, 21, 21, 21, 23, 19, 20, 30, 24, 11, 18, 21, 21, 26, 23, 32, 25, 16, 29, 29, 28, 28, 26, 30, 28, 32, 31, 32, 29, 27, 24, 27, 30, 26, 32, 27, 29, 25, 28, 23, 30, 26, 32, 22, 24, 27, 29, 25, 20, 22, 4, 28, 30, 30, 28, 31, 27, 32, 8, 29, 25, 28, 30, 26, 23, 27, 30, 24, 22, 32, 28, 28, 26, 30, 29, 27, 25, 32, 32, 31], \"xaxis\": \"x\", \"y\": [0.006686115212433441, 0.004284528263991583, 0.003292875491732628, 0.0067021287008553945, 0.006686741279354286, 0.005126323929194952, 0.006042540552445352, 0.004471201690238087, 0.006700589732082932, 0.006047995141010899, 0.003137337435782936, 0.0030424698407405457, 0.0035859452687375475, 0.003469623766601053, 0.003640767125366985, 0.003737988396616332, 0.0031113418465177215, 0.0038598455577899455, 0.0033596546099947952, 0.0041712487576662785, 0.003361307393468085, 0.003290255590852956, 0.0030668141943149575, 0.0035107374308580783, 0.0037319203192948368, 0.0031724661768049757, 0.0034282776999508603, 0.0037190834164093313, 0.004224028247577741, 0.0034883705613773194, 0.003353384199323047, 0.0032086120588555233, 0.003042161962403377, 0.0035408687610625324, 0.003038554813559496, 0.003310443768589637, 0.0030587315915855465, 0.0038496117860201237, 0.003427764666315125, 0.00325893062858381, 0.004368057023763377, 0.003057387983887244, 0.003056185162995904, 0.0032326450666105844, 0.004365878599074314, 0.0036289735762696463, 0.0030518351342642296, 0.003466474440633999, 0.0051050903665554965, 0.0031792010595777806, 0.0033774449724413933, 0.003035623078330721, 0.0031716782930152313, 0.003132834778756104, 0.003063794326888293, 0.0032819868630957123, 0.004250054107055727, 0.0034459470098077163, 0.0035694895406915995, 0.0031311160258558363, 0.003342960619425248, 0.0030490870542123206, 0.0030499337676775104, 0.004479122057407838, 0.0031232284749369305, 0.003264556213763498, 0.0030579376653623266, 0.003655088242479751, 0.003389250094702395, 0.003671586199019296, 0.0032831611527317757, 0.003080989124562916, 0.0030440491975784086, 0.0031947003549624895, 0.0031009304196166288, 0.0030527723775677688, 0.0034937253614362412, 0.003230046839181685, 0.004085687647787657, 0.0033447497927490914, 0.004650460865266002, 0.0030358297032356484, 0.003050512800868242, 0.0032014070255577116, 0.003108687838054023, 0.003951282348364045, 0.0032853923524122797, 0.0030746172987158736, 0.0038150481606825217, 0.003175693379555894, 0.0033919885488563426, 0.0030366114328592856, 0.0030712905044305325, 0.006050982718085376, 0.003168339113585927, 0.0030610071129549502, 0.00307797096575107, 0.0030545286940484367, 0.003338205562423805, 0.003235925133898641, 0.004279793051407756, 0.0031341227290968793, 0.0030392990299807033, 0.0030849423851650876, 0.0030621481796944405, 0.0032064347527757933, 0.003138225419343814, 0.003268970658305879, 0.003089989295175367, 0.003314590035760019, 0.0030351300093353116, 0.0030418422735848196, 0.0031421510412098282, 0.003077556027756016, 0.0032048380811785177, 0.0030424265838345896, 0.003069622384262403, 0.0031763494071959334, 0.003260662663878276, 0.0031394004124947286, 0.0033694019795612725, 0.0030442920721150163, 0.003045915092206465, 0.003040945942693145, 0.003090394395720189, 0.0030476991933826377, 0.003222884054970443, 0.0031076501384619403, 0.0030486537284161275, 0.004406049233048117, 0.0031739158788561123, 0.003050543210819241, 0.0031003596311745987, 0.0030747096037961478, 0.003070905569829401, 0.003289447513282577, 0.0032356211691038743, 0.0041735805659026595, 0.0030438037982954374, 0.0031614741038706556, 0.00303762747963763, 0.0030454817043842233, 0.0030743915691001794, 0.0031321042144613707, 0.0030706608869907233, 0.003038835958410224, 0.004146410685848724, 0.003135770785647889, 0.0032076555542660465, 0.003040533665261347, 0.003258503417109769, 0.003056979311483249, 0.003082588376860224, 0.0030499495854322467, 0.0031377451775924645, 0.0030742264648109625, 0.003048401466625845, 0.0031448666237528108, 0.0031976109652836126, 0.003079587791959947, 0.003048051809737823, 0.003050169432101656, 0.003106481577059623, 0.0030708744823299103, 0.0030587863363752943, 0.003164795711001836, 0.0030695933558443074, 0.0031445989996681505, 0.003235678300444546, 0.003051396008709355, 0.005114584722880311, 0.003042591844779555, 0.0030347432002446263, 0.004314028262632723, 0.0031393186209165824, 0.0030682578289163882, 0.0030499925153345602, 0.0038801918224695875, 0.0036625112514868563, 0.003098830753214743, 0.003139324592227402, 0.0030457435754000914, 0.0030753093897032896, 0.00304661354174854, 0.003063247332099009, 0.0030550832397876087, 0.0031404824108353844, 0.0030665144604152964, 0.0031730323657184136, 0.0030549686764350472, 0.0030670734032654757, 0.0030479591275277035, 0.0030472209978435155, 0.0031001532963630314, 0.003065821579447761, 0.003989506989804649, 0.0032081397679603486, 0.003043229198974911, 0.0031355741781732833, 0.0030652310047505327], \"yaxis\": \"y\"}, {\"marker\": {\"color\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199], \"colorbar\": {\"title\": {\"text\": \"#Trials\"}, \"x\": 1.0, \"xpad\": 40}, \"colorscale\": [[0.0, \"rgb(247,251,255)\"], [0.125, \"rgb(222,235,247)\"], [0.25, \"rgb(198,219,239)\"], [0.375, \"rgb(158,202,225)\"], [0.5, \"rgb(107,174,214)\"], [0.625, \"rgb(66,146,198)\"], [0.75, \"rgb(33,113,181)\"], [0.875, \"rgb(8,81,156)\"], [1.0, \"rgb(8,48,107)\"]], \"line\": {\"color\": \"Grey\", \"width\": 0.5}, \"showscale\": false}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [47, 62, 10, 41, 95, 44, 2, 67, 92, 82, 5, 2, 22, 17, 25, 30, 4, 36, 13, 61, 2, 10, 3, 19, 30, 6, 15, 29, 53, 2, 12, 7, 1, 20, 1, 11, 1, 37, 15, 9, 49, 1, 2, 8, 83, 24, 1, 17, 8, 6, 13, 1, 6, 5, 1, 10, 69, 16, 21, 5, 12, 1, 1, 100, 4, 9, 1, 5, 14, 27, 10, 3, 1, 7, 4, 1, 18, 8, 54, 12, 4, 1, 1, 7, 4, 43, 10, 3, 35, 6, 14, 2, 1, 8, 6, 3, 3, 1, 11, 8, 72, 5, 1, 3, 1, 7, 5, 9, 3, 11, 1, 1, 5, 3, 7, 1, 3, 6, 9, 5, 13, 1, 2, 1, 4, 1, 7, 4, 1, 88, 6, 1, 4, 3, 3, 10, 8, 62, 1, 6, 1, 1, 3, 5, 3, 1, 59, 5, 7, 1, 9, 1, 3, 1, 5, 3, 1, 5, 7, 3, 1, 1, 4, 3, 1, 6, 3, 5, 8, 1, 3, 2, 1, 76, 5, 3, 1, 39, 7, 4, 5, 1, 3, 1, 3, 1, 5, 3, 6, 1, 3, 1, 1, 4, 3, 46, 7, 1, 5, 3], \"xaxis\": \"x2\", \"y\": [0.006686115212433441, 0.004284528263991583, 0.003292875491732628, 0.0067021287008553945, 0.006686741279354286, 0.005126323929194952, 0.006042540552445352, 0.004471201690238087, 0.006700589732082932, 0.006047995141010899, 0.003137337435782936, 0.0030424698407405457, 0.0035859452687375475, 0.003469623766601053, 0.003640767125366985, 0.003737988396616332, 0.0031113418465177215, 0.0038598455577899455, 0.0033596546099947952, 0.0041712487576662785, 0.003361307393468085, 0.003290255590852956, 0.0030668141943149575, 0.0035107374308580783, 0.0037319203192948368, 0.0031724661768049757, 0.0034282776999508603, 0.0037190834164093313, 0.004224028247577741, 0.0034883705613773194, 0.003353384199323047, 0.0032086120588555233, 0.003042161962403377, 0.0035408687610625324, 0.003038554813559496, 0.003310443768589637, 0.0030587315915855465, 0.0038496117860201237, 0.003427764666315125, 0.00325893062858381, 0.004368057023763377, 0.003057387983887244, 0.003056185162995904, 0.0032326450666105844, 0.004365878599074314, 0.0036289735762696463, 0.0030518351342642296, 0.003466474440633999, 0.0051050903665554965, 0.0031792010595777806, 0.0033774449724413933, 0.003035623078330721, 0.0031716782930152313, 0.003132834778756104, 0.003063794326888293, 0.0032819868630957123, 0.004250054107055727, 0.0034459470098077163, 0.0035694895406915995, 0.0031311160258558363, 0.003342960619425248, 0.0030490870542123206, 0.0030499337676775104, 0.004479122057407838, 0.0031232284749369305, 0.003264556213763498, 0.0030579376653623266, 0.003655088242479751, 0.003389250094702395, 0.003671586199019296, 0.0032831611527317757, 0.003080989124562916, 0.0030440491975784086, 0.0031947003549624895, 0.0031009304196166288, 0.0030527723775677688, 0.0034937253614362412, 0.003230046839181685, 0.004085687647787657, 0.0033447497927490914, 0.004650460865266002, 0.0030358297032356484, 0.003050512800868242, 0.0032014070255577116, 0.003108687838054023, 0.003951282348364045, 0.0032853923524122797, 0.0030746172987158736, 0.0038150481606825217, 0.003175693379555894, 0.0033919885488563426, 0.0030366114328592856, 0.0030712905044305325, 0.006050982718085376, 0.003168339113585927, 0.0030610071129549502, 0.00307797096575107, 0.0030545286940484367, 0.003338205562423805, 0.003235925133898641, 0.004279793051407756, 0.0031341227290968793, 0.0030392990299807033, 0.0030849423851650876, 0.0030621481796944405, 0.0032064347527757933, 0.003138225419343814, 0.003268970658305879, 0.003089989295175367, 0.003314590035760019, 0.0030351300093353116, 0.0030418422735848196, 0.0031421510412098282, 0.003077556027756016, 0.0032048380811785177, 0.0030424265838345896, 0.003069622384262403, 0.0031763494071959334, 0.003260662663878276, 0.0031394004124947286, 0.0033694019795612725, 0.0030442920721150163, 0.003045915092206465, 0.003040945942693145, 0.003090394395720189, 0.0030476991933826377, 0.003222884054970443, 0.0031076501384619403, 0.0030486537284161275, 0.004406049233048117, 0.0031739158788561123, 0.003050543210819241, 0.0031003596311745987, 0.0030747096037961478, 0.003070905569829401, 0.003289447513282577, 0.0032356211691038743, 0.0041735805659026595, 0.0030438037982954374, 0.0031614741038706556, 0.00303762747963763, 0.0030454817043842233, 0.0030743915691001794, 0.0031321042144613707, 0.0030706608869907233, 0.003038835958410224, 0.004146410685848724, 0.003135770785647889, 0.0032076555542660465, 0.003040533665261347, 0.003258503417109769, 0.003056979311483249, 0.003082588376860224, 0.0030499495854322467, 0.0031377451775924645, 0.0030742264648109625, 0.003048401466625845, 0.0031448666237528108, 0.0031976109652836126, 0.003079587791959947, 0.003048051809737823, 0.003050169432101656, 0.003106481577059623, 0.0030708744823299103, 0.0030587863363752943, 0.003164795711001836, 0.0030695933558443074, 0.0031445989996681505, 0.003235678300444546, 0.003051396008709355, 0.005114584722880311, 0.003042591844779555, 0.0030347432002446263, 0.004314028262632723, 0.0031393186209165824, 0.0030682578289163882, 0.0030499925153345602, 0.0038801918224695875, 0.0036625112514868563, 0.003098830753214743, 0.003139324592227402, 0.0030457435754000914, 0.0030753093897032896, 0.00304661354174854, 0.003063247332099009, 0.0030550832397876087, 0.0031404824108353844, 0.0030665144604152964, 0.0031730323657184136, 0.0030549686764350472, 0.0030670734032654757, 0.0030479591275277035, 0.0030472209978435155, 0.0031001532963630314, 0.003065821579447761, 0.003989506989804649, 0.0032081397679603486, 0.003043229198974911, 0.0031355741781732833, 0.0030652310047505327], \"yaxis\": \"y2\"}, {\"marker\": {\"color\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199], \"colorbar\": {\"title\": {\"text\": \"#Trials\"}, \"x\": 1.0, \"xpad\": 40}, \"colorscale\": [[0.0, \"rgb(247,251,255)\"], [0.125, \"rgb(222,235,247)\"], [0.25, \"rgb(198,219,239)\"], [0.375, \"rgb(158,202,225)\"], [0.5, \"rgb(107,174,214)\"], [0.625, \"rgb(66,146,198)\"], [0.75, \"rgb(33,113,181)\"], [0.875, \"rgb(8,81,156)\"], [1.0, \"rgb(8,48,107)\"]], \"line\": {\"color\": \"Grey\", \"width\": 0.5}, \"showscale\": false}, \"mode\": \"markers\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [886, 722, 688, 724, 605, 342, 366, 209, 127, 189, 992, 951, 992, 993, 869, 845, 503, 422, 525, 520, 630, 801, 952, 907, 468, 790, 316, 590, 916, 673, 803, 945, 983, 936, 743, 726, 847, 850, 742, 772, 880, 948, 834, 959, 913, 833, 672, 668, 762, 707, 636, 989, 989, 879, 575, 820, 969, 900, 701, 989, 870, 926, 913, 924, 995, 897, 923, 965, 965, 780, 1000, 818, 859, 865, 941, 751, 896, 638, 933, 857, 239, 749, 727, 966, 736, 812, 792, 886, 444, 924, 976, 672, 710, 690, 753, 656, 597, 569, 944, 620, 716, 681, 768, 762, 835, 727, 778, 912, 975, 805, 948, 952, 949, 904, 936, 980, 994, 978, 952, 879, 958, 919, 978, 980, 996, 959, 933, 982, 892, 854, 1000, 976, 947, 919, 966, 981, 379, 935, 909, 866, 903, 905, 885, 837, 923, 959, 949, 961, 791, 944, 949, 509, 128, 900, 967, 741, 942, 998, 930, 695, 910, 920, 958, 873, 978, 650, 937, 898, 981, 772, 963, 907, 915, 883, 549, 852, 821, 939, 922, 900, 953, 921, 913, 987, 966, 940, 876, 890, 932, 1000, 973, 911, 902, 953, 863, 920, 948, 983, 971, 987], \"xaxis\": \"x3\", \"y\": [0.006686115212433441, 0.004284528263991583, 0.003292875491732628, 0.0067021287008553945, 0.006686741279354286, 0.005126323929194952, 0.006042540552445352, 0.004471201690238087, 0.006700589732082932, 0.006047995141010899, 0.003137337435782936, 0.0030424698407405457, 0.0035859452687375475, 0.003469623766601053, 0.003640767125366985, 0.003737988396616332, 0.0031113418465177215, 0.0038598455577899455, 0.0033596546099947952, 0.0041712487576662785, 0.003361307393468085, 0.003290255590852956, 0.0030668141943149575, 0.0035107374308580783, 0.0037319203192948368, 0.0031724661768049757, 0.0034282776999508603, 0.0037190834164093313, 0.004224028247577741, 0.0034883705613773194, 0.003353384199323047, 0.0032086120588555233, 0.003042161962403377, 0.0035408687610625324, 0.003038554813559496, 0.003310443768589637, 0.0030587315915855465, 0.0038496117860201237, 0.003427764666315125, 0.00325893062858381, 0.004368057023763377, 0.003057387983887244, 0.003056185162995904, 0.0032326450666105844, 0.004365878599074314, 0.0036289735762696463, 0.0030518351342642296, 0.003466474440633999, 0.0051050903665554965, 0.0031792010595777806, 0.0033774449724413933, 0.003035623078330721, 0.0031716782930152313, 0.003132834778756104, 0.003063794326888293, 0.0032819868630957123, 0.004250054107055727, 0.0034459470098077163, 0.0035694895406915995, 0.0031311160258558363, 0.003342960619425248, 0.0030490870542123206, 0.0030499337676775104, 0.004479122057407838, 0.0031232284749369305, 0.003264556213763498, 0.0030579376653623266, 0.003655088242479751, 0.003389250094702395, 0.003671586199019296, 0.0032831611527317757, 0.003080989124562916, 0.0030440491975784086, 0.0031947003549624895, 0.0031009304196166288, 0.0030527723775677688, 0.0034937253614362412, 0.003230046839181685, 0.004085687647787657, 0.0033447497927490914, 0.004650460865266002, 0.0030358297032356484, 0.003050512800868242, 0.0032014070255577116, 0.003108687838054023, 0.003951282348364045, 0.0032853923524122797, 0.0030746172987158736, 0.0038150481606825217, 0.003175693379555894, 0.0033919885488563426, 0.0030366114328592856, 0.0030712905044305325, 0.006050982718085376, 0.003168339113585927, 0.0030610071129549502, 0.00307797096575107, 0.0030545286940484367, 0.003338205562423805, 0.003235925133898641, 0.004279793051407756, 0.0031341227290968793, 0.0030392990299807033, 0.0030849423851650876, 0.0030621481796944405, 0.0032064347527757933, 0.003138225419343814, 0.003268970658305879, 0.003089989295175367, 0.003314590035760019, 0.0030351300093353116, 0.0030418422735848196, 0.0031421510412098282, 0.003077556027756016, 0.0032048380811785177, 0.0030424265838345896, 0.003069622384262403, 0.0031763494071959334, 0.003260662663878276, 0.0031394004124947286, 0.0033694019795612725, 0.0030442920721150163, 0.003045915092206465, 0.003040945942693145, 0.003090394395720189, 0.0030476991933826377, 0.003222884054970443, 0.0031076501384619403, 0.0030486537284161275, 0.004406049233048117, 0.0031739158788561123, 0.003050543210819241, 0.0031003596311745987, 0.0030747096037961478, 0.003070905569829401, 0.003289447513282577, 0.0032356211691038743, 0.0041735805659026595, 0.0030438037982954374, 0.0031614741038706556, 0.00303762747963763, 0.0030454817043842233, 0.0030743915691001794, 0.0031321042144613707, 0.0030706608869907233, 0.003038835958410224, 0.004146410685848724, 0.003135770785647889, 0.0032076555542660465, 0.003040533665261347, 0.003258503417109769, 0.003056979311483249, 0.003082588376860224, 0.0030499495854322467, 0.0031377451775924645, 0.0030742264648109625, 0.003048401466625845, 0.0031448666237528108, 0.0031976109652836126, 0.003079587791959947, 0.003048051809737823, 0.003050169432101656, 0.003106481577059623, 0.0030708744823299103, 0.0030587863363752943, 0.003164795711001836, 0.0030695933558443074, 0.0031445989996681505, 0.003235678300444546, 0.003051396008709355, 0.005114584722880311, 0.003042591844779555, 0.0030347432002446263, 0.004314028262632723, 0.0031393186209165824, 0.0030682578289163882, 0.0030499925153345602, 0.0038801918224695875, 0.0036625112514868563, 0.003098830753214743, 0.003139324592227402, 0.0030457435754000914, 0.0030753093897032896, 0.00304661354174854, 0.003063247332099009, 0.0030550832397876087, 0.0031404824108353844, 0.0030665144604152964, 0.0031730323657184136, 0.0030549686764350472, 0.0030670734032654757, 0.0030479591275277035, 0.0030472209978435155, 0.0031001532963630314, 0.003065821579447761, 0.003989506989804649, 0.0032081397679603486, 0.003043229198974911, 0.0031355741781732833, 0.0030652310047505327], \"yaxis\": \"y3\"}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Slice Plot\"}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.2888888888888889], \"title\": {\"text\": \"max_depth\"}}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.35555555555555557, 0.6444444444444445], \"title\": {\"text\": \"min_samples_leaf\"}}, \"xaxis3\": {\"anchor\": \"y3\", \"domain\": [0.7111111111111111, 1.0], \"title\": {\"text\": \"n_estimators\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Objective Value\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0], \"matches\": \"y\", \"showticklabels\": false}, \"yaxis3\": {\"anchor\": \"x3\", \"domain\": [0.0, 1.0], \"matches\": \"y\", \"showticklabels\": false}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d5c65141-5130-4b8b-acee-a89d26fcba73');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "PEZ_-5MHhMM-",
        "outputId": "468f759d-8f45-4cb2-d898-d85187bb5131"
      },
      "source": [
        "optuna.visualization.plot_param_importances(study_randomforest)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"2b1935a8-2f38-4c16-855b-d0f31ed6a85e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"2b1935a8-2f38-4c16-855b-d0f31ed6a85e\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '2b1935a8-2f38-4c16-855b-d0f31ed6a85e',\n",
              "                        [{\"cliponaxis\": false, \"hovertemplate\": [\"n_estimators (IntUniformDistribution): 0.002105656977099362<extra></extra>\", \"min_samples_leaf (IntUniformDistribution): 0.276085913544747<extra></extra>\", \"max_depth (IntLogUniformDistribution): 0.7218084294781536<extra></extra>\"], \"marker\": {\"color\": \"rgb(66,146,198)\"}, \"orientation\": \"h\", \"text\": [\"0.002105656977099362\", \"0.276085913544747\", \"0.7218084294781536\"], \"textposition\": \"outside\", \"texttemplate\": \"%{text:.2f}\", \"type\": \"bar\", \"x\": [0.002105656977099362, 0.276085913544747, 0.7218084294781536], \"y\": [\"n_estimators\", \"min_samples_leaf\", \"max_depth\"]}],\n",
              "                        {\"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Hyperparameter Importances\"}, \"xaxis\": {\"title\": {\"text\": \"Importance for Objective Value\"}}, \"yaxis\": {\"title\": {\"text\": \"Hyperparameter\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('2b1935a8-2f38-4c16-855b-d0f31ed6a85e');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcZflFloqMvj"
      },
      "source": [
        "# **Melhor Resultado:**\n",
        "O Modelo que obteve o menor MSE foi o random forest, com os seguintes hiper parâmetros:\n",
        "{'n_estimators': 915, 'max_depth': 30, 'min_samples_leaf': 1}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMlyBIoRjpX6"
      },
      "source": [
        "def print_results(modelo): \n",
        "    y_pred_train = modelo.predict(X_train)\n",
        "    y_pred_val = modelo.predict(X_val)\n",
        "    y_pred_test = modelo.predict(X_test)\n",
        "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
        "    mse_val = mean_squared_error(y_val, y_pred_val)\n",
        "    mse_test = mean_squared_error(y_test, y_pred_test)\n",
        "    print(f\"MSE treino: {mse_train}\")\n",
        "    print(f\"MSE validacao: {mse_val}\")\n",
        "    print(f\"MSE teste: {mse_test}\")"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIrA3_y6qmF-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "821388de-95dc-4e97-b97f-35ba4b7105df"
      },
      "source": [
        "randomforestreg = RandomForestRegressor(n_estimators=915, max_depth=30,min_samples_leaf=1)\n",
        "randomforestreg.fit(X_train, y_train)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(max_depth=30, n_estimators=915)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICnh234tsyDw",
        "outputId": "11ee450d-a0d1-4104-a426-7bdaad421d86"
      },
      "source": [
        "print_results(randomforestreg)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE treino: 0.0004687242670972402\n",
            "MSE validacao: 0.0030516863973971357\n",
            "MSE teste: 0.002864553587419314\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMc9_HJQs59_"
      },
      "source": [
        "# Utilizando auto-sklearn para comparação com o modelo obtido pela nossa otimização de hiperparâmetros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wa68CPUXgkyD"
      },
      "source": [
        "from autosklearn.regression import AutoSklearnRegressor"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzKuffLvmz8D",
        "outputId": "063af67d-8213-4774-de31-7a87bc3525c3"
      },
      "source": [
        "auto_reg = AutoSklearnRegressor()\n",
        "auto_reg.fit(X_train,y_train)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_regression.py:691: RuntimeWarning:\n",
            "\n",
            "overflow encountered in square\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AutoSklearnRegressor(per_run_time_limit=360)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXarZa4xeSxK",
        "outputId": "60ea1dad-6297-455d-82ec-1ed50c30f82f"
      },
      "source": [
        "print_results(auto_reg)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE treino: 0.0011724120350682001\n",
            "MSE validacao: 0.0025104949298226835\n",
            "MSE teste: 0.0023729149877994627\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPQ2VuiOjKN6"
      },
      "source": [
        "# Diferença de MSE de treino = 0.0004687242670972402 - 0.0011724120350682001 = -0.00070368776797096\n",
        "\n",
        "# Nosso modelo se saiu muito bem nos dados de treinamento, até melhor do que o auto-sklearn, com uma diferença muito pequena, então não há **bias**, descartando **underfitting**.\n",
        "\n",
        "# Diferença de MSE de validação = 0.0030516863973971357-0.0025104949298226835= 0.0005411914675744521\n",
        "\n",
        "# A proporção da diferença dos resultados no conjunto de validação se manteve, se mostrando até menor que a do conjunto de treinamento(baixa **variância**). Porém, como dessa vez nosso modelo se saiu um pouco pior do que o auto-sklearn, talvez seja indicativo de **overfitting**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmKJPMC1nnRC"
      },
      "source": [
        "# **Melhorando o Modelo**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sk1ALfUInvdu"
      },
      "source": [
        "Como nosso erro no conjunto de validação e de teste é extremamente pequeno, provavelmente apenas aumentar o tamanho do dataset de treino corrija o problema"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsQMp3sHnt-m"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=2020)\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=2020)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0ScTtC_oE6i",
        "outputId": "e9f2a2aa-6160-4354-e242-51ccb4c082e7"
      },
      "source": [
        "randomforestreg = RandomForestRegressor(n_estimators=915, max_depth=30,min_samples_leaf=1)\n",
        "randomforestreg.fit(X_train, y_train)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(max_depth=30, n_estimators=915)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-G96t7VRoN2L",
        "outputId": "e17b3a5d-ee04-4745-91c5-f7db32146876"
      },
      "source": [
        "print_results(randomforestreg)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE treino: 0.0004487969474220763\n",
            "MSE validacao: 0.0030810171188915287\n",
            "MSE teste: 0.0027357395289580033\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hn0U5KfPozwg"
      },
      "source": [
        "Estranhamente, o erro no conjunto de validação aumentou ligeiramente, mas diminuiu no conjunto de teste. Acreditamos que mesmo assim a proporção da diferença dos resultados do nosso modelo para o auto-sklearn são praticamente irrelevantes (da ordem de 10^-4), considerando assim ser um bom modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZBvpotEdLX1"
      },
      "source": [
        "# **Ngrok para visualizar mlflow**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-wvtxOCRweA",
        "outputId": "295d1bb7-3faa-407d-a237-b4a034917a25"
      },
      "source": [
        "get_ipython().system_raw(\"mlflow ui --port 5000 &\")\n",
        "from pyngrok import ngrok\n",
        "ngrok.kill()\n",
        "NGROK_AUTH_TOKEN = \"\"\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "ngrok_tunnel = ngrok.connect(addr=\"5000\", proto=\"http\", bind_tls=True)\n",
        "print(\"MLflow Tracking UI:\", ngrok_tunnel.public_url)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLflow Tracking UI: https://22e79722d2e3.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}